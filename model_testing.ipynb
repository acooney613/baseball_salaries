{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball = pd.read_csv('data/baseball.csv')\n",
    "baseball = baseball.drop(['Name', 'Age', 'Name-additional'], axis = 1)\n",
    "baseball['Salary'] = baseball['Salary'].str.replace('$', '').astype(float)\n",
    "\n",
    "baseball['C'] = baseball['Position'].apply(lambda x: 1 if 'C' in x else 0)\n",
    "baseball['1B'] = baseball['Position'].apply(lambda x: 1 if '1B' in x else 0)\n",
    "baseball['2B'] = baseball['Position'].apply(lambda x: 1 if '2B' in x else 0)\n",
    "baseball['3B'] = baseball['Position'].apply(lambda x: 1 if '3B' in x else 0)\n",
    "baseball['SS'] = baseball['Position'].apply(lambda x: 1 if 'SS' in x else 0)\n",
    "baseball['OF'] = baseball['Position'].apply(lambda x: 1 if 'OF' in x else 0)\n",
    "\n",
    "baseball['Num_Pos'] = baseball[['C', '1B', '2B', '3B', 'SS', 'OF']].sum(axis = 1)\n",
    "baseball = baseball.drop(['Position'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "# packages used in each section below\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "import shap\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = baseball.drop(['Salary'], axis = 1)\n",
    "y = baseball['Salary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['Tm', 'Lg', 'Acquired', 'Bat']\n",
    "num_columns = [col for col in X.columns if col not in cat_columns + ['C', '1B', '2B', '3B', 'SS', 'OF']]\n",
    "\n",
    "cat_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('scale', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, num_columns),\n",
    "        ('cat', cat_transformer, cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "X_transform = preprocessor.fit_transform(X)\n",
    "\n",
    "selected_features = np.concatenate([\n",
    "    np.array(num_columns),\n",
    "    np.array(preprocessor.transformers_[1][1]['onehot'].get_feature_names_out(cat_columns)),\n",
    "    np.array(['C', '1B', '2B', '3B', 'SS', 'OF'])\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Packages</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Reduced Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_rf = RFE(estimator = RandomForestRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_rf.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[rfe_rf.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'RAA', 'WAA', 'RAR',\n",
    "               'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'CS', 'BB', 'SO', 'BA', 'OBP',\n",
    "               'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB', 'Num_Pos', 'Season']\n",
    "red_cat_columns = ['Tm', 'Acquired']\n",
    "X_rf = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf_red_train, X_rf_red_test, y_rf_red_train, y_rf_red_test = train_test_split(X_rf, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "rf_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', RandomForestRegressor(n_estimators = 150, min_samples_leaf = 10))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Random Forest Metrics:\n",
      "Training RMSE: 4001660.9448793163\n",
      "Test RMSE: 5397389.862092978\n"
     ]
    }
   ],
   "source": [
    "rf_red_pipe.fit(X_rf_red_train, y_rf_red_train)\n",
    "rf_red_train_mse = mean_squared_error(y_rf_red_train, rf_red_pipe.predict(X_rf_red_train))\n",
    "rf_red_test_mse = mean_squared_error(y_rf_red_test, rf_red_pipe.predict(X_rf_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(rf_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(rf_red_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Full Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestRegressor(n_estimators = 150, min_samples_leaf = 10))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 4008001.3629086222\n",
      "Test RMSE: 5367492.0010215845\n"
     ]
    }
   ],
   "source": [
    "rf_pipe.fit(X_train, y_train)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pipe.predict(X_train))\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(rf_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(rf_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Packages</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Reduced Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                           colsample_bylevel=None, colsample_bynode=None,\n",
       "                           colsample_bytree=None, early_stopping_rounds=None,\n",
       "                           enable_categorical=False, eval_metric=None,\n",
       "                           feature_types=None, gamma=None, gpu_id=None,\n",
       "                           grow_policy=None, importance_type=None,\n",
       "                           interaction_constraints=None, learning_rate=None,\n",
       "                           max_bin=None, max_cat_threshold=None,\n",
       "                           max_cat_to_onehot=None, max_delta_step=None,\n",
       "                           max_depth=None, max_leaves=None,\n",
       "                           min_child_weight=None, missing=nan,\n",
       "                           monotone_constraints=None, n_estimators=100,\n",
       "                           n_jobs=None, num_parallel_tree=None, predictor=None,\n",
       "                           random_state=621, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                           colsample_bylevel=None, colsample_bynode=None,\n",
       "                           colsample_bytree=None, early_stopping_rounds=None,\n",
       "                           enable_categorical=False, eval_metric=None,\n",
       "                           feature_types=None, gamma=None, gpu_id=None,\n",
       "                           grow_policy=None, importance_type=None,\n",
       "                           interaction_constraints=None, learning_rate=None,\n",
       "                           max_bin=None, max_cat_threshold=None,\n",
       "                           max_cat_to_onehot=None, max_delta_step=None,\n",
       "                           max_depth=None, max_leaves=None,\n",
       "                           min_child_weight=None, missing=nan,\n",
       "                           monotone_constraints=None, n_estimators=100,\n",
       "                           n_jobs=None, num_parallel_tree=None, predictor=None,\n",
       "                           random_state=621, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=621, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=621, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                           colsample_bylevel=None, colsample_bynode=None,\n",
       "                           colsample_bytree=None, early_stopping_rounds=None,\n",
       "                           enable_categorical=False, eval_metric=None,\n",
       "                           feature_types=None, gamma=None, gpu_id=None,\n",
       "                           grow_policy=None, importance_type=None,\n",
       "                           interaction_constraints=None, learning_rate=None,\n",
       "                           max_bin=None, max_cat_threshold=None,\n",
       "                           max_cat_to_onehot=None, max_delta_step=None,\n",
       "                           max_depth=None, max_leaves=None,\n",
       "                           min_child_weight=None, missing=nan,\n",
       "                           monotone_constraints=None, n_estimators=100,\n",
       "                           n_jobs=None, num_parallel_tree=None, predictor=None,\n",
       "                           random_state=621, ...))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_xg = RFE(estimator = XGBRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_xg.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Season', 'RBI', 'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS+',\n",
       "       'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB', 'Num_Pos', 'Tm_ARI',\n",
       "       'Tm_BOS', 'Tm_CHC', 'Tm_CIN', 'Tm_DET', 'Tm_HOU', 'Tm_KCR',\n",
       "       'Tm_LAA', 'Tm_LAD', 'Tm_MIA', 'Tm_MIN', 'Tm_MULTIPLE', 'Tm_NYM',\n",
       "       'Tm_NYY', 'Tm_OAK', 'Tm_PHI', 'Tm_STL', 'Tm_TBR', 'Tm_TEX',\n",
       "       'Acquired_Amateur Draft', 'Acquired_Amateur Free Agent',\n",
       "       'Acquired_Free Agency', 'Acquired_Traded', 'Bat_L', 'Bat_R', '1B',\n",
       "       '2B'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features[rfe_xg.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Season', 'RBI', 'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS+', \n",
    "                   'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB', 'Num_Pos']\n",
    "red_cat_columns = ['Tm', 'Acquired', 'Bat', 'C', '1B', '2B', '3B', 'SS', 'OF']\n",
    "X_xg = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xg_red_train, X_xg_red_test, y_xg_red_train, y_xg_red_test = train_test_split(X_xg, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "xg_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', XGBRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Random Forest Metrics:\n",
      "Training RMSE: 1304272.8356999753\n",
      "Test RMSE: 5238201.958554674\n"
     ]
    }
   ],
   "source": [
    "xg_red_pipe.fit(X_xg_red_train, y_xg_red_train)\n",
    "xg_red_train_mse = mean_squared_error(y_xg_red_train, xg_red_pipe.predict(X_xg_red_train))\n",
    "xg_red_test_mse = mean_squared_error(y_xg_red_test, xg_red_pipe.predict(X_xg_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(xg_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(xg_red_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Full Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', XGBRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 996000.2897536749\n",
      "Test RMSE: 5174242.088274057\n"
     ]
    }
   ],
   "source": [
    "xg_pipe.fit(X_train, y_train)\n",
    "xg_train_mse = mean_squared_error(y_train, xg_pipe.predict(X_train))\n",
    "xg_test_mse = mean_squared_error(y_test, xg_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(xg_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(xg_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Packages</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Reduced Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=GradientBoostingRegressor(random_state=621))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=GradientBoostingRegressor(random_state=621))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=621)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=621)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=GradientBoostingRegressor(random_state=621))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_gb = RFE(estimator = GradientBoostingRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_gb.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA',\n",
       "       'WAA', 'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'CS',\n",
       "       'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'SH',\n",
       "       'SF', 'IBB', 'Num_Pos', 'Tm_LAA', 'Tm_LAD', 'Tm_MIN',\n",
       "       'Tm_MULTIPLE', 'Tm_NYY', 'Tm_OAK', 'Tm_STL',\n",
       "       'Acquired_Free Agency', 'Acquired_Traded', '2B'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features[rfe_gb.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA',\n",
    "       'WAA', 'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'CS',\n",
    "       'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'SH',\n",
    "       'SF', 'IBB', 'Num_Pos']\n",
    "red_cat_columns = ['Tm', 'Acquired', 'C', '1B', '2B', '3B', 'SS', 'OF']\n",
    "X_gb = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gb_red_train, X_gb_red_test, y_gb_red_train, y_gb_red_test = train_test_split(X_gb, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "gb_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', GradientBoostingRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Random Forest Metrics:\n",
      "Training RMSE: 4300166.982328629\n",
      "Test RMSE: 5157317.893082923\n"
     ]
    }
   ],
   "source": [
    "gb_red_pipe.fit(X_gb_red_train, y_gb_red_train)\n",
    "gb_red_train_mse = mean_squared_error(y_gb_red_train, gb_red_pipe.predict(X_gb_red_train))\n",
    "gb_red_test_mse = mean_squared_error(y_gb_red_test, gb_red_pipe.predict(X_gb_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(gb_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(gb_red_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Full Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', GradientBoostingRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 4296144.0886627985\n",
      "Test RMSE: 5153019.854593112\n"
     ]
    }
   ],
   "source": [
    "gb_pipe.fit(X_train, y_train)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pipe.predict(X_train))\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(gb_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(gb_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADA Boosting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Packages</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Reduced Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=AdaBoostRegressor(random_state=621))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=AdaBoostRegressor(random_state=621))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(random_state=621)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(random_state=621)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=AdaBoostRegressor(random_state=621))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_ada = RFE(estimator = AdaBoostRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_ada.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA',\n",
       "       'WAA', 'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'CS', 'BB',\n",
       "       'SO', 'BA', 'OBP', 'SLG', 'OPS', 'OPS+', 'GDP', 'HBP', 'SH', 'SF',\n",
       "       'IBB', 'Num_Pos', 'Tm_CHC', 'Tm_COL', 'Tm_DET', 'Tm_HOU', 'Tm_LAA',\n",
       "       'Tm_NYM', 'Tm_NYY', 'Acquired_Free Agency', 'Bat_L', 'Bat_R', '2B'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features[rfe_ada.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA', 'WAA',\n",
    "       'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'CS', 'BB', 'SO', 'BA',\n",
    "       'OBP', 'SLG', 'OPS', 'OPS+', 'GDP', 'HBP', 'SH', 'SF', 'IBB',\n",
    "       'Num_Pos']\n",
    "red_cat_columns = ['Tm', 'Acquired', 'Bat', 'C', '1B', '2B', '3B', 'SS', 'OF']\n",
    "X_ada = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ada_red_train, X_ada_red_test, y_ada_red_train, y_ada_red_test = train_test_split(X_ada, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "ada_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', AdaBoostRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Random Forest Metrics:\n",
      "Training RMSE: 6071280.946153002\n",
      "Test RMSE: 6318851.235672393\n"
     ]
    }
   ],
   "source": [
    "ada_red_pipe.fit(X_ada_red_train, y_ada_red_train)\n",
    "ada_red_train_mse = mean_squared_error(y_ada_red_train, ada_red_pipe.predict(X_ada_red_train))\n",
    "ada_red_test_mse = mean_squared_error(y_ada_red_test, ada_red_pipe.predict(X_ada_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(ada_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(ada_red_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Full Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', PCA(n_components = 30, random_state = 621)),\n",
    "        ('model', AdaBoostRegressor(random_state = 621))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 6005706.449179022\n",
      "Test RMSE: 6434392.497233446\n"
     ]
    }
   ],
   "source": [
    "ada_pipe.fit(X_train, y_train)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pipe.predict(X_train))\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(ada_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(ada_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Packages</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Full Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', SVC())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 5958921.78673805\n",
      "Test RMSE: 6496242.391000514\n"
     ]
    }
   ],
   "source": [
    "svm_pipe.fit(X_train, y_train)\n",
    "svm_train_mse = mean_squared_error(y_train, svm_pipe.predict(X_train))\n",
    "svm_test_mse = mean_squared_error(y_test, svm_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(svm_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(svm_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Packages</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Full Model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', PCA(n_components = 63)),\n",
    "        ('model', KNeighborsRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 4357478.9227963155\n",
      "Test RMSE: 5627354.873436867\n"
     ]
    }
   ],
   "source": [
    "knn_pipe.fit(X_train, y_train)\n",
    "knn_train_mse = mean_squared_error(y_train, knn_pipe.predict(X_train))\n",
    "knn_test_mse = mean_squared_error(y_test, knn_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(knn_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(knn_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Packages</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from bayes_opt import BayesianOptimization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.1\n",
    "scaling = 0.9\n",
    "shift = .2\n",
    "\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "X_train_aug = X_train_scaled + np.random.normal(scale = noise, size = X_train_scaled.shape)\n",
    "X_train_aug *= np.random.uniform(1 - scaling, 1 + scaling, size = X_train_scaled.shape)\n",
    "X_train_aug += np.random.uniform(-shift, shift, size = X_train_scaled.shape)\n",
    "\n",
    "X_train_comb = np.vstack((X_train_scaled, X_train_aug))\n",
    "y_train_comb = np.hstack((y_train, y_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Bayesian Optimization</span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES:\n",
    "- Should look at different dropout rates for the different layers we add (similar code to adding more layers)\n",
    "- Should look into different EPOCHS or optimizers in order to optimally fit and train the data\n",
    "- Should also look into different batch sizes or maybe different activations for the different layers and run more iterations to find the best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | dropou... |  epochs   | layer_... | layer_... | layer_... | layer_... | layer_... | learni... |  neurons  | num_la... | patience  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-2.713e+1\u001b[0m | \u001b[0m207.3    \u001b[0m | \u001b[0m0.4754   \u001b[0m | \u001b[0m392.8    \u001b[0m | \u001b[0m166.1    \u001b[0m | \u001b[0m66.95    \u001b[0m | \u001b[0m66.94    \u001b[0m | \u001b[0m45.01    \u001b[0m | \u001b[0m226.0    \u001b[0m | \u001b[0m0.6051   \u001b[0m | \u001b[0m190.6    \u001b[0m | \u001b[0m1.082    \u001b[0m | \u001b[0m49.1     \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-2.636e+1\u001b[0m | \u001b[95m421.6    \u001b[0m | \u001b[95m0.1062   \u001b[0m | \u001b[95m172.7    \u001b[0m | \u001b[95m73.08    \u001b[0m | \u001b[95m100.2    \u001b[0m | \u001b[95m149.5    \u001b[0m | \u001b[95m128.8    \u001b[0m | \u001b[95m97.24    \u001b[0m | \u001b[95m0.6157   \u001b[0m | \u001b[95m63.25    \u001b[0m | \u001b[95m2.169    \u001b[0m | \u001b[95m30.99    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-2.656e+1\u001b[0m | \u001b[0m245.4    \u001b[0m | \u001b[0m0.3926   \u001b[0m | \u001b[0m179.9    \u001b[0m | \u001b[0m147.2    \u001b[0m | \u001b[0m164.7    \u001b[0m | \u001b[0m42.4     \u001b[0m | \u001b[0m168.1    \u001b[0m | \u001b[0m70.2     \u001b[0m | \u001b[0m0.0744   \u001b[0m | \u001b[0m244.6    \u001b[0m | \u001b[0m4.863    \u001b[0m | \u001b[0m44.25    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-2.65e+13\u001b[0m | \u001b[0m174.6    \u001b[0m | \u001b[0m0.04884  \u001b[0m | \u001b[0m373.7    \u001b[0m | \u001b[0m130.6    \u001b[0m | \u001b[0m59.34    \u001b[0m | \u001b[0m142.9    \u001b[0m | \u001b[0m39.7     \u001b[0m | \u001b[0m235.7    \u001b[0m | \u001b[0m0.2662   \u001b[0m | \u001b[0m180.4    \u001b[0m | \u001b[0m2.247    \u001b[0m | \u001b[0m35.6     \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m-2.609e+1\u001b[0m | \u001b[95m287.9    \u001b[0m | \u001b[95m0.09243  \u001b[0m | \u001b[95m487.8    \u001b[0m | \u001b[95m205.6    \u001b[0m | \u001b[95m242.4    \u001b[0m | \u001b[95m232.4    \u001b[0m | \u001b[95m165.9    \u001b[0m | \u001b[95m238.5    \u001b[0m | \u001b[95m0.09761  \u001b[0m | \u001b[95m75.9     \u001b[0m | \u001b[95m1.181    \u001b[0m | \u001b[95m29.76    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m-2.595e+1\u001b[0m | \u001b[95m259.3    \u001b[0m | \u001b[95m0.354    \u001b[0m | \u001b[95m263.0    \u001b[0m | \u001b[95m154.4    \u001b[0m | \u001b[95m218.6    \u001b[0m | \u001b[95m143.3    \u001b[0m | \u001b[95m158.1    \u001b[0m | \u001b[95m126.6    \u001b[0m | \u001b[95m0.1988   \u001b[0m | \u001b[95m250.1    \u001b[0m | \u001b[95m1.082    \u001b[0m | \u001b[95m23.73    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-2.715e+1\u001b[0m | \u001b[0m262.6    \u001b[0m | \u001b[0m0.1628   \u001b[0m | \u001b[0m287.0    \u001b[0m | \u001b[0m156.5    \u001b[0m | \u001b[0m240.1    \u001b[0m | \u001b[0m178.1    \u001b[0m | \u001b[0m159.8    \u001b[0m | \u001b[0m140.1    \u001b[0m | \u001b[0m0.4089   \u001b[0m | \u001b[0m253.7    \u001b[0m | \u001b[0m1.003    \u001b[0m | \u001b[0m20.04    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-2.837e+1\u001b[0m | \u001b[0m439.1    \u001b[0m | \u001b[0m0.3421   \u001b[0m | \u001b[0m194.0    \u001b[0m | \u001b[0m49.28    \u001b[0m | \u001b[0m243.3    \u001b[0m | \u001b[0m170.7    \u001b[0m | \u001b[0m131.0    \u001b[0m | \u001b[0m83.59    \u001b[0m | \u001b[0m0.1348   \u001b[0m | \u001b[0m86.74    \u001b[0m | \u001b[0m4.043    \u001b[0m | \u001b[0m20.82    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-6.933e+1\u001b[0m | \u001b[0m451.2    \u001b[0m | \u001b[0m0.05307  \u001b[0m | \u001b[0m186.9    \u001b[0m | \u001b[0m114.3    \u001b[0m | \u001b[0m94.19    \u001b[0m | \u001b[0m165.8    \u001b[0m | \u001b[0m54.16    \u001b[0m | \u001b[0m225.9    \u001b[0m | \u001b[0m0.5165   \u001b[0m | \u001b[0m36.21    \u001b[0m | \u001b[0m4.075    \u001b[0m | \u001b[0m36.53    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-2.708e+1\u001b[0m | \u001b[0m346.3    \u001b[0m | \u001b[0m0.1887   \u001b[0m | \u001b[0m182.7    \u001b[0m | \u001b[0m53.25    \u001b[0m | \u001b[0m116.7    \u001b[0m | \u001b[0m128.3    \u001b[0m | \u001b[0m210.9    \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m0.6712   \u001b[0m | \u001b[0m132.9    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m25.12    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-2.639e+1\u001b[0m | \u001b[0m199.9    \u001b[0m | \u001b[0m0.2677   \u001b[0m | \u001b[0m389.7    \u001b[0m | \u001b[0m144.6    \u001b[0m | \u001b[0m153.7    \u001b[0m | \u001b[0m127.7    \u001b[0m | \u001b[0m178.3    \u001b[0m | \u001b[0m111.7    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m128.6    \u001b[0m | \u001b[0m2.345    \u001b[0m | \u001b[0m37.62    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-2.795e+1\u001b[0m | \u001b[0m234.5    \u001b[0m | \u001b[0m0.2632   \u001b[0m | \u001b[0m344.6    \u001b[0m | \u001b[0m105.0    \u001b[0m | \u001b[0m249.8    \u001b[0m | \u001b[0m70.72    \u001b[0m | \u001b[0m197.2    \u001b[0m | \u001b[0m103.6    \u001b[0m | \u001b[0m0.148    \u001b[0m | \u001b[0m132.6    \u001b[0m | \u001b[0m4.014    \u001b[0m | \u001b[0m24.55    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[95m13       \u001b[0m | \u001b[95m-2.427e+1\u001b[0m | \u001b[95m185.7    \u001b[0m | \u001b[95m0.184    \u001b[0m | \u001b[95m317.2    \u001b[0m | \u001b[95m69.97    \u001b[0m | \u001b[95m99.24    \u001b[0m | \u001b[95m116.4    \u001b[0m | \u001b[95m72.71    \u001b[0m | \u001b[95m53.02    \u001b[0m | \u001b[95m0.7511   \u001b[0m | \u001b[95m256.0    \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m23.6     \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-2.737e+1\u001b[0m | \u001b[0m69.73    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m286.0    \u001b[0m | \u001b[0m166.3    \u001b[0m | \u001b[0m138.9    \u001b[0m | \u001b[0m97.89    \u001b[0m | \u001b[0m125.4    \u001b[0m | \u001b[0m140.2    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m22.69    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-2.746e+1\u001b[0m | \u001b[0m247.3    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m323.8    \u001b[0m | \u001b[0m219.5    \u001b[0m | \u001b[0m47.03    \u001b[0m | \u001b[0m141.2    \u001b[0m | \u001b[0m142.2    \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m20.0     \u001b[0m |\n",
      "=========================================================================================================================================================================\n",
      "Best Hyperparameters: {'batch_size': 185.68957383706393, 'dropout_rate': 0.18403286455306758, 'epochs': 317.23784956257674, 'layer_neurons_1': 69.96848204803361, 'layer_neurons_2': 99.23845577190994, 'layer_neurons_3': 116.42769186961587, 'layer_neurons_4': 72.71004025541644, 'layer_neurons_5': 53.02148683060075, 'learning_rate': 0.7511225930680763, 'neurons': 256.0, 'num_layers': 1.0, 'patience': 23.59802268856154}\n"
     ]
    }
   ],
   "source": [
    "def dnn_model_score(neurons, dropout_rate, learning_rate, epochs, batch_size, patience, num_layers, **layer_neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(neurons), activation='relu', input_shape = (X_train_scaled.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    for i in range(1, int(num_layers) + 1):\n",
    "        model.add(Dense(int(layer_neurons[f'layer_neurons_{i}']), activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "    optimizer = Adam(learning_rate = learning_rate)\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "\n",
    "    es = EarlyStopping(monitor = 'val_loss', patience = int(patience), restore_best_weights = True)\n",
    "\n",
    "    model.fit(X_train_comb, y_train_comb, validation_split = .2, epochs = int(epochs), batch_size = int(batch_size), callbacks = es, verbose = 0)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return -mse\n",
    "\n",
    "pbounds = {'neurons': (32, 1000),\n",
    "           'dropout_rate': (0.0, 0.5),\n",
    "           'learning_rate': (0.01, 1),\n",
    "           'epochs' : (100, 500),\n",
    "           'batch_size' : (32, 500),\n",
    "           'patience' : (20, 50),\n",
    "           'num_layers': (1, 5)}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    pbounds[f'layer_neurons_{i}'] = (32, 1000)\n",
    "\n",
    "optimizer = BayesianOptimization(f = dnn_model_score, pbounds = pbounds, random_state = 42)\n",
    "\n",
    "optimizer.maximize(init_points = 5, n_iter = 10)\n",
    "\n",
    "best_params = optimizer.max['params']\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(best_params[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m dropout_rate \u001b[39m=\u001b[39m best_params[\u001b[39m'\u001b[39m\u001b[39mdropout_rate\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(best_params[\u001b[39m'\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = int(best_params['batch_size'])\n",
    "dropout_rate = best_params['dropout_rate']\n",
    "epochs = int(best_params['epochs'])\n",
    "neurons = []\n",
    "neurons.append(int(best_params['neurons']))\n",
    "neurons.append(int(best_params['layer_neurons_1']))\n",
    "neurons.append(int(best_params['layer_neurons_2']))\n",
    "neurons.append(int(best_params['layer_neurons_3']))\n",
    "neurons.append(int(best_params['layer_neurons_4']))\n",
    "neurons.append(int(best_params['layer_neurons_5']))\n",
    "learning_rate = best_params['learning_rate']\n",
    "num_layers = int(best_params['num_layers'])\n",
    "patience = int(best_params['patience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_82\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_82\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">22,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">154</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,654</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">154</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">155</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)            │        \u001b[38;5;34m22,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout1 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense2 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m154\u001b[0m)            │        \u001b[38;5;34m38,654\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout2 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m154\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m155\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,809</span> (237.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,809\u001b[0m (237.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,809</span> (237.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,809\u001b[0m (237.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(name = 'Dense1', units = neurons[0], input_dim = X_train_scaled.shape[1], activation = 'relu'))\n",
    "model.add(Dropout(name = 'Dropout1', rate = dropout_rate))\n",
    "\n",
    "for i in range(1, num_layers + 1):\n",
    "    model.add(Dense(name = f'Dense{i + 1}', units = neurons[i], activation = 'relu'))\n",
    "    model.add(Dropout(name = f'Dropout{i + 1}', rate = dropout_rate))\n",
    "\n",
    "model.add(Dense(name = 'Output', units = 1, activation = 'linear'))\n",
    "\n",
    "optimizer = Adam(learning_rate = learning_rate)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = 'mean_squared_error')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/262\n",
      "15/15 - 0s - 13ms/step - loss: 12380793733120.0000\n",
      "Epoch 2/262\n",
      "15/15 - 0s - 16ms/step - loss: 12435271450624.0000\n",
      "Epoch 3/262\n",
      "15/15 - 0s - 13ms/step - loss: 11717075533824.0000\n",
      "Epoch 4/262\n",
      "15/15 - 0s - 15ms/step - loss: 11960454217728.0000\n",
      "Epoch 5/262\n",
      "15/15 - 0s - 28ms/step - loss: 11455581650944.0000\n",
      "Epoch 6/262\n",
      "15/15 - 0s - 12ms/step - loss: 11338127507456.0000\n",
      "Epoch 7/262\n",
      "15/15 - 0s - 12ms/step - loss: 11049852993536.0000\n",
      "Epoch 8/262\n",
      "15/15 - 0s - 12ms/step - loss: 10889184935936.0000\n",
      "Epoch 9/262\n",
      "15/15 - 0s - 12ms/step - loss: 10229547794432.0000\n",
      "Epoch 10/262\n",
      "15/15 - 0s - 10ms/step - loss: 10793315729408.0000\n",
      "Epoch 11/262\n",
      "15/15 - 0s - 8ms/step - loss: 10930191597568.0000\n",
      "Epoch 12/262\n",
      "15/15 - 0s - 9ms/step - loss: 9637593088000.0000\n",
      "Epoch 13/262\n",
      "15/15 - 0s - 9ms/step - loss: 10207501484032.0000\n",
      "Epoch 14/262\n",
      "15/15 - 0s - 9ms/step - loss: 9725457465344.0000\n",
      "Epoch 15/262\n",
      "15/15 - 0s - 9ms/step - loss: 10264911020032.0000\n",
      "Epoch 16/262\n",
      "15/15 - 0s - 10ms/step - loss: 10109197484032.0000\n",
      "Epoch 17/262\n",
      "15/15 - 0s - 12ms/step - loss: 9442065121280.0000\n",
      "Epoch 18/262\n",
      "15/15 - 0s - 12ms/step - loss: 9533768335360.0000\n",
      "Epoch 19/262\n",
      "15/15 - 0s - 13ms/step - loss: 9256716730368.0000\n",
      "Epoch 20/262\n",
      "15/15 - 0s - 12ms/step - loss: 9434864549888.0000\n",
      "Epoch 21/262\n",
      "15/15 - 0s - 10ms/step - loss: 8951842209792.0000\n",
      "Epoch 22/262\n",
      "15/15 - 0s - 10ms/step - loss: 9422954823680.0000\n",
      "Epoch 23/262\n",
      "15/15 - 0s - 10ms/step - loss: 9179311898624.0000\n",
      "Epoch 24/262\n",
      "15/15 - 0s - 11ms/step - loss: 8895494881280.0000\n",
      "Epoch 25/262\n",
      "15/15 - 0s - 10ms/step - loss: 8830348951552.0000\n",
      "Epoch 26/262\n",
      "15/15 - 0s - 11ms/step - loss: 9398403465216.0000\n",
      "Epoch 27/262\n",
      "15/15 - 0s - 11ms/step - loss: 8778724409344.0000\n",
      "Epoch 28/262\n",
      "15/15 - 0s - 9ms/step - loss: 8508566142976.0000\n",
      "Epoch 29/262\n",
      "15/15 - 0s - 11ms/step - loss: 8139572248576.0000\n",
      "Epoch 30/262\n",
      "15/15 - 0s - 8ms/step - loss: 8294436962304.0000\n",
      "Epoch 31/262\n",
      "15/15 - 0s - 8ms/step - loss: 7807094489088.0000\n",
      "Epoch 32/262\n",
      "15/15 - 0s - 10ms/step - loss: 7961012338688.0000\n",
      "Epoch 33/262\n",
      "15/15 - 0s - 8ms/step - loss: 7909636308992.0000\n",
      "Epoch 34/262\n",
      "15/15 - 0s - 9ms/step - loss: 8038281904128.0000\n",
      "Epoch 35/262\n",
      "15/15 - 0s - 8ms/step - loss: 8679009026048.0000\n",
      "Epoch 36/262\n",
      "15/15 - 0s - 9ms/step - loss: 8277184217088.0000\n",
      "Epoch 37/262\n",
      "15/15 - 0s - 9ms/step - loss: 7636453949440.0000\n",
      "Epoch 38/262\n",
      "15/15 - 0s - 8ms/step - loss: 7995837644800.0000\n",
      "Epoch 39/262\n",
      "15/15 - 0s - 9ms/step - loss: 8340035862528.0000\n",
      "Epoch 40/262\n",
      "15/15 - 0s - 9ms/step - loss: 7730846760960.0000\n",
      "Epoch 41/262\n",
      "15/15 - 0s - 8ms/step - loss: 7809011810304.0000\n",
      "Epoch 42/262\n",
      "15/15 - 0s - 8ms/step - loss: 7370469015552.0000\n",
      "Epoch 43/262\n",
      "15/15 - 0s - 9ms/step - loss: 7175201619968.0000\n",
      "Epoch 44/262\n",
      "15/15 - 0s - 8ms/step - loss: 7334571016192.0000\n",
      "Epoch 45/262\n",
      "15/15 - 0s - 9ms/step - loss: 7106778365952.0000\n",
      "Epoch 46/262\n",
      "15/15 - 0s - 9ms/step - loss: 7577635127296.0000\n",
      "Epoch 47/262\n",
      "15/15 - 0s - 9ms/step - loss: 7502052196352.0000\n",
      "Epoch 48/262\n",
      "15/15 - 0s - 9ms/step - loss: 7456445956096.0000\n",
      "Epoch 49/262\n",
      "15/15 - 0s - 8ms/step - loss: 6922398334976.0000\n",
      "Epoch 50/262\n",
      "15/15 - 0s - 9ms/step - loss: 7324558163968.0000\n",
      "Epoch 51/262\n",
      "15/15 - 0s - 8ms/step - loss: 7243318165504.0000\n",
      "Epoch 52/262\n",
      "15/15 - 0s - 9ms/step - loss: 7523644473344.0000\n",
      "Epoch 53/262\n",
      "15/15 - 0s - 8ms/step - loss: 7285619818496.0000\n",
      "Epoch 54/262\n",
      "15/15 - 0s - 8ms/step - loss: 7143812497408.0000\n",
      "Epoch 55/262\n",
      "15/15 - 0s - 9ms/step - loss: 7012659757056.0000\n",
      "Epoch 56/262\n",
      "15/15 - 0s - 9ms/step - loss: 6683103854592.0000\n",
      "Epoch 57/262\n",
      "15/15 - 0s - 10ms/step - loss: 6854693355520.0000\n",
      "Epoch 58/262\n",
      "15/15 - 0s - 8ms/step - loss: 7036304097280.0000\n",
      "Epoch 59/262\n",
      "15/15 - 0s - 9ms/step - loss: 7011030794240.0000\n",
      "Epoch 60/262\n",
      "15/15 - 0s - 9ms/step - loss: 6357325971456.0000\n",
      "Epoch 61/262\n",
      "15/15 - 0s - 9ms/step - loss: 6683286306816.0000\n",
      "Epoch 62/262\n",
      "15/15 - 0s - 9ms/step - loss: 6672298803200.0000\n",
      "Epoch 63/262\n",
      "15/15 - 0s - 14ms/step - loss: 6702481539072.0000\n",
      "Epoch 64/262\n",
      "15/15 - 0s - 17ms/step - loss: 6617471385600.0000\n",
      "Epoch 65/262\n",
      "15/15 - 0s - 12ms/step - loss: 6941927538688.0000\n",
      "Epoch 66/262\n",
      "15/15 - 0s - 13ms/step - loss: 6611403800576.0000\n",
      "Epoch 67/262\n",
      "15/15 - 0s - 14ms/step - loss: 6406870138880.0000\n",
      "Epoch 68/262\n",
      "15/15 - 0s - 17ms/step - loss: 6419026804736.0000\n",
      "Epoch 69/262\n",
      "15/15 - 0s - 18ms/step - loss: 6828227821568.0000\n",
      "Epoch 70/262\n",
      "15/15 - 0s - 14ms/step - loss: 5843325026304.0000\n",
      "Epoch 71/262\n",
      "15/15 - 0s - 16ms/step - loss: 6453106049024.0000\n",
      "Epoch 72/262\n",
      "15/15 - 0s - 16ms/step - loss: 6088578564096.0000\n",
      "Epoch 73/262\n",
      "15/15 - 0s - 15ms/step - loss: 6751724765184.0000\n",
      "Epoch 74/262\n",
      "15/15 - 0s - 20ms/step - loss: 6422512795648.0000\n",
      "Epoch 75/262\n",
      "15/15 - 0s - 13ms/step - loss: 6389994881024.0000\n",
      "Epoch 76/262\n",
      "15/15 - 0s - 11ms/step - loss: 6568738291712.0000\n",
      "Epoch 77/262\n",
      "15/15 - 0s - 13ms/step - loss: 6164673200128.0000\n",
      "Epoch 78/262\n",
      "15/15 - 0s - 13ms/step - loss: 6736336388096.0000\n",
      "Epoch 79/262\n",
      "15/15 - 0s - 12ms/step - loss: 6854676054016.0000\n",
      "Epoch 80/262\n",
      "15/15 - 0s - 11ms/step - loss: 6293132148736.0000\n",
      "Epoch 81/262\n",
      "15/15 - 0s - 11ms/step - loss: 6167995088896.0000\n",
      "Epoch 82/262\n",
      "15/15 - 0s - 12ms/step - loss: 6091971756032.0000\n",
      "Epoch 83/262\n",
      "15/15 - 0s - 10ms/step - loss: 5797420466176.0000\n",
      "Epoch 84/262\n",
      "15/15 - 0s - 9ms/step - loss: 5872931045376.0000\n",
      "Epoch 85/262\n",
      "15/15 - 0s - 10ms/step - loss: 5908460994560.0000\n",
      "Epoch 86/262\n",
      "15/15 - 0s - 7ms/step - loss: 6126854209536.0000\n",
      "Epoch 87/262\n",
      "15/15 - 0s - 8ms/step - loss: 5966280523776.0000\n",
      "Epoch 88/262\n",
      "15/15 - 0s - 8ms/step - loss: 6151895777280.0000\n",
      "Epoch 89/262\n",
      "15/15 - 0s - 8ms/step - loss: 6432211075072.0000\n",
      "Epoch 90/262\n",
      "15/15 - 0s - 7ms/step - loss: 6144531628032.0000\n",
      "Epoch 91/262\n",
      "15/15 - 0s - 7ms/step - loss: 5776576348160.0000\n",
      "Epoch 92/262\n",
      "15/15 - 0s - 7ms/step - loss: 6034808635392.0000\n",
      "Epoch 93/262\n",
      "15/15 - 0s - 8ms/step - loss: 5669222612992.0000\n",
      "Epoch 94/262\n",
      "15/15 - 0s - 8ms/step - loss: 6010766884864.0000\n",
      "Epoch 95/262\n",
      "15/15 - 0s - 7ms/step - loss: 6073088475136.0000\n",
      "Epoch 96/262\n",
      "15/15 - 0s - 7ms/step - loss: 6234211090432.0000\n",
      "Epoch 97/262\n",
      "15/15 - 0s - 8ms/step - loss: 5894799097856.0000\n",
      "Epoch 98/262\n",
      "15/15 - 0s - 7ms/step - loss: 6145681915904.0000\n",
      "Epoch 99/262\n",
      "15/15 - 0s - 7ms/step - loss: 5976957648896.0000\n",
      "Epoch 100/262\n",
      "15/15 - 0s - 7ms/step - loss: 6030374207488.0000\n",
      "Epoch 101/262\n",
      "15/15 - 0s - 8ms/step - loss: 5682910199808.0000\n",
      "Epoch 102/262\n",
      "15/15 - 0s - 7ms/step - loss: 5712240443392.0000\n",
      "Epoch 103/262\n",
      "15/15 - 0s - 8ms/step - loss: 5913237258240.0000\n",
      "Epoch 104/262\n",
      "15/15 - 0s - 7ms/step - loss: 5720215912448.0000\n",
      "Epoch 105/262\n",
      "15/15 - 0s - 8ms/step - loss: 5584787079168.0000\n",
      "Epoch 106/262\n",
      "15/15 - 0s - 7ms/step - loss: 5926041419776.0000\n",
      "Epoch 107/262\n",
      "15/15 - 0s - 8ms/step - loss: 5528751177728.0000\n",
      "Epoch 108/262\n",
      "15/15 - 0s - 10ms/step - loss: 5590931734528.0000\n",
      "Epoch 109/262\n",
      "15/15 - 0s - 23ms/step - loss: 5739318870016.0000\n",
      "Epoch 110/262\n",
      "15/15 - 0s - 15ms/step - loss: 5422062239744.0000\n",
      "Epoch 111/262\n",
      "15/15 - 0s - 13ms/step - loss: 5742895038464.0000\n",
      "Epoch 112/262\n",
      "15/15 - 0s - 12ms/step - loss: 5535125471232.0000\n",
      "Epoch 113/262\n",
      "15/15 - 0s - 13ms/step - loss: 5409468317696.0000\n",
      "Epoch 114/262\n",
      "15/15 - 0s - 13ms/step - loss: 5653902917632.0000\n",
      "Epoch 115/262\n",
      "15/15 - 0s - 11ms/step - loss: 5531989704704.0000\n",
      "Epoch 116/262\n",
      "15/15 - 0s - 13ms/step - loss: 5352453570560.0000\n",
      "Epoch 117/262\n",
      "15/15 - 0s - 13ms/step - loss: 5433924780032.0000\n",
      "Epoch 118/262\n",
      "15/15 - 0s - 16ms/step - loss: 5449279602688.0000\n",
      "Epoch 119/262\n",
      "15/15 - 0s - 13ms/step - loss: 5374995857408.0000\n",
      "Epoch 120/262\n",
      "15/15 - 0s - 13ms/step - loss: 5434017579008.0000\n",
      "Epoch 121/262\n",
      "15/15 - 0s - 14ms/step - loss: 5324873400320.0000\n",
      "Epoch 122/262\n",
      "15/15 - 0s - 12ms/step - loss: 5087797706752.0000\n",
      "Epoch 123/262\n",
      "15/15 - 0s - 12ms/step - loss: 5319715979264.0000\n",
      "Epoch 124/262\n",
      "15/15 - 0s - 15ms/step - loss: 5172037681152.0000\n",
      "Epoch 125/262\n",
      "15/15 - 0s - 14ms/step - loss: 5309958979584.0000\n",
      "Epoch 126/262\n",
      "15/15 - 0s - 11ms/step - loss: 4920364761088.0000\n",
      "Epoch 127/262\n",
      "15/15 - 0s - 10ms/step - loss: 5380176871424.0000\n",
      "Epoch 128/262\n",
      "15/15 - 0s - 11ms/step - loss: 5503318491136.0000\n",
      "Epoch 129/262\n",
      "15/15 - 0s - 8ms/step - loss: 5744294363136.0000\n",
      "Epoch 130/262\n",
      "15/15 - 0s - 9ms/step - loss: 5261265207296.0000\n",
      "Epoch 131/262\n",
      "15/15 - 0s - 10ms/step - loss: 5521848926208.0000\n",
      "Epoch 132/262\n",
      "15/15 - 0s - 13ms/step - loss: 5169379540992.0000\n",
      "Epoch 133/262\n",
      "15/15 - 0s - 14ms/step - loss: 4996495048704.0000\n",
      "Epoch 134/262\n",
      "15/15 - 0s - 12ms/step - loss: 5358676869120.0000\n",
      "Epoch 135/262\n",
      "15/15 - 0s - 11ms/step - loss: 5624329404416.0000\n",
      "Epoch 136/262\n",
      "15/15 - 0s - 8ms/step - loss: 5694417272832.0000\n",
      "Epoch 137/262\n",
      "15/15 - 0s - 9ms/step - loss: 5440279150592.0000\n",
      "Epoch 138/262\n",
      "15/15 - 0s - 11ms/step - loss: 5534148722688.0000\n",
      "Epoch 139/262\n",
      "15/15 - 0s - 8ms/step - loss: 5610881941504.0000\n",
      "Epoch 140/262\n",
      "15/15 - 0s - 8ms/step - loss: 5311282282496.0000\n",
      "Epoch 141/262\n",
      "15/15 - 0s - 9ms/step - loss: 5184332759040.0000\n",
      "Epoch 142/262\n",
      "15/15 - 0s - 9ms/step - loss: 5475610918912.0000\n",
      "Epoch 143/262\n",
      "15/15 - 0s - 10ms/step - loss: 5339413479424.0000\n",
      "Epoch 144/262\n",
      "15/15 - 0s - 9ms/step - loss: 4701170958336.0000\n",
      "Epoch 145/262\n",
      "15/15 - 0s - 9ms/step - loss: 4961004421120.0000\n",
      "Epoch 146/262\n",
      "15/15 - 0s - 9ms/step - loss: 5351171162112.0000\n",
      "Epoch 147/262\n",
      "15/15 - 0s - 9ms/step - loss: 5383697989632.0000\n",
      "Epoch 148/262\n",
      "15/15 - 0s - 8ms/step - loss: 5321694642176.0000\n",
      "Epoch 149/262\n",
      "15/15 - 0s - 9ms/step - loss: 5041141317632.0000\n",
      "Epoch 150/262\n",
      "15/15 - 0s - 9ms/step - loss: 5186390065152.0000\n",
      "Epoch 151/262\n",
      "15/15 - 0s - 9ms/step - loss: 4943980789760.0000\n",
      "Epoch 152/262\n",
      "15/15 - 0s - 18ms/step - loss: 5289090220032.0000\n",
      "Epoch 153/262\n",
      "15/15 - 0s - 12ms/step - loss: 5451129815040.0000\n",
      "Epoch 154/262\n",
      "15/15 - 0s - 9ms/step - loss: 5083459223552.0000\n",
      "Epoch 155/262\n",
      "15/15 - 0s - 9ms/step - loss: 5044481032192.0000\n",
      "Epoch 156/262\n",
      "15/15 - 0s - 9ms/step - loss: 5151312052224.0000\n",
      "Epoch 157/262\n",
      "15/15 - 0s - 9ms/step - loss: 4895220957184.0000\n",
      "Epoch 158/262\n",
      "15/15 - 0s - 8ms/step - loss: 4972793561088.0000\n",
      "Epoch 159/262\n",
      "15/15 - 0s - 9ms/step - loss: 4902326632448.0000\n",
      "Epoch 160/262\n",
      "15/15 - 0s - 9ms/step - loss: 5135808856064.0000\n",
      "Epoch 161/262\n",
      "15/15 - 0s - 9ms/step - loss: 4782874427392.0000\n",
      "Epoch 162/262\n",
      "15/15 - 0s - 9ms/step - loss: 4775974797312.0000\n",
      "Epoch 163/262\n",
      "15/15 - 0s - 9ms/step - loss: 4971143102464.0000\n",
      "Epoch 164/262\n",
      "15/15 - 0s - 9ms/step - loss: 5109086945280.0000\n",
      "Epoch 165/262\n",
      "15/15 - 0s - 9ms/step - loss: 4921407045632.0000\n",
      "Epoch 166/262\n",
      "15/15 - 0s - 9ms/step - loss: 4736439812096.0000\n",
      "Epoch 167/262\n",
      "15/15 - 0s - 9ms/step - loss: 4866988048384.0000\n",
      "Epoch 168/262\n",
      "15/15 - 0s - 9ms/step - loss: 5038312259584.0000\n",
      "Epoch 169/262\n",
      "15/15 - 0s - 8ms/step - loss: 5018504134656.0000\n",
      "Epoch 170/262\n",
      "15/15 - 0s - 9ms/step - loss: 4584549384192.0000\n",
      "Epoch 171/262\n",
      "15/15 - 0s - 10ms/step - loss: 4931830415360.0000\n",
      "Epoch 172/262\n",
      "15/15 - 0s - 8ms/step - loss: 4635890810880.0000\n",
      "Epoch 173/262\n",
      "15/15 - 0s - 9ms/step - loss: 4870876168192.0000\n",
      "Epoch 174/262\n",
      "15/15 - 0s - 9ms/step - loss: 4699940978688.0000\n",
      "Epoch 175/262\n",
      "15/15 - 0s - 9ms/step - loss: 4789127086080.0000\n",
      "Epoch 176/262\n",
      "15/15 - 0s - 8ms/step - loss: 4472328159232.0000\n",
      "Epoch 177/262\n",
      "15/15 - 0s - 10ms/step - loss: 4872613134336.0000\n",
      "Epoch 178/262\n",
      "15/15 - 0s - 9ms/step - loss: 4592241213440.0000\n",
      "Epoch 179/262\n",
      "15/15 - 0s - 9ms/step - loss: 4624647454720.0000\n",
      "Epoch 180/262\n",
      "15/15 - 0s - 9ms/step - loss: 4937026633728.0000\n",
      "Epoch 181/262\n",
      "15/15 - 0s - 8ms/step - loss: 4883979698176.0000\n",
      "Epoch 182/262\n",
      "15/15 - 0s - 9ms/step - loss: 5077694152704.0000\n",
      "Epoch 183/262\n",
      "15/15 - 0s - 9ms/step - loss: 4830642307072.0000\n",
      "Epoch 184/262\n",
      "15/15 - 0s - 8ms/step - loss: 4953087672320.0000\n",
      "Epoch 185/262\n",
      "15/15 - 0s - 9ms/step - loss: 4823353131008.0000\n",
      "Epoch 186/262\n",
      "15/15 - 0s - 9ms/step - loss: 4771092627456.0000\n",
      "Epoch 187/262\n",
      "15/15 - 0s - 9ms/step - loss: 5025466679296.0000\n",
      "Epoch 188/262\n",
      "15/15 - 0s - 9ms/step - loss: 4914512134144.0000\n",
      "Epoch 189/262\n",
      "15/15 - 0s - 9ms/step - loss: 4370193711104.0000\n",
      "Epoch 190/262\n",
      "15/15 - 0s - 9ms/step - loss: 4439096688640.0000\n",
      "Epoch 191/262\n",
      "15/15 - 0s - 8ms/step - loss: 4835981131776.0000\n",
      "Epoch 192/262\n",
      "15/15 - 0s - 9ms/step - loss: 4550356369408.0000\n",
      "Epoch 193/262\n",
      "15/15 - 0s - 9ms/step - loss: 4965029904384.0000\n",
      "Epoch 194/262\n",
      "15/15 - 0s - 9ms/step - loss: 4456586412032.0000\n",
      "Epoch 195/262\n",
      "15/15 - 0s - 9ms/step - loss: 4595030425600.0000\n",
      "Epoch 196/262\n",
      "15/15 - 0s - 8ms/step - loss: 4549189828608.0000\n",
      "Epoch 197/262\n",
      "15/15 - 0s - 9ms/step - loss: 4774251462656.0000\n",
      "Epoch 198/262\n",
      "15/15 - 0s - 8ms/step - loss: 4473751601152.0000\n",
      "Epoch 199/262\n",
      "15/15 - 0s - 9ms/step - loss: 4790629695488.0000\n",
      "Epoch 200/262\n",
      "15/15 - 0s - 10ms/step - loss: 4957797351424.0000\n",
      "Epoch 201/262\n",
      "15/15 - 0s - 9ms/step - loss: 4838817005568.0000\n",
      "Epoch 202/262\n",
      "15/15 - 0s - 21ms/step - loss: 4447040700416.0000\n",
      "Epoch 203/262\n",
      "15/15 - 0s - 7ms/step - loss: 4392640053248.0000\n",
      "Epoch 204/262\n",
      "15/15 - 0s - 11ms/step - loss: 4590774779904.0000\n",
      "Epoch 205/262\n",
      "15/15 - 0s - 8ms/step - loss: 4538727661568.0000\n",
      "Epoch 206/262\n",
      "15/15 - 0s - 9ms/step - loss: 4846713307136.0000\n",
      "Epoch 207/262\n",
      "15/15 - 0s - 10ms/step - loss: 4601789546496.0000\n",
      "Epoch 208/262\n",
      "15/15 - 0s - 9ms/step - loss: 4847491874816.0000\n",
      "Epoch 209/262\n",
      "15/15 - 0s - 10ms/step - loss: 4594943393792.0000\n",
      "Epoch 210/262\n",
      "15/15 - 0s - 9ms/step - loss: 4698436272128.0000\n",
      "Epoch 211/262\n",
      "15/15 - 0s - 9ms/step - loss: 4784615063552.0000\n",
      "Epoch 212/262\n",
      "15/15 - 0s - 14ms/step - loss: 4664040882176.0000\n",
      "Epoch 213/262\n",
      "15/15 - 0s - 14ms/step - loss: 5035011866624.0000\n",
      "Epoch 214/262\n",
      "15/15 - 0s - 14ms/step - loss: 4484036558848.0000\n",
      "Epoch 215/262\n",
      "15/15 - 0s - 13ms/step - loss: 4284897034240.0000\n",
      "Epoch 216/262\n",
      "15/15 - 0s - 20ms/step - loss: 4581565661184.0000\n",
      "Epoch 217/262\n",
      "15/15 - 0s - 18ms/step - loss: 4511958564864.0000\n",
      "Epoch 218/262\n",
      "15/15 - 0s - 9ms/step - loss: 4550614843392.0000\n",
      "Epoch 219/262\n",
      "15/15 - 0s - 9ms/step - loss: 4617616228352.0000\n",
      "Epoch 220/262\n",
      "15/15 - 0s - 9ms/step - loss: 4513149222912.0000\n",
      "Epoch 221/262\n",
      "15/15 - 0s - 9ms/step - loss: 4642732769280.0000\n",
      "Epoch 222/262\n",
      "15/15 - 0s - 9ms/step - loss: 4730394247168.0000\n",
      "Epoch 223/262\n",
      "15/15 - 0s - 9ms/step - loss: 4572930637824.0000\n",
      "Epoch 224/262\n",
      "15/15 - 0s - 8ms/step - loss: 4811275632640.0000\n",
      "Epoch 225/262\n",
      "15/15 - 0s - 9ms/step - loss: 4633598099456.0000\n",
      "Epoch 226/262\n",
      "15/15 - 0s - 9ms/step - loss: 4690804736000.0000\n",
      "Epoch 227/262\n",
      "15/15 - 0s - 9ms/step - loss: 4246353215488.0000\n",
      "Epoch 228/262\n",
      "15/15 - 0s - 9ms/step - loss: 4423958396928.0000\n",
      "Epoch 229/262\n",
      "15/15 - 0s - 9ms/step - loss: 4881218273280.0000\n",
      "Epoch 230/262\n",
      "15/15 - 0s - 9ms/step - loss: 4506188775424.0000\n",
      "Epoch 231/262\n",
      "15/15 - 0s - 8ms/step - loss: 4315641544704.0000\n",
      "Epoch 232/262\n",
      "15/15 - 0s - 9ms/step - loss: 4435606503424.0000\n",
      "Epoch 233/262\n",
      "15/15 - 0s - 9ms/step - loss: 4583995736064.0000\n",
      "Epoch 234/262\n",
      "15/15 - 0s - 11ms/step - loss: 4388699504640.0000\n",
      "Epoch 235/262\n",
      "15/15 - 0s - 9ms/step - loss: 4561836179456.0000\n",
      "Epoch 236/262\n",
      "15/15 - 0s - 9ms/step - loss: 4353781399552.0000\n",
      "Epoch 237/262\n",
      "15/15 - 0s - 9ms/step - loss: 4340209942528.0000\n",
      "Epoch 238/262\n",
      "15/15 - 0s - 9ms/step - loss: 4636964552704.0000\n",
      "Epoch 239/262\n",
      "15/15 - 0s - 9ms/step - loss: 4705987067904.0000\n",
      "Epoch 240/262\n",
      "15/15 - 0s - 9ms/step - loss: 4383396593664.0000\n",
      "Epoch 241/262\n",
      "15/15 - 0s - 9ms/step - loss: 4391976042496.0000\n",
      "Epoch 242/262\n",
      "15/15 - 0s - 9ms/step - loss: 4376639569920.0000\n",
      "Epoch 243/262\n",
      "15/15 - 0s - 9ms/step - loss: 4515026698240.0000\n",
      "Epoch 244/262\n",
      "15/15 - 0s - 9ms/step - loss: 4449163542528.0000\n",
      "Epoch 245/262\n",
      "15/15 - 0s - 9ms/step - loss: 4616195932160.0000\n",
      "Epoch 246/262\n",
      "15/15 - 0s - 9ms/step - loss: 4581387927552.0000\n",
      "Epoch 247/262\n",
      "15/15 - 0s - 10ms/step - loss: 4720602120192.0000\n",
      "Epoch 248/262\n",
      "15/15 - 0s - 9ms/step - loss: 4335795961856.0000\n",
      "Epoch 249/262\n",
      "15/15 - 0s - 9ms/step - loss: 4508134932480.0000\n",
      "Epoch 250/262\n",
      "15/15 - 0s - 9ms/step - loss: 4394284220416.0000\n",
      "Epoch 251/262\n",
      "15/15 - 0s - 9ms/step - loss: 4230048382976.0000\n",
      "Epoch 252/262\n",
      "15/15 - 0s - 10ms/step - loss: 4487179665408.0000\n",
      "Epoch 253/262\n",
      "15/15 - 0s - 9ms/step - loss: 4467511525376.0000\n",
      "Epoch 254/262\n",
      "15/15 - 0s - 9ms/step - loss: 4289381269504.0000\n",
      "Epoch 255/262\n",
      "15/15 - 0s - 9ms/step - loss: 4587841388544.0000\n",
      "Epoch 256/262\n",
      "15/15 - 0s - 9ms/step - loss: 4448674381824.0000\n",
      "Epoch 257/262\n",
      "15/15 - 0s - 9ms/step - loss: 4323154853888.0000\n",
      "Epoch 258/262\n",
      "15/15 - 0s - 11ms/step - loss: 4127675645952.0000\n",
      "Epoch 259/262\n",
      "15/15 - 0s - 8ms/step - loss: 4204414894080.0000\n",
      "Epoch 260/262\n",
      "15/15 - 0s - 10ms/step - loss: 4314646708224.0000\n",
      "Epoch 261/262\n",
      "15/15 - 0s - 8ms/step - loss: 4558615478272.0000\n",
      "Epoch 262/262\n",
      "15/15 - 0s - 9ms/step - loss: 4612427874304.0000\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', patience = int(patience), restore_best_weights = True)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, validation_split = .2, batch_size = batch_size, epochs = epochs, callbacks = es, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict(X_test_scaled)\n",
    "train_preds = model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 1278910.1811474678\n",
      "Test RMSE: 4978824.0827679485\n"
     ]
    }
   ],
   "source": [
    "train_rmse = mean_squared_error(y_train, train_preds)\n",
    "test_rmse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "print(f'Train RMSE: {np.sqrt(train_rmse)}')\n",
    "print(f'Test RMSE: {np.sqrt(test_rmse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:yellow\">Deep Neural Network</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(name = 'Dense1', units = 208, input_dim = X_train_scaled.shape[1], activation = 'relu'))\n",
    "model.add(Dropout(name = 'Dropout1', rate = 0.21597250932105788))\n",
    "model.add(Dense(name = 'Dense2', units = 97, activation = 'relu'))\n",
    "model.add(Dropout(name = 'Dropout2', rate = 0.21597250932105788))\n",
    "model.add(Dense(name = 'Dense3', units = 169, activation = 'relu'))\n",
    "model.add(Dropout(name = 'Dropout3', rate = 0.21597250932105788))\n",
    "\n",
    "model.add(Dense(name = 'Output', units = 1, activation = 'linear'))\n",
    "\n",
    "optimizer = Adam(learning_rate = 0.46150928437486555)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = 'mean_squared_error')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train, validation_split = .2, batch_size = 32, epochs = 50, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test_scaled)\n",
    "train_preds = model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = mean_squared_error(y_train, train_preds)\n",
    "test_rmse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "print(f'Train RMSE: {np.sqrt(train_rmse)}')\n",
    "print(f'Test RMSE: {np.sqrt(test_rmse)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
