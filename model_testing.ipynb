{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball = pd.read_csv('data/baseball.csv')\n",
    "baseball = baseball.drop(['Name', 'Age', 'Name-additional'], axis = 1)\n",
    "baseball['Salary'] = baseball['Salary'].str.replace('$', '').astype(float)\n",
    "\n",
    "baseball['C'] = baseball['Position'].apply(lambda x: 1 if 'C' in x else 0)\n",
    "baseball['1B'] = baseball['Position'].apply(lambda x: 1 if '1B' in x else 0)\n",
    "baseball['2B'] = baseball['Position'].apply(lambda x: 1 if '2B' in x else 0)\n",
    "baseball['3B'] = baseball['Position'].apply(lambda x: 1 if '3B' in x else 0)\n",
    "baseball['SS'] = baseball['Position'].apply(lambda x: 1 if 'SS' in x else 0)\n",
    "baseball['OF'] = baseball['Position'].apply(lambda x: 1 if 'OF' in x else 0)\n",
    "\n",
    "baseball['Num_Pos'] = baseball[['C', '1B', '2B', '3B', 'SS', 'OF']].sum(axis = 1)\n",
    "baseball = baseball.drop(['Position'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "# packages used in each section below\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "import shap\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = baseball.drop(['Salary'], axis = 1)\n",
    "y = baseball['Salary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['Tm', 'Lg', 'Acquired', 'Bat']\n",
    "num_columns = [col for col in X.columns if col not in cat_columns + ['C', '1B', '2B', '3B', 'SS', 'OF']]\n",
    "\n",
    "cat_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('scale', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, num_columns),\n",
    "        ('cat', cat_transformer, cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "X_transform = preprocessor.fit_transform(X)\n",
    "\n",
    "selected_features = np.concatenate([\n",
    "    np.array(num_columns),\n",
    "    np.array(preprocessor.transformers_[1][1]['onehot'].get_feature_names_out(cat_columns)),\n",
    "    np.array(['C', '1B', '2B', '3B', 'SS', 'OF'])\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=RandomForestRegressor(random_state=621))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=RandomForestRegressor(random_state=621))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=621)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=621)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=RandomForestRegressor(random_state=621))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_rf = RFE(estimator = RandomForestRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_rf.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA',\n",
       "       'WAA', 'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'CS',\n",
       "       'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'HBP',\n",
       "       'SH', 'SF', 'IBB', 'Num_Pos', 'Tm_LAA', 'Tm_LAD', 'Tm_MULTIPLE',\n",
       "       'Tm_NYM', 'Tm_NYY', 'Tm_SFG', 'Tm_STL', 'Acquired_Free Agency',\n",
       "       'Acquired_Traded'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features[rfe_rf.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'RAA', 'WAA', 'RAR',\n",
    "               'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'CS', 'BB', 'SO', 'BA', 'OBP',\n",
    "               'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB', 'Num_Pos', 'Season']\n",
    "red_cat_columns = ['Tm', 'Acquired']\n",
    "X_rf = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf_red_train, X_rf_red_test, y_rf_red_train, y_rf_red_test = train_test_split(X_rf, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "rf_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', RandomForestRegressor(n_estimators = 200, max_depth = 12, min_samples_split = 3))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Random Forest Metrics:\n",
      "Training RMSE: 2665873.0847510966\n",
      "Test RMSE: 5328864.974109751\n"
     ]
    }
   ],
   "source": [
    "rf_red_pipe.fit(X_rf_red_train, y_rf_red_train)\n",
    "rf_red_train_mse = mean_squared_error(y_rf_red_train, rf_red_pipe.predict(X_rf_red_train))\n",
    "rf_red_test_mse = mean_squared_error(y_rf_red_test, rf_red_pipe.predict(X_rf_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(rf_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(rf_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestRegressor(n_estimators = 200, min_samples_split = 14))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 2995640.073838007\n",
      "Test RMSE: 5339371.913062029\n"
     ]
    }
   ],
   "source": [
    "rf_pipe.fit(X_train, y_train)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pipe.predict(X_train))\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(rf_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(rf_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                           colsample_bylevel=None, colsample_bynode=None,\n",
       "                           colsample_bytree=None, early_stopping_rounds=None,\n",
       "                           enable_categorical=False, eval_metric=None,\n",
       "                           feature_types=None, gamma=None, gpu_id=None,\n",
       "                           grow_policy=None, importance_type=None,\n",
       "                           interaction_constraints=None, learning_rate=None,\n",
       "                           max_bin=None, max_cat_threshold=None,\n",
       "                           max_cat_to_onehot=None, max_delta_step=None,\n",
       "                           max_depth=None, max_leaves=None,\n",
       "                           min_child_weight=None, missing=nan,\n",
       "                           monotone_constraints=None, n_estimators=100,\n",
       "                           n_jobs=None, num_parallel_tree=None, predictor=None,\n",
       "                           random_state=621, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                           colsample_bylevel=None, colsample_bynode=None,\n",
       "                           colsample_bytree=None, early_stopping_rounds=None,\n",
       "                           enable_categorical=False, eval_metric=None,\n",
       "                           feature_types=None, gamma=None, gpu_id=None,\n",
       "                           grow_policy=None, importance_type=None,\n",
       "                           interaction_constraints=None, learning_rate=None,\n",
       "                           max_bin=None, max_cat_threshold=None,\n",
       "                           max_cat_to_onehot=None, max_delta_step=None,\n",
       "                           max_depth=None, max_leaves=None,\n",
       "                           min_child_weight=None, missing=nan,\n",
       "                           monotone_constraints=None, n_estimators=100,\n",
       "                           n_jobs=None, num_parallel_tree=None, predictor=None,\n",
       "                           random_state=621, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=621, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=621, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                           colsample_bylevel=None, colsample_bynode=None,\n",
       "                           colsample_bytree=None, early_stopping_rounds=None,\n",
       "                           enable_categorical=False, eval_metric=None,\n",
       "                           feature_types=None, gamma=None, gpu_id=None,\n",
       "                           grow_policy=None, importance_type=None,\n",
       "                           interaction_constraints=None, learning_rate=None,\n",
       "                           max_bin=None, max_cat_threshold=None,\n",
       "                           max_cat_to_onehot=None, max_delta_step=None,\n",
       "                           max_depth=None, max_leaves=None,\n",
       "                           min_child_weight=None, missing=nan,\n",
       "                           monotone_constraints=None, n_estimators=100,\n",
       "                           n_jobs=None, num_parallel_tree=None, predictor=None,\n",
       "                           random_state=621, ...))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_xg = RFE(estimator = XGBRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_xg.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Season', 'RBI', 'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS+',\n",
       "       'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB', 'Num_Pos', 'Tm_ARI',\n",
       "       'Tm_BOS', 'Tm_CHC', 'Tm_CIN', 'Tm_DET', 'Tm_HOU', 'Tm_KCR',\n",
       "       'Tm_LAA', 'Tm_LAD', 'Tm_MIA', 'Tm_MIN', 'Tm_MULTIPLE', 'Tm_NYM',\n",
       "       'Tm_NYY', 'Tm_OAK', 'Tm_PHI', 'Tm_STL', 'Tm_TBR', 'Tm_TEX',\n",
       "       'Acquired_Amateur Draft', 'Acquired_Amateur Free Agent',\n",
       "       'Acquired_Free Agency', 'Acquired_Traded', 'Bat_L', 'Bat_R', '1B',\n",
       "       '2B'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features[rfe_xg.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Season', 'RBI', 'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS+', \n",
    "                   'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB', 'Num_Pos']\n",
    "red_cat_columns = ['Tm', 'Acquired', 'Bat', 'C', '1B', '2B', '3B', 'SS', 'OF']\n",
    "X_xg = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xg_red_train, X_xg_red_test, y_xg_red_train, y_xg_red_test = train_test_split(X_xg, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "xg_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', XGBRegressor(n_estimators = 200, learning_rate = .06, max_depth = 5))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Random Forest Metrics:\n",
      "Training RMSE: 3174834.536729983\n",
      "Test RMSE: 5035866.184550909\n"
     ]
    }
   ],
   "source": [
    "xg_red_pipe.fit(X_xg_red_train, y_xg_red_train)\n",
    "xg_red_train_mse = mean_squared_error(y_xg_red_train, xg_red_pipe.predict(X_xg_red_train))\n",
    "xg_red_test_mse = mean_squared_error(y_xg_red_test, xg_red_pipe.predict(X_xg_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(xg_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(xg_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', XGBRegressor(n_estimators = 100, learning_rate = .03, max_depth = 6))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 3537922.5378611186\n",
      "Test RMSE: 5184611.048067813\n"
     ]
    }
   ],
   "source": [
    "xg_pipe.fit(X_train, y_train)\n",
    "xg_train_mse = mean_squared_error(y_train, xg_pipe.predict(X_train))\n",
    "xg_test_mse = mean_squared_error(y_test, xg_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(xg_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(xg_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=GradientBoostingRegressor(random_state=621))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=GradientBoostingRegressor(random_state=621))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=621)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=621)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=GradientBoostingRegressor(random_state=621))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_gb = RFE(estimator = GradientBoostingRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_gb.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA',\n",
       "       'WAA', 'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'CS',\n",
       "       'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'SH',\n",
       "       'SF', 'IBB', 'Num_Pos', 'Tm_LAA', 'Tm_LAD', 'Tm_MIN',\n",
       "       'Tm_MULTIPLE', 'Tm_NYY', 'Tm_OAK', 'Tm_STL',\n",
       "       'Acquired_Free Agency', 'Acquired_Traded', '2B'], dtype=object)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features[rfe_gb.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA',\n",
    "       'WAA', 'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'CS',\n",
    "       'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'SH',\n",
    "       'SF', 'IBB', 'Num_Pos']\n",
    "red_cat_columns = ['Tm', 'Acquired', 'C', '1B', '2B', '3B', 'SS', 'OF']\n",
    "X_gb = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gb_red_train, X_gb_red_test, y_gb_red_train, y_gb_red_test = train_test_split(X_gb, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "gb_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', GradientBoostingRegressor(learning_rate = 0.075, n_estimators = 200, max_depth = 4))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Random Forest Metrics:\n",
      "Training RMSE: 3426537.951924427\n",
      "Test RMSE: 5028275.917521109\n"
     ]
    }
   ],
   "source": [
    "gb_red_pipe.fit(X_gb_red_train, y_gb_red_train)\n",
    "gb_red_train_mse = mean_squared_error(y_gb_red_train, gb_red_pipe.predict(X_gb_red_train))\n",
    "gb_red_test_mse = mean_squared_error(y_gb_red_test, gb_red_pipe.predict(X_gb_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(gb_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(gb_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', GradientBoostingRegressor(learning_rate = 0.075, n_estimators = 200, max_depth = 4))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 3379850.3723368607\n",
      "Test RMSE: 5028062.821060685\n"
     ]
    }
   ],
   "source": [
    "gb_pipe.fit(X_train, y_train)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pipe.predict(X_train))\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(gb_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(gb_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADA Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=AdaBoostRegressor(random_state=621))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=AdaBoostRegressor(random_state=621))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(random_state=621)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(random_state=621)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=AdaBoostRegressor(random_state=621))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_ada = RFE(estimator = AdaBoostRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_ada.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA',\n",
       "       'WAA', 'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'CS', 'BB',\n",
       "       'SO', 'BA', 'OBP', 'SLG', 'OPS', 'OPS+', 'GDP', 'HBP', 'SH', 'SF',\n",
       "       'IBB', 'Num_Pos', 'Tm_CHC', 'Tm_COL', 'Tm_DET', 'Tm_HOU', 'Tm_LAA',\n",
       "       'Tm_NYM', 'Tm_NYY', 'Acquired_Free Agency', 'Bat_L', 'Bat_R', '2B'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features[rfe_ada.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA', 'WAA',\n",
    "       'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'CS', 'BB', 'SO', 'BA',\n",
    "       'OBP', 'SLG', 'OPS', 'OPS+', 'GDP', 'HBP', 'SH', 'SF', 'IBB',\n",
    "       'Num_Pos']\n",
    "red_cat_columns = ['Tm', 'Acquired', 'Bat', 'C', '1B', '2B', '3B', 'SS', 'OF']\n",
    "X_ada = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ada_red_train, X_ada_red_test, y_ada_red_train, y_ada_red_test = train_test_split(X_ada, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "ada_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', AdaBoostRegressor(n_estimators = 200, learning_rate = 0.01))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Random Forest Metrics:\n",
      "Training RMSE: 5358808.636299628\n",
      "Test RMSE: 5656509.686938622\n"
     ]
    }
   ],
   "source": [
    "ada_red_pipe.fit(X_ada_red_train, y_ada_red_train)\n",
    "ada_red_train_mse = mean_squared_error(y_ada_red_train, ada_red_pipe.predict(X_ada_red_train))\n",
    "ada_red_test_mse = mean_squared_error(y_ada_red_test, ada_red_pipe.predict(X_ada_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(ada_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(ada_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', PCA(n_components = 30)),\n",
    "        ('model', AdaBoostRegressor(n_estimators = 200, learning_rate = 0.01))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 5528645.110368226\n",
      "Test RMSE: 5866138.083422676\n"
     ]
    }
   ],
   "source": [
    "ada_pipe.fit(X_train, y_train)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pipe.predict(X_train))\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(ada_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(ada_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', SVC(C = 3))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 3305791.485725613\n",
      "Test RMSE: 6511994.651652397\n"
     ]
    }
   ],
   "source": [
    "svm_pipe.fit(X_train, y_train)\n",
    "svm_train_mse = mean_squared_error(y_train, svm_pipe.predict(X_train))\n",
    "svm_test_mse = mean_squared_error(y_test, svm_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(svm_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(svm_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', PCA(n_components = 63)),\n",
    "        ('model', KNeighborsRegressor(n_neighbors = 5, weights = 'uniform'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 4357478.9227963155\n",
      "Test RMSE: 5627354.873436867\n"
     ]
    }
   ],
   "source": [
    "knn_pipe.fit(X_train, y_train)\n",
    "knn_train_mse = mean_squared_error(y_train, knn_pipe.predict(X_train))\n",
    "knn_test_mse = mean_squared_error(y_test, knn_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(knn_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(knn_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 23:56:30.885077: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from bayes_opt import BayesianOptimization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.1\n",
    "scaling = 0.9\n",
    "shift = .2\n",
    "\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "X_train_aug = X_train_scaled + np.random.normal(scale = noise, size = X_train_scaled.shape)\n",
    "X_train_aug *= np.random.uniform(1 - scaling, 1 + scaling, size = X_train_scaled.shape)\n",
    "X_train_aug += np.random.uniform(-shift, shift, size = X_train_scaled.shape)\n",
    "\n",
    "X_train_comb = np.vstack((X_train_scaled, X_train_aug))\n",
    "y_train_comb = np.hstack((y_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | dropou... |  epochs   | layer_... | layer_... | layer_... | layer_... | layer_... | learni... |  neurons  | num_la... | patience  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-2.949e+1\u001b[0m | \u001b[0m207.3    \u001b[0m | \u001b[0m0.4754   \u001b[0m | \u001b[0m392.8    \u001b[0m | \u001b[0m166.1    \u001b[0m | \u001b[0m66.95    \u001b[0m | \u001b[0m66.94    \u001b[0m | \u001b[0m45.01    \u001b[0m | \u001b[0m226.0    \u001b[0m | \u001b[0m0.6051   \u001b[0m | \u001b[0m190.6    \u001b[0m | \u001b[0m1.082    \u001b[0m | \u001b[0m49.1     \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-2.681e+1\u001b[0m | \u001b[95m421.6    \u001b[0m | \u001b[95m0.1062   \u001b[0m | \u001b[95m172.7    \u001b[0m | \u001b[95m73.08    \u001b[0m | \u001b[95m100.2    \u001b[0m | \u001b[95m149.5    \u001b[0m | \u001b[95m128.8    \u001b[0m | \u001b[95m97.24    \u001b[0m | \u001b[95m0.6157   \u001b[0m | \u001b[95m63.25    \u001b[0m | \u001b[95m2.169    \u001b[0m | \u001b[95m30.99    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-2.933e+1\u001b[0m | \u001b[0m245.4    \u001b[0m | \u001b[0m0.3926   \u001b[0m | \u001b[0m179.9    \u001b[0m | \u001b[0m147.2    \u001b[0m | \u001b[0m164.7    \u001b[0m | \u001b[0m42.4     \u001b[0m | \u001b[0m168.1    \u001b[0m | \u001b[0m70.2     \u001b[0m | \u001b[0m0.0744   \u001b[0m | \u001b[0m244.6    \u001b[0m | \u001b[0m4.863    \u001b[0m | \u001b[0m44.25    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m-2.596e+1\u001b[0m | \u001b[95m174.6    \u001b[0m | \u001b[95m0.04884  \u001b[0m | \u001b[95m373.7    \u001b[0m | \u001b[95m130.6    \u001b[0m | \u001b[95m59.34    \u001b[0m | \u001b[95m142.9    \u001b[0m | \u001b[95m39.7     \u001b[0m | \u001b[95m235.7    \u001b[0m | \u001b[95m0.2662   \u001b[0m | \u001b[95m180.4    \u001b[0m | \u001b[95m2.247    \u001b[0m | \u001b[95m35.6     \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m-2.552e+1\u001b[0m | \u001b[95m287.9    \u001b[0m | \u001b[95m0.09243  \u001b[0m | \u001b[95m487.8    \u001b[0m | \u001b[95m205.6    \u001b[0m | \u001b[95m242.4    \u001b[0m | \u001b[95m232.4    \u001b[0m | \u001b[95m165.9    \u001b[0m | \u001b[95m238.5    \u001b[0m | \u001b[95m0.09761  \u001b[0m | \u001b[95m75.9     \u001b[0m | \u001b[95m1.181    \u001b[0m | \u001b[95m29.76    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-2.611e+1\u001b[0m | \u001b[0m259.3    \u001b[0m | \u001b[0m0.354    \u001b[0m | \u001b[0m263.0    \u001b[0m | \u001b[0m154.4    \u001b[0m | \u001b[0m218.6    \u001b[0m | \u001b[0m143.3    \u001b[0m | \u001b[0m158.1    \u001b[0m | \u001b[0m126.6    \u001b[0m | \u001b[0m0.1988   \u001b[0m | \u001b[0m250.1    \u001b[0m | \u001b[0m1.082    \u001b[0m | \u001b[0m23.73    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-2.752e+1\u001b[0m | \u001b[0m353.1    \u001b[0m | \u001b[0m0.3643   \u001b[0m | \u001b[0m410.4    \u001b[0m | \u001b[0m232.1    \u001b[0m | \u001b[0m166.2    \u001b[0m | \u001b[0m254.1    \u001b[0m | \u001b[0m59.43    \u001b[0m | \u001b[0m206.1    \u001b[0m | \u001b[0m0.06139  \u001b[0m | \u001b[0m62.54    \u001b[0m | \u001b[0m3.695    \u001b[0m | \u001b[0m35.34    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-6.934e+1\u001b[0m | \u001b[0m439.1    \u001b[0m | \u001b[0m0.3421   \u001b[0m | \u001b[0m194.0    \u001b[0m | \u001b[0m49.28    \u001b[0m | \u001b[0m243.3    \u001b[0m | \u001b[0m170.7    \u001b[0m | \u001b[0m131.0    \u001b[0m | \u001b[0m83.59    \u001b[0m | \u001b[0m0.1348   \u001b[0m | \u001b[0m86.74    \u001b[0m | \u001b[0m4.043    \u001b[0m | \u001b[0m20.82    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-2.884e+1\u001b[0m | \u001b[0m451.2    \u001b[0m | \u001b[0m0.05307  \u001b[0m | \u001b[0m186.9    \u001b[0m | \u001b[0m114.3    \u001b[0m | \u001b[0m94.19    \u001b[0m | \u001b[0m165.8    \u001b[0m | \u001b[0m54.16    \u001b[0m | \u001b[0m225.9    \u001b[0m | \u001b[0m0.5165   \u001b[0m | \u001b[0m36.21    \u001b[0m | \u001b[0m4.075    \u001b[0m | \u001b[0m36.53    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-2.642e+1\u001b[0m | \u001b[0m316.9    \u001b[0m | \u001b[0m0.2116   \u001b[0m | \u001b[0m453.4    \u001b[0m | \u001b[0m217.4    \u001b[0m | \u001b[0m208.6    \u001b[0m | \u001b[0m242.0    \u001b[0m | \u001b[0m118.6    \u001b[0m | \u001b[0m224.1    \u001b[0m | \u001b[0m0.0817   \u001b[0m | \u001b[0m69.98    \u001b[0m | \u001b[0m2.297    \u001b[0m | \u001b[0m32.24    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-2.621e+1\u001b[0m | \u001b[0m222.1    \u001b[0m | \u001b[0m0.03216  \u001b[0m | \u001b[0m381.2    \u001b[0m | \u001b[0m174.2    \u001b[0m | \u001b[0m175.0    \u001b[0m | \u001b[0m199.3    \u001b[0m | \u001b[0m132.4    \u001b[0m | \u001b[0m207.2    \u001b[0m | \u001b[0m0.1005   \u001b[0m | \u001b[0m172.6    \u001b[0m | \u001b[0m1.486    \u001b[0m | \u001b[0m26.43    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-6.933e+1\u001b[0m | \u001b[0m234.5    \u001b[0m | \u001b[0m0.2632   \u001b[0m | \u001b[0m344.6    \u001b[0m | \u001b[0m105.0    \u001b[0m | \u001b[0m249.8    \u001b[0m | \u001b[0m70.72    \u001b[0m | \u001b[0m197.2    \u001b[0m | \u001b[0m103.6    \u001b[0m | \u001b[0m0.148    \u001b[0m | \u001b[0m132.6    \u001b[0m | \u001b[0m4.014    \u001b[0m | \u001b[0m24.55    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-2.603e+1\u001b[0m | \u001b[0m248.7    \u001b[0m | \u001b[0m0.2003   \u001b[0m | \u001b[0m256.8    \u001b[0m | \u001b[0m195.5    \u001b[0m | \u001b[0m105.7    \u001b[0m | \u001b[0m191.1    \u001b[0m | \u001b[0m90.29    \u001b[0m | \u001b[0m189.6    \u001b[0m | \u001b[0m0.2684   \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m33.79    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-2.842e+1\u001b[0m | \u001b[0m422.3    \u001b[0m | \u001b[0m0.3801   \u001b[0m | \u001b[0m174.8    \u001b[0m | \u001b[0m77.66    \u001b[0m | \u001b[0m110.6    \u001b[0m | \u001b[0m149.9    \u001b[0m | \u001b[0m135.3    \u001b[0m | \u001b[0m109.6    \u001b[0m | \u001b[0m0.8784   \u001b[0m | \u001b[0m65.05    \u001b[0m | \u001b[0m2.342    \u001b[0m | \u001b[0m30.11    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-2.702e+1\u001b[0m | \u001b[0m347.6    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m100.0    \u001b[0m | \u001b[0m175.7    \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m134.8    \u001b[0m | \u001b[0m135.3    \u001b[0m | \u001b[0m134.7    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m103.3    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m50.0     \u001b[0m |\n",
      "=========================================================================================================================================================================\n",
      "Best Hyperparameters: {'batch_size': 287.8604107326549, 'dropout_rate': 0.09242722776276352, 'epochs': 487.83385110582344, 'layer_neurons_1': 205.62975243288966, 'layer_neurons_2': 242.44776291037837, 'layer_neurons_3': 232.44132649579333, 'layer_neurons_4': 165.92959525368306, 'layer_neurons_5': 238.49982864517818, 'learning_rate': 0.0976075770314003, 'neurons': 75.90016118188852, 'num_layers': 1.1809091556421523, 'patience': 29.759909922897933}\n"
     ]
    }
   ],
   "source": [
    "def dnn_model_score(neurons, dropout_rate, learning_rate, epochs, batch_size, patience, num_layers, **layer_neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(neurons), activation='relu', input_shape = (X_train_scaled.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    for i in range(1, int(num_layers) + 1):\n",
    "        model.add(Dense(int(layer_neurons[f'layer_neurons_{i}']), activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "    optimizer = Adam(learning_rate = learning_rate)\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "\n",
    "    es = EarlyStopping(monitor = 'val_loss', patience = int(patience), restore_best_weights = True)\n",
    "\n",
    "    model.fit(X_train_comb, y_train_comb, validation_split = .2, epochs = int(epochs), batch_size = int(batch_size), callbacks = es, verbose = 0)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return -mse\n",
    "\n",
    "pbounds = {'neurons': (32, 256),\n",
    "           'dropout_rate': (0.0, 0.5),\n",
    "           'learning_rate': (0.01, 1),\n",
    "           'epochs' : (100, 500),\n",
    "           'batch_size' : (32, 500),\n",
    "           'patience' : (20, 50),\n",
    "           'num_layers': (1, 5)}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    pbounds[f'layer_neurons_{i}'] = (32, 256)\n",
    "\n",
    "optimizer = BayesianOptimization(f = dnn_model_score, pbounds = pbounds, random_state = 42)\n",
    "\n",
    "optimizer.maximize(init_points = 5, n_iter = 10)\n",
    "\n",
    "best_params = optimizer.max['params']\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(best_params['batch_size'])\n",
    "dropout_rate = best_params['dropout_rate']\n",
    "epochs = int(best_params['epochs'])\n",
    "neurons = []\n",
    "neurons.append(int(best_params['neurons']))\n",
    "neurons.append(int(best_params['layer_neurons_1']))\n",
    "neurons.append(int(best_params['layer_neurons_2']))\n",
    "neurons.append(int(best_params['layer_neurons_3']))\n",
    "neurons.append(int(best_params['layer_neurons_4']))\n",
    "neurons.append(int(best_params['layer_neurons_5']))\n",
    "learning_rate = best_params['learning_rate']\n",
    "num_layers = int(best_params['num_layers'])\n",
    "patience = int(best_params['patience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">205</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,580</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">205</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">206</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m)             │         \u001b[38;5;34m6,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout1 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense2 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m205\u001b[0m)            │        \u001b[38;5;34m15,580\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout2 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m205\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m206\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,386</span> (87.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,386\u001b[0m (87.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,386</span> (87.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,386\u001b[0m (87.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(name = 'Dense1', units = neurons[0], input_dim = X_train_scaled.shape[1], activation = 'relu'))\n",
    "model.add(Dropout(name = 'Dropout1', rate = dropout_rate))\n",
    "\n",
    "for i in range(1, num_layers + 1):\n",
    "    model.add(Dense(name = f'Dense{i + 1}', units = neurons[i], activation = 'relu'))\n",
    "    model.add(Dropout(name = f'Dropout{i + 1}', rate = dropout_rate))\n",
    "\n",
    "model.add(Dense(name = 'Output', units = 1, activation = 'linear'))\n",
    "\n",
    "optimizer = Adam(learning_rate = learning_rate)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = 'mean_squared_error')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/487\n",
      "11/11 - 2s - 194ms/step - loss: 65617541464064.0000 - val_loss: 61464106762240.0000\n",
      "Epoch 2/487\n",
      "11/11 - 0s - 16ms/step - loss: 62748947906560.0000 - val_loss: 54243897638912.0000\n",
      "Epoch 3/487\n",
      "11/11 - 0s - 17ms/step - loss: 50985649045504.0000 - val_loss: 37272535695360.0000\n",
      "Epoch 4/487\n",
      "11/11 - 0s - 18ms/step - loss: 38402305032192.0000 - val_loss: 31758282129408.0000\n",
      "Epoch 5/487\n",
      "11/11 - 0s - 15ms/step - loss: 34544057057280.0000 - val_loss: 28183059496960.0000\n",
      "Epoch 6/487\n",
      "11/11 - 0s - 17ms/step - loss: 32093205692416.0000 - val_loss: 26492624961536.0000\n",
      "Epoch 7/487\n",
      "11/11 - 0s - 17ms/step - loss: 30406552322048.0000 - val_loss: 25403529887744.0000\n",
      "Epoch 8/487\n",
      "11/11 - 0s - 18ms/step - loss: 29246594482176.0000 - val_loss: 24403880443904.0000\n",
      "Epoch 9/487\n",
      "11/11 - 0s - 18ms/step - loss: 28240332718080.0000 - val_loss: 23625226780672.0000\n",
      "Epoch 10/487\n",
      "11/11 - 0s - 16ms/step - loss: 27447516987392.0000 - val_loss: 23094450192384.0000\n",
      "Epoch 11/487\n",
      "11/11 - 0s - 16ms/step - loss: 26915897344000.0000 - val_loss: 22690528231424.0000\n",
      "Epoch 12/487\n",
      "11/11 - 0s - 17ms/step - loss: 26280772763648.0000 - val_loss: 22276747558912.0000\n",
      "Epoch 13/487\n",
      "11/11 - 0s - 15ms/step - loss: 26041718407168.0000 - val_loss: 22087393607680.0000\n",
      "Epoch 14/487\n",
      "11/11 - 0s - 15ms/step - loss: 25937292820480.0000 - val_loss: 21956657152000.0000\n",
      "Epoch 15/487\n",
      "11/11 - 0s - 16ms/step - loss: 25777108156416.0000 - val_loss: 21824781942784.0000\n",
      "Epoch 16/487\n",
      "11/11 - 0s - 17ms/step - loss: 25504042188800.0000 - val_loss: 21615580545024.0000\n",
      "Epoch 17/487\n",
      "11/11 - 0s - 15ms/step - loss: 25302545727488.0000 - val_loss: 21454003372032.0000\n",
      "Epoch 18/487\n",
      "11/11 - 0s - 15ms/step - loss: 25228788891648.0000 - val_loss: 21780238434304.0000\n",
      "Epoch 19/487\n",
      "11/11 - 0s - 16ms/step - loss: 25067979276288.0000 - val_loss: 21396660944896.0000\n",
      "Epoch 20/487\n",
      "11/11 - 0s - 15ms/step - loss: 24737902231552.0000 - val_loss: 21562627457024.0000\n",
      "Epoch 21/487\n",
      "11/11 - 0s - 15ms/step - loss: 24629278146560.0000 - val_loss: 21208407998464.0000\n",
      "Epoch 22/487\n",
      "11/11 - 0s - 15ms/step - loss: 24767390285824.0000 - val_loss: 21330292375552.0000\n",
      "Epoch 23/487\n",
      "11/11 - 0s - 16ms/step - loss: 24626491031552.0000 - val_loss: 21197704134656.0000\n",
      "Epoch 24/487\n",
      "11/11 - 0s - 15ms/step - loss: 24518349291520.0000 - val_loss: 21058996404224.0000\n",
      "Epoch 25/487\n",
      "11/11 - 0s - 14ms/step - loss: 24298316103680.0000 - val_loss: 21107484655616.0000\n",
      "Epoch 26/487\n",
      "11/11 - 0s - 14ms/step - loss: 24380853714944.0000 - val_loss: 20980252540928.0000\n",
      "Epoch 27/487\n",
      "11/11 - 0s - 15ms/step - loss: 24098998583296.0000 - val_loss: 21130528161792.0000\n",
      "Epoch 28/487\n",
      "11/11 - 0s - 14ms/step - loss: 24223768641536.0000 - val_loss: 21041657151488.0000\n",
      "Epoch 29/487\n",
      "11/11 - 0s - 23ms/step - loss: 24020502183936.0000 - val_loss: 20885939421184.0000\n",
      "Epoch 30/487\n",
      "11/11 - 0s - 25ms/step - loss: 23895260266496.0000 - val_loss: 20826543882240.0000\n",
      "Epoch 31/487\n",
      "11/11 - 0s - 15ms/step - loss: 23839243239424.0000 - val_loss: 20790038757376.0000\n",
      "Epoch 32/487\n",
      "11/11 - 0s - 14ms/step - loss: 23823493627904.0000 - val_loss: 21105850974208.0000\n",
      "Epoch 33/487\n",
      "11/11 - 0s - 16ms/step - loss: 23662264582144.0000 - val_loss: 20681074933760.0000\n",
      "Epoch 34/487\n",
      "11/11 - 0s - 16ms/step - loss: 23461481152512.0000 - val_loss: 21072017620992.0000\n",
      "Epoch 35/487\n",
      "11/11 - 0s - 14ms/step - loss: 23605333196800.0000 - val_loss: 20603037810688.0000\n",
      "Epoch 36/487\n",
      "11/11 - 0s - 15ms/step - loss: 23262950064128.0000 - val_loss: 20727195500544.0000\n",
      "Epoch 37/487\n",
      "11/11 - 0s - 16ms/step - loss: 23205941084160.0000 - val_loss: 20628155400192.0000\n",
      "Epoch 38/487\n",
      "11/11 - 0s - 15ms/step - loss: 23067761836032.0000 - val_loss: 20517746638848.0000\n",
      "Epoch 39/487\n",
      "11/11 - 0s - 16ms/step - loss: 22979727589376.0000 - val_loss: 20726790750208.0000\n",
      "Epoch 40/487\n",
      "11/11 - 0s - 15ms/step - loss: 23071714967552.0000 - val_loss: 20485026873344.0000\n",
      "Epoch 41/487\n",
      "11/11 - 0s - 15ms/step - loss: 22701815103488.0000 - val_loss: 20353451556864.0000\n",
      "Epoch 42/487\n",
      "11/11 - 0s - 15ms/step - loss: 22855865597952.0000 - val_loss: 20943067938816.0000\n",
      "Epoch 43/487\n",
      "11/11 - 0s - 15ms/step - loss: 22742248194048.0000 - val_loss: 20342602989568.0000\n",
      "Epoch 44/487\n",
      "11/11 - 0s - 15ms/step - loss: 22420844969984.0000 - val_loss: 20310975840256.0000\n",
      "Epoch 45/487\n",
      "11/11 - 0s - 17ms/step - loss: 22498257141760.0000 - val_loss: 20569565167616.0000\n",
      "Epoch 46/487\n",
      "11/11 - 0s - 15ms/step - loss: 22283512971264.0000 - val_loss: 20147794345984.0000\n",
      "Epoch 47/487\n",
      "11/11 - 0s - 16ms/step - loss: 22196602798080.0000 - val_loss: 20263576010752.0000\n",
      "Epoch 48/487\n",
      "11/11 - 0s - 14ms/step - loss: 22174966480896.0000 - val_loss: 20203821858816.0000\n",
      "Epoch 49/487\n",
      "11/11 - 0s - 15ms/step - loss: 22060805914624.0000 - val_loss: 20296453062656.0000\n",
      "Epoch 50/487\n",
      "11/11 - 0s - 15ms/step - loss: 21556946272256.0000 - val_loss: 20225653211136.0000\n",
      "Epoch 51/487\n",
      "11/11 - 0s - 16ms/step - loss: 21744869965824.0000 - val_loss: 20174132477952.0000\n",
      "Epoch 52/487\n",
      "11/11 - 0s - 15ms/step - loss: 21880926896128.0000 - val_loss: 20102948847616.0000\n",
      "Epoch 53/487\n",
      "11/11 - 0s - 15ms/step - loss: 21638546456576.0000 - val_loss: 20251961982976.0000\n",
      "Epoch 54/487\n",
      "11/11 - 0s - 16ms/step - loss: 21374259167232.0000 - val_loss: 19979701321728.0000\n",
      "Epoch 55/487\n",
      "11/11 - 0s - 15ms/step - loss: 21285159567360.0000 - val_loss: 20043685429248.0000\n",
      "Epoch 56/487\n",
      "11/11 - 0s - 16ms/step - loss: 21336833392640.0000 - val_loss: 19849497542656.0000\n",
      "Epoch 57/487\n",
      "11/11 - 0s - 14ms/step - loss: 21056500793344.0000 - val_loss: 19890612207616.0000\n",
      "Epoch 58/487\n",
      "11/11 - 0s - 14ms/step - loss: 21148114878464.0000 - val_loss: 20156914860032.0000\n",
      "Epoch 59/487\n",
      "11/11 - 0s - 14ms/step - loss: 21061582192640.0000 - val_loss: 20024366465024.0000\n",
      "Epoch 60/487\n",
      "11/11 - 0s - 14ms/step - loss: 20722724372480.0000 - val_loss: 19827819282432.0000\n",
      "Epoch 61/487\n",
      "11/11 - 0s - 14ms/step - loss: 21020085846016.0000 - val_loss: 19821255196672.0000\n",
      "Epoch 62/487\n",
      "11/11 - 0s - 15ms/step - loss: 20683065131008.0000 - val_loss: 20048680845312.0000\n",
      "Epoch 63/487\n",
      "11/11 - 0s - 14ms/step - loss: 20537839452160.0000 - val_loss: 19852423069696.0000\n",
      "Epoch 64/487\n",
      "11/11 - 0s - 16ms/step - loss: 20725899460608.0000 - val_loss: 20115363987456.0000\n",
      "Epoch 65/487\n",
      "11/11 - 0s - 14ms/step - loss: 20426740727808.0000 - val_loss: 19733797666816.0000\n",
      "Epoch 66/487\n",
      "11/11 - 0s - 22ms/step - loss: 20686982610944.0000 - val_loss: 19792425648128.0000\n",
      "Epoch 67/487\n",
      "11/11 - 0s - 14ms/step - loss: 20179826245632.0000 - val_loss: 19550454153216.0000\n",
      "Epoch 68/487\n",
      "11/11 - 0s - 13ms/step - loss: 20004189765632.0000 - val_loss: 19654172999680.0000\n",
      "Epoch 69/487\n",
      "11/11 - 0s - 14ms/step - loss: 19888500375552.0000 - val_loss: 19896901566464.0000\n",
      "Epoch 70/487\n",
      "11/11 - 0s - 14ms/step - loss: 20031345786880.0000 - val_loss: 19697303027712.0000\n",
      "Epoch 71/487\n",
      "11/11 - 0s - 14ms/step - loss: 19969215561728.0000 - val_loss: 20008077885440.0000\n",
      "Epoch 72/487\n",
      "11/11 - 0s - 14ms/step - loss: 19920762961920.0000 - val_loss: 19494084804608.0000\n",
      "Epoch 73/487\n",
      "11/11 - 0s - 14ms/step - loss: 19698978652160.0000 - val_loss: 19612880076800.0000\n",
      "Epoch 74/487\n",
      "11/11 - 0s - 13ms/step - loss: 19445500084224.0000 - val_loss: 19674337116160.0000\n",
      "Epoch 75/487\n",
      "11/11 - 0s - 14ms/step - loss: 19428586553344.0000 - val_loss: 19461276958720.0000\n",
      "Epoch 76/487\n",
      "11/11 - 0s - 16ms/step - loss: 19299288743936.0000 - val_loss: 19724339511296.0000\n",
      "Epoch 77/487\n",
      "11/11 - 0s - 14ms/step - loss: 19576567889920.0000 - val_loss: 19536778625024.0000\n",
      "Epoch 78/487\n",
      "11/11 - 0s - 14ms/step - loss: 19568925868032.0000 - val_loss: 19731492896768.0000\n",
      "Epoch 79/487\n",
      "11/11 - 0s - 14ms/step - loss: 19399075430400.0000 - val_loss: 19366127075328.0000\n",
      "Epoch 80/487\n",
      "11/11 - 0s - 14ms/step - loss: 19055081684992.0000 - val_loss: 19410391662592.0000\n",
      "Epoch 81/487\n",
      "11/11 - 0s - 13ms/step - loss: 18773394325504.0000 - val_loss: 19545351782400.0000\n",
      "Epoch 82/487\n",
      "11/11 - 0s - 14ms/step - loss: 18647105929216.0000 - val_loss: 19550886166528.0000\n",
      "Epoch 83/487\n",
      "11/11 - 0s - 13ms/step - loss: 18770164711424.0000 - val_loss: 19200370278400.0000\n",
      "Epoch 84/487\n",
      "11/11 - 0s - 14ms/step - loss: 18683749466112.0000 - val_loss: 19418786562048.0000\n",
      "Epoch 85/487\n",
      "11/11 - 0s - 14ms/step - loss: 18353940856832.0000 - val_loss: 20118006398976.0000\n",
      "Epoch 86/487\n",
      "11/11 - 0s - 14ms/step - loss: 18618219757568.0000 - val_loss: 19645924900864.0000\n",
      "Epoch 87/487\n",
      "11/11 - 0s - 14ms/step - loss: 18307067412480.0000 - val_loss: 19452569583616.0000\n",
      "Epoch 88/487\n",
      "11/11 - 0s - 15ms/step - loss: 18054266224640.0000 - val_loss: 19220247085056.0000\n",
      "Epoch 89/487\n",
      "11/11 - 0s - 14ms/step - loss: 18082886057984.0000 - val_loss: 19273959342080.0000\n",
      "Epoch 90/487\n",
      "11/11 - 0s - 14ms/step - loss: 17930376970240.0000 - val_loss: 19020543688704.0000\n",
      "Epoch 91/487\n",
      "11/11 - 0s - 14ms/step - loss: 17822820335616.0000 - val_loss: 19102124998656.0000\n",
      "Epoch 92/487\n",
      "11/11 - 0s - 14ms/step - loss: 17721179766784.0000 - val_loss: 19061966635008.0000\n",
      "Epoch 93/487\n",
      "11/11 - 0s - 15ms/step - loss: 17463988191232.0000 - val_loss: 19043830464512.0000\n",
      "Epoch 94/487\n",
      "11/11 - 0s - 15ms/step - loss: 17416795979776.0000 - val_loss: 19042777694208.0000\n",
      "Epoch 95/487\n",
      "11/11 - 0s - 14ms/step - loss: 17571777609728.0000 - val_loss: 18989356941312.0000\n",
      "Epoch 96/487\n",
      "11/11 - 0s - 14ms/step - loss: 17297668308992.0000 - val_loss: 19048676982784.0000\n",
      "Epoch 97/487\n",
      "11/11 - 0s - 14ms/step - loss: 17111622615040.0000 - val_loss: 18992477503488.0000\n",
      "Epoch 98/487\n",
      "11/11 - 0s - 14ms/step - loss: 17007423520768.0000 - val_loss: 19099853783040.0000\n",
      "Epoch 99/487\n",
      "11/11 - 0s - 14ms/step - loss: 17170852478976.0000 - val_loss: 18967877910528.0000\n",
      "Epoch 100/487\n",
      "11/11 - 0s - 15ms/step - loss: 16647430602752.0000 - val_loss: 19017253257216.0000\n",
      "Epoch 101/487\n",
      "11/11 - 0s - 15ms/step - loss: 16727957045248.0000 - val_loss: 18768814145536.0000\n",
      "Epoch 102/487\n",
      "11/11 - 0s - 23ms/step - loss: 16437183774720.0000 - val_loss: 18735431680000.0000\n",
      "Epoch 103/487\n",
      "11/11 - 0s - 16ms/step - loss: 16215676289024.0000 - val_loss: 19089745510400.0000\n",
      "Epoch 104/487\n",
      "11/11 - 0s - 15ms/step - loss: 16699788099584.0000 - val_loss: 18572986286080.0000\n",
      "Epoch 105/487\n",
      "11/11 - 0s - 16ms/step - loss: 16223970525184.0000 - val_loss: 18792788787200.0000\n",
      "Epoch 106/487\n",
      "11/11 - 0s - 15ms/step - loss: 16695416586240.0000 - val_loss: 18729438019584.0000\n",
      "Epoch 107/487\n",
      "11/11 - 0s - 15ms/step - loss: 15930551697408.0000 - val_loss: 18707147390976.0000\n",
      "Epoch 108/487\n",
      "11/11 - 0s - 17ms/step - loss: 16176582230016.0000 - val_loss: 18462766268416.0000\n",
      "Epoch 109/487\n",
      "11/11 - 0s - 16ms/step - loss: 16054726164480.0000 - val_loss: 18652577398784.0000\n",
      "Epoch 110/487\n",
      "11/11 - 0s - 15ms/step - loss: 15787193532416.0000 - val_loss: 18439288651776.0000\n",
      "Epoch 111/487\n",
      "11/11 - 0s - 21ms/step - loss: 15577450020864.0000 - val_loss: 18473610641408.0000\n",
      "Epoch 112/487\n",
      "11/11 - 0s - 18ms/step - loss: 15436627312640.0000 - val_loss: 18327237820416.0000\n",
      "Epoch 113/487\n",
      "11/11 - 0s - 19ms/step - loss: 15314140004352.0000 - val_loss: 18541463994368.0000\n",
      "Epoch 114/487\n",
      "11/11 - 0s - 24ms/step - loss: 15309719207936.0000 - val_loss: 18358726557696.0000\n",
      "Epoch 115/487\n",
      "11/11 - 0s - 27ms/step - loss: 15148216483840.0000 - val_loss: 18553463898112.0000\n",
      "Epoch 116/487\n",
      "11/11 - 0s - 17ms/step - loss: 15586550611968.0000 - val_loss: 18856902918144.0000\n",
      "Epoch 117/487\n",
      "11/11 - 0s - 17ms/step - loss: 15247750463488.0000 - val_loss: 18525987012608.0000\n",
      "Epoch 118/487\n",
      "11/11 - 0s - 17ms/step - loss: 14711192027136.0000 - val_loss: 18303804243968.0000\n",
      "Epoch 119/487\n",
      "11/11 - 0s - 17ms/step - loss: 14736970219520.0000 - val_loss: 18732227231744.0000\n",
      "Epoch 120/487\n",
      "11/11 - 0s - 17ms/step - loss: 14602231349248.0000 - val_loss: 18334793859072.0000\n",
      "Epoch 121/487\n",
      "11/11 - 0s - 16ms/step - loss: 14614727229440.0000 - val_loss: 18342263914496.0000\n",
      "Epoch 122/487\n",
      "11/11 - 0s - 15ms/step - loss: 14321830592512.0000 - val_loss: 18379479973888.0000\n",
      "Epoch 123/487\n",
      "11/11 - 0s - 15ms/step - loss: 14261374943232.0000 - val_loss: 18368541229056.0000\n",
      "Epoch 124/487\n",
      "11/11 - 0s - 15ms/step - loss: 14128055844864.0000 - val_loss: 18377680617472.0000\n",
      "Epoch 125/487\n",
      "11/11 - 0s - 15ms/step - loss: 13719602987008.0000 - val_loss: 18386174083072.0000\n",
      "Epoch 126/487\n",
      "11/11 - 0s - 27ms/step - loss: 13920150487040.0000 - val_loss: 18506355572736.0000\n",
      "Epoch 127/487\n",
      "11/11 - 0s - 15ms/step - loss: 14020682711040.0000 - val_loss: 18342756745216.0000\n",
      "Epoch 128/487\n",
      "11/11 - 0s - 14ms/step - loss: 13494662463488.0000 - val_loss: 18306352283648.0000\n",
      "Epoch 129/487\n",
      "11/11 - 0s - 14ms/step - loss: 13610460905472.0000 - val_loss: 18461575086080.0000\n",
      "Epoch 130/487\n",
      "11/11 - 0s - 15ms/step - loss: 13438648582144.0000 - val_loss: 18365078831104.0000\n",
      "Epoch 131/487\n",
      "11/11 - 0s - 14ms/step - loss: 13364143063040.0000 - val_loss: 18659210690560.0000\n",
      "Epoch 132/487\n",
      "11/11 - 0s - 15ms/step - loss: 13231043117056.0000 - val_loss: 18247099351040.0000\n",
      "Epoch 133/487\n",
      "11/11 - 0s - 14ms/step - loss: 12866453241856.0000 - val_loss: 18463944867840.0000\n",
      "Epoch 134/487\n",
      "11/11 - 0s - 14ms/step - loss: 12926790402048.0000 - val_loss: 18205642850304.0000\n",
      "Epoch 135/487\n",
      "11/11 - 0s - 15ms/step - loss: 13362867994624.0000 - val_loss: 18586512916480.0000\n",
      "Epoch 136/487\n",
      "11/11 - 0s - 15ms/step - loss: 12972998000640.0000 - val_loss: 18157303496704.0000\n",
      "Epoch 137/487\n",
      "11/11 - 0s - 14ms/step - loss: 12747688378368.0000 - val_loss: 18798826487808.0000\n",
      "Epoch 138/487\n",
      "11/11 - 0s - 14ms/step - loss: 12727061839872.0000 - val_loss: 18167099293696.0000\n",
      "Epoch 139/487\n",
      "11/11 - 0s - 14ms/step - loss: 12272939302912.0000 - val_loss: 18563414884352.0000\n",
      "Epoch 140/487\n",
      "11/11 - 0s - 15ms/step - loss: 12512833568768.0000 - val_loss: 18455755489280.0000\n",
      "Epoch 141/487\n",
      "11/11 - 0s - 15ms/step - loss: 12082481201152.0000 - val_loss: 18152979169280.0000\n",
      "Epoch 142/487\n",
      "11/11 - 0s - 14ms/step - loss: 12349547216896.0000 - val_loss: 18230963863552.0000\n",
      "Epoch 143/487\n",
      "11/11 - 0s - 15ms/step - loss: 11940637179904.0000 - val_loss: 18046534025216.0000\n",
      "Epoch 144/487\n",
      "11/11 - 0s - 18ms/step - loss: 12289186988032.0000 - val_loss: 18320059269120.0000\n",
      "Epoch 145/487\n",
      "11/11 - 0s - 15ms/step - loss: 11791987900416.0000 - val_loss: 17991609614336.0000\n",
      "Epoch 146/487\n",
      "11/11 - 0s - 14ms/step - loss: 11673216745472.0000 - val_loss: 18354079268864.0000\n",
      "Epoch 147/487\n",
      "11/11 - 0s - 15ms/step - loss: 11441726816256.0000 - val_loss: 18560705363968.0000\n",
      "Epoch 148/487\n",
      "11/11 - 0s - 15ms/step - loss: 12156005253120.0000 - val_loss: 18180110024704.0000\n",
      "Epoch 149/487\n",
      "11/11 - 0s - 15ms/step - loss: 11364921769984.0000 - val_loss: 18113917616128.0000\n",
      "Epoch 150/487\n",
      "11/11 - 0s - 16ms/step - loss: 11251846479872.0000 - val_loss: 18041834307584.0000\n",
      "Epoch 151/487\n",
      "11/11 - 0s - 15ms/step - loss: 10941624221696.0000 - val_loss: 18103507353600.0000\n",
      "Epoch 152/487\n",
      "11/11 - 0s - 15ms/step - loss: 11030848602112.0000 - val_loss: 18026682384384.0000\n",
      "Epoch 153/487\n",
      "11/11 - 0s - 14ms/step - loss: 11495503036416.0000 - val_loss: 18064865230848.0000\n",
      "Epoch 154/487\n",
      "11/11 - 0s - 15ms/step - loss: 10692680744960.0000 - val_loss: 18050361327616.0000\n",
      "Epoch 155/487\n",
      "11/11 - 0s - 15ms/step - loss: 10886305546240.0000 - val_loss: 18111614943232.0000\n",
      "Epoch 156/487\n",
      "11/11 - 0s - 15ms/step - loss: 10874342342656.0000 - val_loss: 17945008799744.0000\n",
      "Epoch 157/487\n",
      "11/11 - 0s - 15ms/step - loss: 10866251530240.0000 - val_loss: 18221927235584.0000\n",
      "Epoch 158/487\n",
      "11/11 - 0s - 15ms/step - loss: 10471224639488.0000 - val_loss: 18096777592832.0000\n",
      "Epoch 159/487\n",
      "11/11 - 0s - 15ms/step - loss: 10357579972608.0000 - val_loss: 18790683246592.0000\n",
      "Epoch 160/487\n",
      "11/11 - 0s - 14ms/step - loss: 10370801467392.0000 - val_loss: 18404597563392.0000\n",
      "Epoch 161/487\n",
      "11/11 - 0s - 15ms/step - loss: 10527254249472.0000 - val_loss: 18411623022592.0000\n",
      "Epoch 162/487\n",
      "11/11 - 0s - 14ms/step - loss: 10256593715200.0000 - val_loss: 17818458259456.0000\n",
      "Epoch 163/487\n",
      "11/11 - 0s - 15ms/step - loss: 10208707346432.0000 - val_loss: 18230143877120.0000\n",
      "Epoch 164/487\n",
      "11/11 - 0s - 14ms/step - loss: 10046952964096.0000 - val_loss: 18314359209984.0000\n",
      "Epoch 165/487\n",
      "11/11 - 0s - 14ms/step - loss: 9626940604416.0000 - val_loss: 17957409259520.0000\n",
      "Epoch 166/487\n",
      "11/11 - 0s - 25ms/step - loss: 10055141294080.0000 - val_loss: 17962704568320.0000\n",
      "Epoch 167/487\n",
      "11/11 - 0s - 15ms/step - loss: 9640793341952.0000 - val_loss: 18198990684160.0000\n",
      "Epoch 168/487\n",
      "11/11 - 0s - 15ms/step - loss: 10051046604800.0000 - val_loss: 18226490638336.0000\n",
      "Epoch 169/487\n",
      "11/11 - 0s - 14ms/step - loss: 9442499231744.0000 - val_loss: 18512307290112.0000\n",
      "Epoch 170/487\n",
      "11/11 - 0s - 14ms/step - loss: 9567599591424.0000 - val_loss: 18214528483328.0000\n",
      "Epoch 171/487\n",
      "11/11 - 0s - 15ms/step - loss: 9838751907840.0000 - val_loss: 20183567564800.0000\n",
      "Epoch 172/487\n",
      "11/11 - 0s - 15ms/step - loss: 9776696131584.0000 - val_loss: 18455497539584.0000\n",
      "Epoch 173/487\n",
      "11/11 - 0s - 14ms/step - loss: 9294856585216.0000 - val_loss: 18620977512448.0000\n",
      "Epoch 174/487\n",
      "11/11 - 0s - 15ms/step - loss: 9461422882816.0000 - val_loss: 18601645965312.0000\n",
      "Epoch 175/487\n",
      "11/11 - 0s - 14ms/step - loss: 9233338728448.0000 - val_loss: 18451095617536.0000\n",
      "Epoch 176/487\n",
      "11/11 - 0s - 14ms/step - loss: 8911070429184.0000 - val_loss: 18502085771264.0000\n",
      "Epoch 177/487\n",
      "11/11 - 0s - 17ms/step - loss: 8656596238336.0000 - val_loss: 18250693869568.0000\n",
      "Epoch 178/487\n",
      "11/11 - 0s - 15ms/step - loss: 8740509581312.0000 - val_loss: 18123306565632.0000\n",
      "Epoch 179/487\n",
      "11/11 - 0s - 15ms/step - loss: 8919209476096.0000 - val_loss: 18697020243968.0000\n",
      "Epoch 180/487\n",
      "11/11 - 0s - 15ms/step - loss: 9230253817856.0000 - val_loss: 18235709718528.0000\n",
      "Epoch 181/487\n",
      "11/11 - 0s - 14ms/step - loss: 8760879742976.0000 - val_loss: 18320866672640.0000\n",
      "Epoch 182/487\n",
      "11/11 - 0s - 14ms/step - loss: 8774640730112.0000 - val_loss: 18631874314240.0000\n",
      "Epoch 183/487\n",
      "11/11 - 0s - 15ms/step - loss: 8694095937536.0000 - val_loss: 18285112328192.0000\n",
      "Epoch 184/487\n",
      "11/11 - 0s - 14ms/step - loss: 8580393074688.0000 - val_loss: 18105149423616.0000\n",
      "Epoch 185/487\n",
      "11/11 - 0s - 15ms/step - loss: 8419267837952.0000 - val_loss: 18469856739328.0000\n",
      "Epoch 186/487\n",
      "11/11 - 0s - 15ms/step - loss: 8450688417792.0000 - val_loss: 18830652866560.0000\n",
      "Epoch 187/487\n",
      "11/11 - 0s - 14ms/step - loss: 8292660150272.0000 - val_loss: 18769621549056.0000\n",
      "Epoch 188/487\n",
      "11/11 - 0s - 15ms/step - loss: 8365150306304.0000 - val_loss: 18825152036864.0000\n",
      "Epoch 189/487\n",
      "11/11 - 0s - 14ms/step - loss: 8322282422272.0000 - val_loss: 18302457872384.0000\n",
      "Epoch 190/487\n",
      "11/11 - 0s - 14ms/step - loss: 8008497102848.0000 - val_loss: 18628099440640.0000\n",
      "Epoch 191/487\n",
      "11/11 - 0s - 17ms/step - loss: 7954081251328.0000 - val_loss: 18692110811136.0000\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', patience = int(patience), restore_best_weights = True)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, validation_split = .2, batch_size = batch_size, epochs = epochs, callbacks = es, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict(X_test_scaled)\n",
    "train_preds = model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 3239015.80199959\n",
      "Test RMSE: 4964849.974897946\n"
     ]
    }
   ],
   "source": [
    "train_rmse = mean_squared_error(y_train, train_preds)\n",
    "test_rmse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "print(f'Train RMSE: {np.sqrt(train_rmse)}')\n",
    "print(f'Test RMSE: {np.sqrt(test_rmse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dnn/dnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dnn/model_weights.joblib']"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "\n",
    "with open('dnn/model_architecture.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "joblib.dump(model.get_weights(), 'dnn/model_weights.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "with  open('dnn/model_architecture.json', 'r') as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "loaded_model.set_weights(joblib.load('dnn/model_weights.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Train RMSE: 3239015.80199959\n",
      "Test RMSE: 4964849.974897946\n"
     ]
    }
   ],
   "source": [
    "test_preds = loaded_model.predict(X_test_scaled)\n",
    "train_preds = loaded_model.predict(X_train_scaled)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train, train_preds)\n",
    "test_rmse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "print(f'Train RMSE: {np.sqrt(train_rmse)}')\n",
    "print(f'Test RMSE: {np.sqrt(test_rmse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('testing.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = tf.keras.models.load_model('testing.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Train RMSE: 3239015.80199959\n",
      "Test RMSE: 4964849.974897946\n"
     ]
    }
   ],
   "source": [
    "test_preds = load.predict(X_test_scaled)\n",
    "train_preds = load.predict(X_train_scaled)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train, train_preds)\n",
    "test_rmse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "print(f'Train RMSE: {np.sqrt(train_rmse)}')\n",
    "print(f'Test RMSE: {np.sqrt(test_rmse)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
