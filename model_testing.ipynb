{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball = pd.read_csv('data/baseball.csv')\n",
    "baseball = baseball.drop(['Name', 'Age', 'Name-additional'], axis = 1)\n",
    "baseball['Salary'] = baseball['Salary'].str.replace('$', '').astype(float)\n",
    "\n",
    "baseball['C'] = baseball['Position'].apply(lambda x: 1 if 'C' in x else 0)\n",
    "baseball['1B'] = baseball['Position'].apply(lambda x: 1 if '1B' in x else 0)\n",
    "baseball['2B'] = baseball['Position'].apply(lambda x: 1 if '2B' in x else 0)\n",
    "baseball['3B'] = baseball['Position'].apply(lambda x: 1 if '3B' in x else 0)\n",
    "baseball['SS'] = baseball['Position'].apply(lambda x: 1 if 'SS' in x else 0)\n",
    "baseball['OF'] = baseball['Position'].apply(lambda x: 1 if 'OF' in x else 0)\n",
    "\n",
    "baseball['Num_Pos'] = baseball[['C', '1B', '2B', '3B', 'SS', 'OF']].sum(axis = 1)\n",
    "baseball = baseball.drop(['Position'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "# packages used in each section below\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "import shap\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = baseball.drop(['Salary'], axis = 1)\n",
    "y = baseball['Salary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['Tm', 'Lg', 'Acquired', 'Bat']\n",
    "num_columns = [col for col in X.columns if col not in cat_columns + ['C', '1B', '2B', '3B', 'SS', 'OF']]\n",
    "\n",
    "cat_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('scale', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, num_columns),\n",
    "        ('cat', cat_transformer, cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "X_transform = preprocessor.fit_transform(X)\n",
    "\n",
    "selected_features = np.concatenate([\n",
    "    np.array(num_columns),\n",
    "    np.array(preprocessor.transformers_[1][1]['onehot'].get_feature_names_out(cat_columns)),\n",
    "    np.array(['C', '1B', '2B', '3B', 'SS', 'OF'])\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_rf = RFE(estimator = RandomForestRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_rf.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[rfe_rf.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'RAA', 'WAA', 'RAR',\n",
    "               'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'CS', 'BB', 'SO', 'BA', 'OBP',\n",
    "               'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB', 'Num_Pos', 'Season']\n",
    "red_cat_columns = ['Tm', 'Acquired']\n",
    "X_rf = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf_red_train, X_rf_red_test, y_rf_red_train, y_rf_red_test = train_test_split(X_rf, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "rf_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', RandomForestRegressor(n_estimators = 150, min_samples_leaf = 10))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_red_pipe.fit(X_rf_red_train, y_rf_red_train)\n",
    "rf_red_train_mse = mean_squared_error(y_rf_red_train, rf_red_pipe.predict(X_rf_red_train))\n",
    "rf_red_test_mse = mean_squared_error(y_rf_red_test, rf_red_pipe.predict(X_rf_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(rf_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(rf_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestRegressor(n_estimators = 150, min_samples_leaf = 10))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe.fit(X_train, y_train)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pipe.predict(X_train))\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(rf_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(rf_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_xg = RFE(estimator = XGBRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_xg.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[rfe_xg.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Season', 'RBI', 'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS+', \n",
    "                   'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB', 'Num_Pos']\n",
    "red_cat_columns = ['Tm', 'Acquired', 'Bat', 'C', '1B', '2B', '3B', 'SS', 'OF']\n",
    "X_xg = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xg_red_train, X_xg_red_test, y_xg_red_train, y_xg_red_test = train_test_split(X_xg, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "xg_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', XGBRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_red_pipe.fit(X_xg_red_train, y_xg_red_train)\n",
    "xg_red_train_mse = mean_squared_error(y_xg_red_train, xg_red_pipe.predict(X_xg_red_train))\n",
    "xg_red_test_mse = mean_squared_error(y_xg_red_test, xg_red_pipe.predict(X_xg_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(xg_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(xg_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', XGBRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_pipe.fit(X_train, y_train)\n",
    "xg_train_mse = mean_squared_error(y_train, xg_pipe.predict(X_train))\n",
    "xg_test_mse = mean_squared_error(y_test, xg_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(xg_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(xg_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_gb = RFE(estimator = GradientBoostingRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_gb.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[rfe_gb.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA',\n",
    "       'WAA', 'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'CS',\n",
    "       'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'SH',\n",
    "       'SF', 'IBB', 'Num_Pos']\n",
    "red_cat_columns = ['Tm', 'Acquired', 'C', '1B', '2B', '3B', 'SS', 'OF']\n",
    "X_gb = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gb_red_train, X_gb_red_test, y_gb_red_train, y_gb_red_test = train_test_split(X_gb, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "gb_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', GradientBoostingRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_red_pipe.fit(X_gb_red_train, y_gb_red_train)\n",
    "gb_red_train_mse = mean_squared_error(y_gb_red_train, gb_red_pipe.predict(X_gb_red_train))\n",
    "gb_red_test_mse = mean_squared_error(y_gb_red_test, gb_red_pipe.predict(X_gb_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(gb_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(gb_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', GradientBoostingRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipe.fit(X_train, y_train)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pipe.predict(X_train))\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(gb_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(gb_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADA Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_ada = RFE(estimator = AdaBoostRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_ada.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[rfe_ada.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA', 'WAA',\n",
    "       'RAR', 'WAR', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'BB', 'SO', 'BA',\n",
    "       'OBP', 'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB',\n",
    "       'Num_Pos']\n",
    "red_cat_columns = ['Tm', 'Acquired', 'Bat', 'C', '1B', '2B', '3B', 'SS', 'OF']\n",
    "X_ada = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ada_red_train, X_ada_red_test, y_ada_red_train, y_ada_red_test = train_test_split(X_ada, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "ada_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', AdaBoostRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_red_pipe.fit(X_ada_red_train, y_ada_red_train)\n",
    "ada_red_train_mse = mean_squared_error(y_ada_red_train, ada_red_pipe.predict(X_ada_red_train))\n",
    "ada_red_test_mse = mean_squared_error(y_ada_red_test, ada_red_pipe.predict(X_ada_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(ada_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(ada_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', PCA(n_components = 30, random_state = 621)),\n",
    "        ('model', AdaBoostRegressor(random_state = 621))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_pipe.fit(X_train, y_train)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pipe.predict(X_train))\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(ada_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(ada_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', SVC())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipe.fit(X_train, y_train)\n",
    "svm_train_mse = mean_squared_error(y_train, svm_pipe.predict(X_train))\n",
    "svm_test_mse = mean_squared_error(y_test, svm_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(svm_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(svm_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', PCA(n_components = 63)),\n",
    "        ('model', KNeighborsRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe.fit(X_train, y_train)\n",
    "knn_train_mse = mean_squared_error(y_train, knn_pipe.predict(X_train))\n",
    "knn_test_mse = mean_squared_error(y_test, knn_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(knn_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(knn_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 12:27:42.928037: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from bayes_opt import BayesianOptimization\n",
    "from keras.optimizers import Adam\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES:\n",
    "- Should look at different dropout rates for the different layers we add (similar code to adding more layers)\n",
    "- Should look into different EPOCHS or optimizers in order to optimally fit and train the data\n",
    "- Should also look into different batch sizes or maybe different activations for the different layers and run more iterations to find the best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | dropou... |  epochs   | layer_... | layer_... | layer_... | layer_... | layer_... | learni... |  neurons  | num_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-2.969e+1\u001b[0m | \u001b[0m32.49    \u001b[0m | \u001b[0m0.4754   \u001b[0m | \u001b[0m758.8    \u001b[0m | \u001b[0m166.1    \u001b[0m | \u001b[0m66.95    \u001b[0m | \u001b[0m66.94    \u001b[0m | \u001b[0m45.01    \u001b[0m | \u001b[0m226.0    \u001b[0m | \u001b[0m0.6051   \u001b[0m | \u001b[0m190.6    \u001b[0m | \u001b[0m1.082    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-2.389e+1\u001b[0m | \u001b[95m44.4     \u001b[0m | \u001b[95m0.4162   \u001b[0m | \u001b[95m291.1    \u001b[0m | \u001b[95m72.73    \u001b[0m | \u001b[95m73.08    \u001b[0m | \u001b[95m100.2    \u001b[0m | \u001b[95m149.5    \u001b[0m | \u001b[95m128.8    \u001b[0m | \u001b[95m0.2983   \u001b[0m | \u001b[95m169.1    \u001b[0m | \u001b[95m1.558    \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m     pbounds[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlayer_neurons_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m (\u001b[39m32\u001b[39m, \u001b[39m256\u001b[39m)\n\u001b[1;32m     32\u001b[0m optimizer \u001b[39m=\u001b[39m BayesianOptimization(f \u001b[39m=\u001b[39m dnn_cv_score, pbounds \u001b[39m=\u001b[39m pbounds, random_state \u001b[39m=\u001b[39m \u001b[39m42\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m optimizer\u001b[39m.\u001b[39mmaximize(init_points \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m, n_iter \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m)\n\u001b[1;32m     36\u001b[0m best_params \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39mmax[\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     37\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Hyperparameters:\u001b[39m\u001b[39m\"\u001b[39m, best_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/bayes_opt/bayesian_optimization.py:310\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[0;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[1;32m    308\u001b[0m     x_probe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msuggest(util)\n\u001b[1;32m    309\u001b[0m     iteration \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 310\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprobe(x_probe, lazy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    312\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bounds_transformer \u001b[39mand\u001b[39;00m iteration \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    313\u001b[0m     \u001b[39m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[39m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_bounds(\n\u001b[1;32m    316\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bounds_transformer\u001b[39m.\u001b[39mtransform(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_space))\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/bayes_opt/bayesian_optimization.py:208\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[0;34m(self, params, lazy)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_queue\u001b[39m.\u001b[39madd(params)\n\u001b[1;32m    207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_space\u001b[39m.\u001b[39mprobe(params)\n\u001b[1;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch(Events\u001b[39m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/bayes_opt/target_space.py:236\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    234\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_as_array(params)\n\u001b[1;32m    235\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_keys, x))\n\u001b[0;32m--> 236\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constraint \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregister(x, target)\n",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m, in \u001b[0;36mdnn_cv_score\u001b[0;34m(neurons, dropout_rate, learning_rate, epochs, batch_size, num_layers, **layer_neurons)\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer \u001b[39m=\u001b[39m Adam(learning_rate \u001b[39m=\u001b[39m learning_rate)\n\u001b[1;32m     13\u001b[0m model\u001b[39m.\u001b[39mcompile(loss \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m'\u001b[39m, optimizer \u001b[39m=\u001b[39m optimizer)\n\u001b[0;32m---> 15\u001b[0m model\u001b[39m.\u001b[39mfit(X_train_scaled, y_train, epochs \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(epochs), batch_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(batch_size), verbose \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test_scaled)\n\u001b[1;32m     18\u001b[0m mse \u001b[39m=\u001b[39m mean_squared_error(y_test, y_pred)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:329\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[39mfor\u001b[39;00m step, iterator \u001b[39min\u001b[39;00m epoch_iterator\u001b[39m.\u001b[39menumerate_epoch():\n\u001b[1;32m    328\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 329\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    330\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    331\u001b[0m         step, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    332\u001b[0m     )\n\u001b[1;32m    333\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    878\u001b[0m     args, kwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config\n\u001b[1;32m    879\u001b[0m )\n\u001b[1;32m    880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_function\u001b[39m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_flat(\u001b[39m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute(\n\u001b[1;32m   1487\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1488\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   1489\u001b[0m       inputs\u001b[39m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1490\u001b[0m       attrs\u001b[39m=\u001b[39mattrs,\n\u001b[1;32m   1491\u001b[0m       ctx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1492\u001b[0m   )\n\u001b[1;32m   1493\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def dnn_model_score(neurons, dropout_rate, learning_rate, epochs, batch_size, num_layers, **layer_neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(neurons), activation='relu', input_shape = (X_train_scaled.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    for i in range(1, int(num_layers) + 1):\n",
    "        model.add(Dense(int(layer_neurons[f'layer_neurons_{i}']), activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "    optimizer = Adam(learning_rate = learning_rate)\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "\n",
    "    model.fit(X_train_scaled, y_train, epochs = int(epochs), batch_size = int(batch_size), verbose = 0)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return -mse\n",
    "\n",
    "pbounds = {'neurons': (32, 256),\n",
    "           'dropout_rate': (0.0, 0.5),\n",
    "           'learning_rate': (0.01, 1),\n",
    "           'epochs' : (100, 1000),\n",
    "           'batch_size' : (25, 45),\n",
    "           'num_layers': (1, 5)}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    pbounds[f'layer_neurons_{i}'] = (32, 256)\n",
    "\n",
    "optimizer = BayesianOptimization(f = dnn_model_score, pbounds = pbounds, random_state = 42)\n",
    "\n",
    "optimizer.maximize(init_points = 5, n_iter = 10)\n",
    "\n",
    "best_params = optimizer.max['params']\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,273</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">169</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,562</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">169</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m208\u001b[0m)            │        \u001b[38;5;34m18,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout1 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m208\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense2 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m)             │        \u001b[38;5;34m20,273\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout2 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m97\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense3 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m169\u001b[0m)            │        \u001b[38;5;34m16,562\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout3 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m169\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m170\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,309</span> (216.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,309\u001b[0m (216.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,309</span> (216.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,309\u001b[0m (216.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(name = 'Dense1', units = 208, input_dim = X_train_scaled.shape[1], activation = 'relu'))\n",
    "model.add(Dropout(name = 'Dropout1', rate = 0.21597250932105788))\n",
    "model.add(Dense(name = 'Dense2', units = 97, activation = 'relu'))\n",
    "model.add(Dropout(name = 'Dropout2', rate = 0.21597250932105788))\n",
    "model.add(Dense(name = 'Dense3', units = 169, activation = 'relu'))\n",
    "model.add(Dropout(name = 'Dropout3', rate = 0.21597250932105788))\n",
    "\n",
    "model.add(Dense(name = 'Output', units = 1, activation = 'linear'))\n",
    "\n",
    "optimizer = Adam(learning_rate = 0.46150928437486555)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = 'mean_squared_error')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(X_train_scaled, y_train, validation_split \u001b[39m=\u001b[39m \u001b[39m.2\u001b[39m, batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m, epochs \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m, verbose \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:329\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[39mfor\u001b[39;00m step, iterator \u001b[39min\u001b[39;00m epoch_iterator\u001b[39m.\u001b[39menumerate_epoch():\n\u001b[1;32m    328\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 329\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    330\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    331\u001b[0m         step, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    332\u001b[0m     )\n\u001b[1;32m    333\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:888\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    885\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 888\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39minitializers)\n\u001b[1;32m    889\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[1;32m    891\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[1;32m    892\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[39m.\u001b[39mScopeType\u001b[39m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[39m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39mtrace_function(\n\u001b[1;32m    696\u001b[0m     args, kwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config\n\u001b[1;32m    697\u001b[0m )\n\u001b[1;32m    699\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[39m=\u001b[39m tracing_options\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[39m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tracing_options\u001b[39m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[39m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[39m=\u001b[39m _create_concrete_function(\n\u001b[1;32m    284\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[1;32m    285\u001b[0m )\n\u001b[1;32m    287\u001b[0m \u001b[39mif\u001b[39;00m tracing_options\u001b[39m.\u001b[39mfunction_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[39m.\u001b[39mfunction_cache\u001b[39m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[39m=\u001b[39m function_type\u001b[39m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[39m=\u001b[39m tracing_options\u001b[39m.\u001b[39mattributes \u001b[39mand\u001b[39;00m tracing_options\u001b[39m.\u001b[39mattributes\u001b[39m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[39m.\u001b[39mDISABLE_ACD, \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39mfunc_graph_from_py_func(\n\u001b[1;32m    311\u001b[0m     tracing_options\u001b[39m.\u001b[39mname,\n\u001b[1;32m    312\u001b[0m     tracing_options\u001b[39m.\u001b[39mpython_function,\n\u001b[1;32m    313\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39margs,\n\u001b[1;32m    314\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39mkwargs,\n\u001b[1;32m    315\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    316\u001b[0m     func_graph\u001b[39m=\u001b[39mfunc_graph,\n\u001b[1;32m    317\u001b[0m     add_control_dependencies\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m disable_acd,\n\u001b[1;32m    318\u001b[0m     arg_names\u001b[39m=\u001b[39mfunction_type_utils\u001b[39m.\u001b[39mto_arg_names(function_type),\n\u001b[1;32m    319\u001b[0m     create_placeholders\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    322\u001b[0m transform\u001b[39m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[39m=\u001b[39m traced_func_graph\u001b[39m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[1;32m   1061\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39m__wrapped__(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    599\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[39mreturn\u001b[39;00m api\u001b[39m.\u001b[39mconverted_call(\n\u001b[1;32m     42\u001b[0m       original_func,\n\u001b[1;32m     43\u001b[0m       args,\n\u001b[1;32m     44\u001b[0m       kwargs,\n\u001b[1;32m     45\u001b[0m       options\u001b[39m=\u001b[39mconverter\u001b[39m.\u001b[39mConversionOptions(\n\u001b[1;32m     46\u001b[0m           recursive\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m           optional_features\u001b[39m=\u001b[39mautograph_options,\n\u001b[1;32m     48\u001b[0m           user_requested\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m       ))\n\u001b[1;32m     50\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:339\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39mif\u001b[39;00m is_autograph_artifact(f):\n\u001b[1;32m    338\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPermanently allowed: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph artifact\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 339\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    341\u001b[0m \u001b[39m# If this is a partial, unwrap it and redo all the checks.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(f, functools\u001b[39m.\u001b[39mpartial):\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:122\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Runs a single training step given a Dataset iterator.\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[0;32m--> 122\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mrun(\n\u001b[1;32m    123\u001b[0m     one_step_on_data, args\u001b[39m=\u001b[39m(data,)\n\u001b[1;32m    124\u001b[0m )\n\u001b[1;32m    125\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[1;32m    126\u001b[0m     outputs,\n\u001b[1;32m    127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy,\n\u001b[1;32m    128\u001b[0m     reduction\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_reduction_method,\n\u001b[1;32m    129\u001b[0m )\n\u001b[1;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:1681\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[1;32m   1677\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   1680\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 1681\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extended\u001b[39m.\u001b[39mcall_for_each_replica(fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3271\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   3270\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 3271\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4069\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4067\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[1;32m   4068\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m-> 4069\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:905\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    902\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    903\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     \u001b[39m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39mcall_function(\n\u001b[1;32m    906\u001b[0m         args, kwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_config\n\u001b[1;32m    907\u001b[0m     )\n\u001b[1;32m    908\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    909\u001b[0m   bound_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_variable_creation_fn\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\n\u001b[1;32m    910\u001b[0m       \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds\n\u001b[1;32m    911\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[39m=\u001b[39m args \u001b[39mif\u001b[39;00m args \u001b[39melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[39m=\u001b[39m kwargs \u001b[39mif\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[39m=\u001b[39m trace_function(\n\u001b[1;32m    133\u001b[0m     args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs, tracing_options\u001b[39m=\u001b[39mtracing_options\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    136\u001b[0m \u001b[39m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[39m=\u001b[39m tracing_options\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[39m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[1;32m    182\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tracing_options\u001b[39m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[39m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[39m=\u001b[39m _create_concrete_function(\n\u001b[1;32m    284\u001b[0m     target_func_type, lookup_func_context, func_graph, tracing_options\n\u001b[1;32m    285\u001b[0m )\n\u001b[1;32m    287\u001b[0m \u001b[39mif\u001b[39;00m tracing_options\u001b[39m.\u001b[39mfunction_cache \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[39m.\u001b[39mfunction_cache\u001b[39m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[39m=\u001b[39m function_type\u001b[39m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[39m=\u001b[39m tracing_options\u001b[39m.\u001b[39mattributes \u001b[39mand\u001b[39;00m tracing_options\u001b[39m.\u001b[39mattributes\u001b[39m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[39m.\u001b[39mDISABLE_ACD, \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39mfunc_graph_from_py_func(\n\u001b[1;32m    311\u001b[0m     tracing_options\u001b[39m.\u001b[39mname,\n\u001b[1;32m    312\u001b[0m     tracing_options\u001b[39m.\u001b[39mpython_function,\n\u001b[1;32m    313\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39margs,\n\u001b[1;32m    314\u001b[0m     placeholder_bound_args\u001b[39m.\u001b[39mkwargs,\n\u001b[1;32m    315\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    316\u001b[0m     func_graph\u001b[39m=\u001b[39mfunc_graph,\n\u001b[1;32m    317\u001b[0m     add_control_dependencies\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m disable_acd,\n\u001b[1;32m    318\u001b[0m     arg_names\u001b[39m=\u001b[39mfunction_type_utils\u001b[39m.\u001b[39mto_arg_names(function_type),\n\u001b[1;32m    319\u001b[0m     create_placeholders\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    322\u001b[0m transform\u001b[39m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[39m=\u001b[39m traced_func_graph\u001b[39m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[1;32m   1061\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:598\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    595\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 598\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39m__wrapped__(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    599\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py:41\u001b[0m, in \u001b[0;36mpy_func_from_autograph.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m   \u001b[39mreturn\u001b[39;00m api\u001b[39m.\u001b[39mconverted_call(\n\u001b[1;32m     42\u001b[0m       original_func,\n\u001b[1;32m     43\u001b[0m       args,\n\u001b[1;32m     44\u001b[0m       kwargs,\n\u001b[1;32m     45\u001b[0m       options\u001b[39m=\u001b[39mconverter\u001b[39m.\u001b[39mConversionOptions(\n\u001b[1;32m     46\u001b[0m           recursive\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m           optional_features\u001b[39m=\u001b[39mautograph_options,\n\u001b[1;32m     48\u001b[0m           user_requested\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m       ))\n\u001b[1;32m     50\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m     51\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m conversion\u001b[39m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: from cache\u001b[39m\u001b[39m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    333\u001b[0m \u001b[39mif\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mcontrol_status_ctx()\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m ag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[39m.\u001b[39mlog(\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAllowlisted: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: AutoGraph is disabled in context\u001b[39m\u001b[39m'\u001b[39m, f)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:110\u001b[0m, in \u001b[0;36mTensorFlowTrainer.make_train_function.<locals>.one_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39m@tf\u001b[39m\u001b[39m.\u001b[39mautograph\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mdo_not_convert\n\u001b[1;32m    108\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mone_step_on_data\u001b[39m(data):\n\u001b[1;32m    109\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_step(data)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:75\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     72\u001b[0m     gradients \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39mgradient(loss, trainable_weights)\n\u001b[1;32m     74\u001b[0m     \u001b[39m# Update weights\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(gradients, trainable_weights))\n\u001b[1;32m     76\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe model does not have any trainable weights.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:279\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_gradients\u001b[39m(\u001b[39mself\u001b[39m, grads_and_vars):\n\u001b[1;32m    278\u001b[0m     grads, trainable_variables \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mgrads_and_vars)\n\u001b[0;32m--> 279\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply(grads, trainable_variables)\n\u001b[1;32m    280\u001b[0m     \u001b[39m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterations\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:340\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    339\u001b[0m \u001b[39m# Apply gradient updates.\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend_apply_gradients(grads, trainable_variables)\n\u001b[1;32m    341\u001b[0m \u001b[39m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[39mfor\u001b[39;00m variable \u001b[39min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:390\u001b[0m, in \u001b[0;36mBaseOptimizer._backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    383\u001b[0m     ops\u001b[39m.\u001b[39mcond(\n\u001b[1;32m    384\u001b[0m         is_update_step,\n\u001b[1;32m    385\u001b[0m         \u001b[39mlambda\u001b[39;00m: _update_step_fn(\u001b[39mself\u001b[39m, grads, trainable_variables),\n\u001b[1;32m    386\u001b[0m         \u001b[39mlambda\u001b[39;00m: _grad_accumulation_fn(\u001b[39mself\u001b[39m, grads),\n\u001b[1;32m    387\u001b[0m     )\n\u001b[1;32m    388\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    389\u001b[0m     \u001b[39m# Run udpate step.\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend_update_step(\n\u001b[1;32m    391\u001b[0m         grads, trainable_variables, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlearning_rate\n\u001b[1;32m    392\u001b[0m     )\n\u001b[1;32m    394\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_ema:\n\u001b[1;32m    395\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_model_variables_moving_average(\n\u001b[1;32m    396\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainable_variables\n\u001b[1;32m    397\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:119\u001b[0m, in \u001b[0;36mTFOptimizer._backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_backend_update_step\u001b[39m(\u001b[39mself\u001b[39m, grads, trainable_variables, learning_rate):\n\u001b[1;32m    115\u001b[0m     trainable_variables \u001b[39m=\u001b[39m [\n\u001b[1;32m    116\u001b[0m         v\u001b[39m.\u001b[39mvalue \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, backend\u001b[39m.\u001b[39mVariable) \u001b[39melse\u001b[39;00m v\n\u001b[1;32m    117\u001b[0m         \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m trainable_variables\n\u001b[1;32m    118\u001b[0m     ]\n\u001b[0;32m--> 119\u001b[0m     tf\u001b[39m.\u001b[39m__internal__\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39minterim\u001b[39m.\u001b[39mmaybe_merge_call(\n\u001b[1;32m    120\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distributed_tf_update_step,\n\u001b[1;32m    121\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribution_strategy,\n\u001b[1;32m    122\u001b[0m         \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(grads, trainable_variables)),\n\u001b[1;32m    123\u001b[0m         learning_rate,\n\u001b[1;32m    124\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(strategy, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[39mreturn\u001b[39;00m distribute_lib\u001b[39m.\u001b[39mget_replica_context()\u001b[39m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:135\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step\u001b[0;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_step(grad, var, learning_rate)\n\u001b[1;32m    134\u001b[0m \u001b[39mfor\u001b[39;00m grad, var \u001b[39min\u001b[39;00m grads_and_vars:\n\u001b[0;32m--> 135\u001b[0m     distribution\u001b[39m.\u001b[39mextended\u001b[39m.\u001b[39mupdate(\n\u001b[1;32m    136\u001b[0m         var, apply_grad_to_update_var, args\u001b[39m=\u001b[39m(grad,), group\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3015\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3013\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   3014\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3015\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   3016\u001b[0m       var, fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs, group\u001b[39m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:2894\u001b[0m, in \u001b[0;36mStrategyExtendedV2._replica_ctx_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2891\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_fn\u001b[39m(_, \u001b[39m*\u001b[39mmerged_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmerged_kwargs):\n\u001b[1;32m   2892\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(var, fn, merged_args, merged_kwargs, group\u001b[39m=\u001b[39mgroup)\n\u001b[0;32m-> 2894\u001b[0m \u001b[39mreturn\u001b[39;00m replica_context\u001b[39m.\u001b[39mmerge_call(merge_fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3486\u001b[0m, in \u001b[0;36mReplicaContextBase.merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3482\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m   3484\u001b[0m merge_fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   3485\u001b[0m     merge_fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 3486\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_call(merge_fn, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3493\u001b[0m, in \u001b[0;36mReplicaContextBase._merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3490\u001b[0m _push_per_thread_mode(  \u001b[39m# thread-local, so not needed with multiple threads\u001b[39;00m\n\u001b[1;32m   3491\u001b[0m     _CrossReplicaThreadMode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy))  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3492\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3493\u001b[0m   \u001b[39mreturn\u001b[39;00m merge_fn(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strategy, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   3494\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   3495\u001b[0m   _pop_per_thread_mode()\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:2892\u001b[0m, in \u001b[0;36mStrategyExtendedV2._replica_ctx_update.<locals>.merge_fn\u001b[0;34m(_, *merged_args, **merged_kwargs)\u001b[0m\n\u001b[1;32m   2891\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge_fn\u001b[39m(_, \u001b[39m*\u001b[39mmerged_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmerged_kwargs):\n\u001b[0;32m-> 2892\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(var, fn, merged_args, merged_kwargs, group\u001b[39m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:3013\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3010\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[1;32m   3011\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   3012\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[0;32m-> 3013\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update(var, fn, args, kwargs, group)\n\u001b[1;32m   3014\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3015\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   3016\u001b[0m       var, fn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs, group\u001b[39m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4083\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4080\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update\u001b[39m(\u001b[39mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   4081\u001b[0m   \u001b[39m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   4082\u001b[0m   \u001b[39m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 4083\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_non_slot(var, fn, (var,) \u001b[39m+\u001b[39m \u001b[39mtuple\u001b[39m(args), kwargs, group)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/distribute/distribute_lib.py:4089\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4085\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_non_slot\u001b[39m(\u001b[39mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   4086\u001b[0m   \u001b[39m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   4087\u001b[0m   \u001b[39m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   4088\u001b[0m   \u001b[39mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 4089\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   4090\u001b[0m     \u001b[39mif\u001b[39;00m should_group:\n\u001b[1;32m   4091\u001b[0m       \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:643\u001b[0m, in \u001b[0;36mdo_not_convert.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    642\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mDISABLED):\n\u001b[0;32m--> 643\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:132\u001b[0m, in \u001b[0;36mTFOptimizer._distributed_tf_update_step.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_grad_to_update_var\u001b[39m(var, grad):\n\u001b[0;32m--> 132\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_step(grad, var, learning_rate)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/optimizers/adam.py:113\u001b[0m, in \u001b[0;36mAdam.update_step\u001b[0;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_step\u001b[39m(\u001b[39mself\u001b[39m, gradient, variable, learning_rate):\n\u001b[1;32m    112\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Update step given gradient and the associated model variable.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     lr \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mcast(learning_rate, variable\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    114\u001b[0m     gradient \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mcast(gradient, variable\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    115\u001b[0m     local_step \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mcast(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterations \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, variable\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/ops/core.py:473\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(x, dtype)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[39mif\u001b[39;00m any_symbolic_tensors((x,)):\n\u001b[1;32m    472\u001b[0m     \u001b[39mreturn\u001b[39;00m Cast(dtype\u001b[39m=\u001b[39mdtype)(x)\n\u001b[0;32m--> 473\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mcore\u001b[39m.\u001b[39mcast(x, dtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/backend/tensorflow/core.py:172\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(x, dtype)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m    171\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcast(x, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/ops/math_ops.py:1015\u001b[0m, in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m   1009\u001b[0m   x \u001b[39m=\u001b[39m indexed_slices\u001b[39m.\u001b[39mIndexedSlices(values_cast, x\u001b[39m.\u001b[39mindices, x\u001b[39m.\u001b[39mdense_shape)\n\u001b[1;32m   1010\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m   \u001b[39m# TODO(josh11b): If x is not already a Tensor, we could return\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m   \u001b[39m# ops.convert_to_tensor(x, dtype=dtype, ...)  here, but that\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m   \u001b[39m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m   \u001b[39m# strings.\u001b[39;00m\n\u001b[0;32m-> 1015\u001b[0m   x \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(x, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1016\u001b[0m   \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mis_complex \u001b[39mand\u001b[39;00m base_type\u001b[39m.\u001b[39mis_floating:\n\u001b[1;32m   1017\u001b[0m     logging\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1018\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou are casting an input of type \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m to an \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mincompatible dtype \u001b[39m\u001b[39m{\u001b[39;00mbase_type\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m.  This will \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1020\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdiscard the imaginary part and may not be what you \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mintended.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1022\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:696\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[39m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    695\u001b[0m preferred_dtype \u001b[39m=\u001b[39m preferred_dtype \u001b[39mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 696\u001b[0m \u001b[39mreturn\u001b[39;00m tensor_conversion_registry\u001b[39m.\u001b[39mconvert(\n\u001b[1;32m    697\u001b[0m     value, dtype, name, as_ref, preferred_dtype, accepted_result_types\n\u001b[1;32m    698\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:209\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    207\u001b[0m overload \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(value, \u001b[39m\"\u001b[39m\u001b[39m__tf_tensor__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    208\u001b[0m \u001b[39mif\u001b[39;00m overload \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m   \u001b[39mreturn\u001b[39;00m overload(dtype, name)  \u001b[39m#  pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[39mfor\u001b[39;00m base_type, conversion_func \u001b[39min\u001b[39;00m get(\u001b[39mtype\u001b[39m(value)):\n\u001b[1;32m    212\u001b[0m   \u001b[39m# If dtype is None but preferred_dtype is not None, we try to\u001b[39;00m\n\u001b[1;32m    213\u001b[0m   \u001b[39m# cast to preferred_dtype first.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/keras/src/backend/tensorflow/core.py:64\u001b[0m, in \u001b[0;36mVariable.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__tf_tensor__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 64\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mconvert_to_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue, dtype\u001b[39m=\u001b[39mdtype, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1261\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion.py:161\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39m@tf_export\u001b[39m\u001b[39m.\u001b[39mtf_export(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m     97\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[1;32m     99\u001b[0m     value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype_hint\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    100\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m tensor_lib\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    101\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[39m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m   \u001b[39mreturn\u001b[39;00m convert_to_tensor_v2(\n\u001b[1;32m    162\u001b[0m       value, dtype\u001b[39m=\u001b[39mdtype, dtype_hint\u001b[39m=\u001b[39mdtype_hint, name\u001b[39m=\u001b[39mname\n\u001b[1;32m    163\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion.py:171\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[39mreturn\u001b[39;00m tensor_conversion_registry\u001b[39m.\u001b[39mconvert(\n\u001b[1;32m    172\u001b[0m     value, dtype, name, preferred_dtype\u001b[39m=\u001b[39mdtype_hint\n\u001b[1;32m    173\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39mdtype, name\u001b[39m=\u001b[39mname, as_ref\u001b[39m=\u001b[39mas_ref)\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:2340\u001b[0m, in \u001b[0;36m_dense_var_to_tensor\u001b[0;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   2339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_dense_var_to_tensor\u001b[39m(var, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m-> 2340\u001b[0m   \u001b[39mreturn\u001b[39;00m var\u001b[39m.\u001b[39m_dense_var_to_tensor(dtype\u001b[39m=\u001b[39mdtype, name\u001b[39m=\u001b[39mname, as_ref\u001b[39m=\u001b[39mas_ref)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:1582\u001b[0m, in \u001b[0;36mBaseResourceVariable._dense_var_to_tensor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1580\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_value()\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39minputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1581\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue()\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:634\u001b[0m, in \u001b[0;36mBaseResourceVariable.value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_value\n\u001b[1;32m    633\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mNone\u001b[39;00m, ignore_existing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 634\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_variable_op()\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:818\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[0;34m(self, no_copy)\u001b[0m\n\u001b[1;32m    816\u001b[0m       result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[1;32m    817\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 818\u001b[0m   result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[1;32m    820\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    821\u001b[0m   \u001b[39m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[1;32m    822\u001b[0m   \u001b[39m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[1;32m    823\u001b[0m   record\u001b[39m.\u001b[39mrecord_operation(\n\u001b[1;32m    824\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReadVariableOp\u001b[39m\u001b[39m\"\u001b[39m, [result], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle],\n\u001b[1;32m    825\u001b[0m       backward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x],\n\u001b[1;32m    826\u001b[0m       forward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:808\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[0;34m(no_copy)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[39mif\u001b[39;00m no_copy \u001b[39mand\u001b[39;00m forward_compat\u001b[39m.\u001b[39mforward_compatible(\u001b[39m2022\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[1;32m    807\u001b[0m   gen_resource_variable_ops\u001b[39m.\u001b[39mdisable_copy_on_read(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle)\n\u001b[0;32m--> 808\u001b[0m result \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39mread_variable_op(\n\u001b[1;32m    809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype)\n\u001b[1;32m    810\u001b[0m _maybe_set_handle_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, result)\n\u001b[1;32m    811\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:548\u001b[0m, in \u001b[0;36mread_variable_op\u001b[0;34m(resource, dtype, name)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m dtype \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_type(dtype, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 548\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39m_apply_op_helper(\n\u001b[1;32m    549\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReadVariableOp\u001b[39m\u001b[39m\"\u001b[39m, resource\u001b[39m=\u001b[39mresource, dtype\u001b[39m=\u001b[39mdtype, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m    550\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[1;32m    551\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/framework/op_def_library.py:796\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    791\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[1;32m    792\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[1;32m    793\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[1;32m    794\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[1;32m    795\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 796\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    797\u001b[0m                              name\u001b[39m=\u001b[39mscope, input_types\u001b[39m=\u001b[39minput_types,\n\u001b[1;32m    798\u001b[0m                              attrs\u001b[39m=\u001b[39mattr_protos, op_def\u001b[39m=\u001b[39mop_def)\n\u001b[1;32m    800\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[1;32m    804\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:670\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    668\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[1;32m    669\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[0;32m--> 670\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    671\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[1;32m    672\u001b[0m     compute_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:2652\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   2649\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[1;32m   2650\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[1;32m   2651\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[0;32m-> 2652\u001b[0m   ret \u001b[39m=\u001b[39m Operation\u001b[39m.\u001b[39mfrom_node_def(\n\u001b[1;32m   2653\u001b[0m       node_def,\n\u001b[1;32m   2654\u001b[0m       \u001b[39mself\u001b[39m,\n\u001b[1;32m   2655\u001b[0m       inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m   2656\u001b[0m       output_types\u001b[39m=\u001b[39mdtypes,\n\u001b[1;32m   2657\u001b[0m       control_inputs\u001b[39m=\u001b[39mcontrol_inputs,\n\u001b[1;32m   2658\u001b[0m       input_types\u001b[39m=\u001b[39minput_types,\n\u001b[1;32m   2659\u001b[0m       original_op\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_original_op,\n\u001b[1;32m   2660\u001b[0m       op_def\u001b[39m=\u001b[39mop_def,\n\u001b[1;32m   2661\u001b[0m   )\n\u001b[1;32m   2662\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[1;32m   2663\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:1162\u001b[0m, in \u001b[0;36mOperation.from_node_def\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1160\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39mop_def)\n\u001b[1;32m   1161\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m Operation(c_op, SymbolicTensor)\n\u001b[0;32m-> 1162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init(g)\n\u001b[1;32m   1164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_op \u001b[39m=\u001b[39m original_op\n\u001b[1;32m   1166\u001b[0m \u001b[39m# Post process for control flows.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:1213\u001b[0m, in \u001b[0;36mOperation._init\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[39m# Gradient function for this op. There are three ways to specify gradient\u001b[39;00m\n\u001b[1;32m   1207\u001b[0m \u001b[39m# function, and first available gradient gets used, in the following order.\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m \u001b[39m# 1. self._gradient_function\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m \u001b[39m# 2. Gradient name registered by \"_gradient_op_type\" attribute.\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m \u001b[39m# 3. Gradient name registered by op.type.\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_function \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1213\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_outputs()\n\u001b[1;32m   1214\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_add_op(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pythonEnv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:245\u001b[0m, in \u001b[0;36mSymbolicTensor.__new__\u001b[0;34m(cls, op, value_index, dtype, unique_id)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[39mif\u001b[39;00m unique_id \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m   unique_id \u001b[39m=\u001b[39m uid()\n\u001b[0;32m--> 245\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tf_session\u001b[39m.\u001b[39mPyTensor\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(\n\u001b[1;32m    246\u001b[0m     SymbolicTensor, op, value_index, dtypes\u001b[39m.\u001b[39mas_dtype(dtype), unique_id\n\u001b[1;32m    247\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, validation_split = .2, batch_size = 32, epochs = 50, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test_scaled)\n",
    "train_preds = model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = mean_squared_error(y_train, train_preds)\n",
    "test_rmse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "print(f'Train RMSE: {np.sqrt(train_rmse)}')\n",
    "print(f'Test RMSE: {np.sqrt(test_rmse)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
