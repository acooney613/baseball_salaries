{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball = pd.read_csv('data/baseball.csv')\n",
    "baseball = baseball.drop(['Name', 'Age', 'Name-additional'], axis = 1)\n",
    "baseball['Salary'] = baseball['Salary'].str.replace('$', '').astype(float)\n",
    "\n",
    "baseball['C'] = baseball['Position'].apply(lambda x: 1 if 'C' in x else 0)\n",
    "baseball['1B'] = baseball['Position'].apply(lambda x: 1 if '1B' in x else 0)\n",
    "baseball['2B'] = baseball['Position'].apply(lambda x: 1 if '2B' in x else 0)\n",
    "baseball['3B'] = baseball['Position'].apply(lambda x: 1 if '3B' in x else 0)\n",
    "baseball['SS'] = baseball['Position'].apply(lambda x: 1 if 'SS' in x else 0)\n",
    "baseball['OF'] = baseball['Position'].apply(lambda x: 1 if 'OF' in x else 0)\n",
    "\n",
    "baseball['Num_Pos'] = baseball[['C', '1B', '2B', '3B', 'SS', 'OF']].sum(axis = 1)\n",
    "baseball = baseball.drop(['Position'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "# packages used in each section below\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "import shap\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = baseball.drop(['Salary'], axis = 1)\n",
    "y = baseball['Salary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['Tm', 'Lg', 'Acquired', 'Bat']\n",
    "num_columns = [col for col in X.columns if col not in cat_columns + ['C', '1B', '2B', '3B', 'SS', 'OF']]\n",
    "\n",
    "cat_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('scale', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, num_columns),\n",
    "        ('cat', cat_transformer, cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "X_transform = preprocessor.fit_transform(X)\n",
    "\n",
    "selected_features = np.concatenate([\n",
    "    np.array(num_columns),\n",
    "    np.array(preprocessor.transformers_[1][1]['onehot'].get_feature_names_out(cat_columns)),\n",
    "    np.array(['C', '1B', '2B', '3B', 'SS', 'OF'])\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=RandomForestRegressor(random_state=621))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=RandomForestRegressor(random_state=621))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=621)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=621)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=RandomForestRegressor(random_state=621))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_rf = RFE(estimator = RandomForestRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_rf.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA',\n",
       "       'WAA', 'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'CS',\n",
       "       'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'HBP',\n",
       "       'SH', 'SF', 'IBB', 'Num_Pos', 'Tm_LAA', 'Tm_LAD', 'Tm_MULTIPLE',\n",
       "       'Tm_NYM', 'Tm_NYY', 'Tm_SFG', 'Tm_STL', 'Acquired_Free Agency',\n",
       "       'Acquired_Traded'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features[rfe_rf.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'RAA', 'WAA', 'RAR',\n",
    "               'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'CS', 'BB', 'SO', 'BA', 'OBP',\n",
    "               'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB', 'Num_Pos', 'Season']\n",
    "red_cat_columns = ['Tm', 'Acquired']\n",
    "X_rf = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf_red_train, X_rf_red_test, y_rf_red_train, y_rf_red_test = train_test_split(X_rf, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "rf_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', RandomForestRegressor(n_estimators = 200, max_depth = 12, min_samples_split = 3))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Random Forest Metrics:\n",
      "Training RMSE: 2665873.0847510966\n",
      "Test RMSE: 5328864.974109751\n"
     ]
    }
   ],
   "source": [
    "rf_red_pipe.fit(X_rf_red_train, y_rf_red_train)\n",
    "rf_red_train_mse = mean_squared_error(y_rf_red_train, rf_red_pipe.predict(X_rf_red_train))\n",
    "rf_red_test_mse = mean_squared_error(y_rf_red_test, rf_red_pipe.predict(X_rf_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(rf_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(rf_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestRegressor(n_estimators = 200, min_samples_split = 14))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 2995640.073838007\n",
      "Test RMSE: 5339371.913062029\n"
     ]
    }
   ],
   "source": [
    "rf_pipe.fit(X_train, y_train)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pipe.predict(X_train))\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(rf_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(rf_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                           colsample_bylevel=None, colsample_bynode=None,\n",
       "                           colsample_bytree=None, early_stopping_rounds=None,\n",
       "                           enable_categorical=False, eval_metric=None,\n",
       "                           feature_types=None, gamma=None, gpu_id=None,\n",
       "                           grow_policy=None, importance_type=None,\n",
       "                           interaction_constraints=None, learning_rate=None,\n",
       "                           max_bin=None, max_cat_threshold=None,\n",
       "                           max_cat_to_onehot=None, max_delta_step=None,\n",
       "                           max_depth=None, max_leaves=None,\n",
       "                           min_child_weight=None, missing=nan,\n",
       "                           monotone_constraints=None, n_estimators=100,\n",
       "                           n_jobs=None, num_parallel_tree=None, predictor=None,\n",
       "                           random_state=621, ...))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                           colsample_bylevel=None, colsample_bynode=None,\n",
       "                           colsample_bytree=None, early_stopping_rounds=None,\n",
       "                           enable_categorical=False, eval_metric=None,\n",
       "                           feature_types=None, gamma=None, gpu_id=None,\n",
       "                           grow_policy=None, importance_type=None,\n",
       "                           interaction_constraints=None, learning_rate=None,\n",
       "                           max_bin=None, max_cat_threshold=None,\n",
       "                           max_cat_to_onehot=None, max_delta_step=None,\n",
       "                           max_depth=None, max_leaves=None,\n",
       "                           min_child_weight=None, missing=nan,\n",
       "                           monotone_constraints=None, n_estimators=100,\n",
       "                           n_jobs=None, num_parallel_tree=None, predictor=None,\n",
       "                           random_state=621, ...))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=621, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=621, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "                           colsample_bylevel=None, colsample_bynode=None,\n",
       "                           colsample_bytree=None, early_stopping_rounds=None,\n",
       "                           enable_categorical=False, eval_metric=None,\n",
       "                           feature_types=None, gamma=None, gpu_id=None,\n",
       "                           grow_policy=None, importance_type=None,\n",
       "                           interaction_constraints=None, learning_rate=None,\n",
       "                           max_bin=None, max_cat_threshold=None,\n",
       "                           max_cat_to_onehot=None, max_delta_step=None,\n",
       "                           max_depth=None, max_leaves=None,\n",
       "                           min_child_weight=None, missing=nan,\n",
       "                           monotone_constraints=None, n_estimators=100,\n",
       "                           n_jobs=None, num_parallel_tree=None, predictor=None,\n",
       "                           random_state=621, ...))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_xg = RFE(estimator = XGBRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_xg.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Season', 'RBI', 'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS+',\n",
       "       'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB', 'Num_Pos', 'Tm_ARI',\n",
       "       'Tm_BOS', 'Tm_CHC', 'Tm_CIN', 'Tm_DET', 'Tm_HOU', 'Tm_KCR',\n",
       "       'Tm_LAA', 'Tm_LAD', 'Tm_MIA', 'Tm_MIN', 'Tm_MULTIPLE', 'Tm_NYM',\n",
       "       'Tm_NYY', 'Tm_OAK', 'Tm_PHI', 'Tm_STL', 'Tm_TBR', 'Tm_TEX',\n",
       "       'Acquired_Amateur Draft', 'Acquired_Amateur Free Agent',\n",
       "       'Acquired_Free Agency', 'Acquired_Traded', 'Bat_L', 'Bat_R', '1B',\n",
       "       '2B'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features[rfe_xg.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Season', 'RBI', 'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS+', \n",
    "                   'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB', 'Num_Pos']\n",
    "red_cat_columns = ['Tm', 'Acquired', 'Bat', 'C', '1B', '2B', '3B', 'SS', 'OF']\n",
    "X_xg = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xg_red_train, X_xg_red_test, y_xg_red_train, y_xg_red_test = train_test_split(X_xg, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "xg_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', XGBRegressor(n_estimators = 200, learning_rate = .06, max_depth = 5))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Random Forest Metrics:\n",
      "Training RMSE: 3174834.536729983\n",
      "Test RMSE: 5035866.184550909\n"
     ]
    }
   ],
   "source": [
    "xg_red_pipe.fit(X_xg_red_train, y_xg_red_train)\n",
    "xg_red_train_mse = mean_squared_error(y_xg_red_train, xg_red_pipe.predict(X_xg_red_train))\n",
    "xg_red_test_mse = mean_squared_error(y_xg_red_test, xg_red_pipe.predict(X_xg_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(xg_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(xg_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', XGBRegressor(n_estimators = 100, learning_rate = .03, max_depth = 6))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 3537922.5378611186\n",
      "Test RMSE: 5184611.048067813\n"
     ]
    }
   ],
   "source": [
    "xg_pipe.fit(X_train, y_train)\n",
    "xg_train_mse = mean_squared_error(y_train, xg_pipe.predict(X_train))\n",
    "xg_test_mse = mean_squared_error(y_test, xg_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(xg_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(xg_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=GradientBoostingRegressor(random_state=621))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=GradientBoostingRegressor(random_state=621))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=621)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(random_state=621)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=GradientBoostingRegressor(random_state=621))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_gb = RFE(estimator = GradientBoostingRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_gb.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA',\n",
       "       'WAA', 'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'CS',\n",
       "       'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'SH',\n",
       "       'SF', 'IBB', 'Num_Pos', 'Tm_LAA', 'Tm_LAD', 'Tm_MIN',\n",
       "       'Tm_MULTIPLE', 'Tm_NYY', 'Tm_OAK', 'Tm_STL',\n",
       "       'Acquired_Free Agency', 'Acquired_Traded', '2B'], dtype=object)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features[rfe_gb.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA',\n",
    "       'WAA', 'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'CS',\n",
    "       'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'SH',\n",
    "       'SF', 'IBB', 'Num_Pos']\n",
    "red_cat_columns = ['Tm', 'Acquired', 'C', '1B', '2B', '3B', 'SS', 'OF']\n",
    "X_gb = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gb_red_train, X_gb_red_test, y_gb_red_train, y_gb_red_test = train_test_split(X_gb, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "gb_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', GradientBoostingRegressor(learning_rate = 0.075, n_estimators = 200, max_depth = 4))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Random Forest Metrics:\n",
      "Training RMSE: 3426537.951924427\n",
      "Test RMSE: 5028275.917521109\n"
     ]
    }
   ],
   "source": [
    "gb_red_pipe.fit(X_gb_red_train, y_gb_red_train)\n",
    "gb_red_train_mse = mean_squared_error(y_gb_red_train, gb_red_pipe.predict(X_gb_red_train))\n",
    "gb_red_test_mse = mean_squared_error(y_gb_red_test, gb_red_pipe.predict(X_gb_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(gb_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(gb_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', GradientBoostingRegressor(learning_rate = 0.075, n_estimators = 200, max_depth = 4))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 3379850.3723368607\n",
      "Test RMSE: 5028062.821060685\n"
     ]
    }
   ],
   "source": [
    "gb_pipe.fit(X_train, y_train)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pipe.predict(X_train))\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(gb_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(gb_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADA Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=AdaBoostRegressor(random_state=621))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=AdaBoostRegressor(random_state=621))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(random_state=621)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(random_state=621)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=AdaBoostRegressor(random_state=621))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_ada = RFE(estimator = AdaBoostRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_ada.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA',\n",
       "       'WAA', 'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'CS', 'BB',\n",
       "       'SO', 'BA', 'OBP', 'SLG', 'OPS', 'OPS+', 'GDP', 'HBP', 'SH', 'SF',\n",
       "       'IBB', 'Num_Pos', 'Tm_CHC', 'Tm_COL', 'Tm_DET', 'Tm_HOU', 'Tm_LAA',\n",
       "       'Tm_NYM', 'Tm_NYY', 'Acquired_Free Agency', 'Bat_L', 'Bat_R', '2B'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features[rfe_ada.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA', 'WAA',\n",
    "       'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'CS', 'BB', 'SO', 'BA',\n",
    "       'OBP', 'SLG', 'OPS', 'OPS+', 'GDP', 'HBP', 'SH', 'SF', 'IBB',\n",
    "       'Num_Pos']\n",
    "red_cat_columns = ['Tm', 'Acquired', 'Bat', 'C', '1B', '2B', '3B', 'SS', 'OF']\n",
    "X_ada = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ada_red_train, X_ada_red_test, y_ada_red_train, y_ada_red_test = train_test_split(X_ada, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "ada_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', AdaBoostRegressor(n_estimators = 200, learning_rate = 0.01))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Random Forest Metrics:\n",
      "Training RMSE: 5358808.636299628\n",
      "Test RMSE: 5656509.686938622\n"
     ]
    }
   ],
   "source": [
    "ada_red_pipe.fit(X_ada_red_train, y_ada_red_train)\n",
    "ada_red_train_mse = mean_squared_error(y_ada_red_train, ada_red_pipe.predict(X_ada_red_train))\n",
    "ada_red_test_mse = mean_squared_error(y_ada_red_test, ada_red_pipe.predict(X_ada_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(ada_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(ada_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', PCA(n_components = 30)),\n",
    "        ('model', AdaBoostRegressor(n_estimators = 200, learning_rate = 0.01))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 5528645.110368226\n",
      "Test RMSE: 5866138.083422676\n"
     ]
    }
   ],
   "source": [
    "ada_pipe.fit(X_train, y_train)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pipe.predict(X_train))\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(ada_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(ada_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', SVC(C = 3))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 3305791.485725613\n",
      "Test RMSE: 6511994.651652397\n"
     ]
    }
   ],
   "source": [
    "svm_pipe.fit(X_train, y_train)\n",
    "svm_train_mse = mean_squared_error(y_train, svm_pipe.predict(X_train))\n",
    "svm_test_mse = mean_squared_error(y_test, svm_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(svm_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(svm_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', PCA(n_components = 63)),\n",
    "        ('model', KNeighborsRegressor(n_neighbors = 5, weights = 'uniform'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Metrics:\n",
      "Training RMSE: 4357478.9227963155\n",
      "Test RMSE: 5627354.873436867\n"
     ]
    }
   ],
   "source": [
    "knn_pipe.fit(X_train, y_train)\n",
    "knn_train_mse = mean_squared_error(y_train, knn_pipe.predict(X_train))\n",
    "knn_test_mse = mean_squared_error(y_test, knn_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(knn_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(knn_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from bayes_opt import BayesianOptimization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.1\n",
    "scaling = 0.9\n",
    "shift = .2\n",
    "\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "X_train_aug = X_train_scaled + np.random.normal(scale = noise, size = X_train_scaled.shape)\n",
    "X_train_aug *= np.random.uniform(1 - scaling, 1 + scaling, size = X_train_scaled.shape)\n",
    "X_train_aug += np.random.uniform(-shift, shift, size = X_train_scaled.shape)\n",
    "\n",
    "X_train_comb = np.vstack((X_train_scaled, X_train_aug))\n",
    "y_train_comb = np.hstack((y_train, y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = preprocessor.fit_transform(X)\n",
    "\n",
    "#X_aug = X_scaled + np.random.normal(scale = noise, size = X_scaled.shape)\n",
    "#_aug *= np.random.uniform(1 - scaling, 1 + scaling, size = X_scaled.shape)\n",
    "#X_aug += np.random.uniform(-shift, shift, size = X_scaled.shape)\n",
    "\n",
    "#X_comb = np.vstack((X_scaled, X_aug))\n",
    "#y_comb = np.hstack((y, y))\n",
    "\n",
    "pca = PCA(n_components = 25, random_state = 621)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size = .2, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8097, 25)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | dropou... |  epochs   | layer_... | layer_... | layer_... | layer_... | layer_... | learni... |  neurons  | num_la... | patience  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-2.4e+13 \u001b[0m | \u001b[0m207.3    \u001b[0m | \u001b[0m0.4754   \u001b[0m | \u001b[0m392.8    \u001b[0m | \u001b[0m166.1    \u001b[0m | \u001b[0m66.95    \u001b[0m | \u001b[0m66.94    \u001b[0m | \u001b[0m45.01    \u001b[0m | \u001b[0m226.0    \u001b[0m | \u001b[0m0.6051   \u001b[0m | \u001b[0m190.6    \u001b[0m | \u001b[0m1.082    \u001b[0m | \u001b[0m49.1     \u001b[0m |\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m-2.576e+1\u001b[0m | \u001b[0m421.6    \u001b[0m | \u001b[0m0.1062   \u001b[0m | \u001b[0m172.7    \u001b[0m | \u001b[0m73.08    \u001b[0m | \u001b[0m100.2    \u001b[0m | \u001b[0m149.5    \u001b[0m | \u001b[0m128.8    \u001b[0m | \u001b[0m97.24    \u001b[0m | \u001b[0m0.6157   \u001b[0m | \u001b[0m63.25    \u001b[0m | \u001b[0m2.169    \u001b[0m | \u001b[0m30.99    \u001b[0m |\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-2.487e+1\u001b[0m | \u001b[0m245.4    \u001b[0m | \u001b[0m0.3926   \u001b[0m | \u001b[0m179.9    \u001b[0m | \u001b[0m147.2    \u001b[0m | \u001b[0m164.7    \u001b[0m | \u001b[0m42.4     \u001b[0m | \u001b[0m168.1    \u001b[0m | \u001b[0m70.2     \u001b[0m | \u001b[0m0.0744   \u001b[0m | \u001b[0m244.6    \u001b[0m | \u001b[0m4.863    \u001b[0m | \u001b[0m44.25    \u001b[0m |\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-2.475e+1\u001b[0m | \u001b[0m174.6    \u001b[0m | \u001b[0m0.04884  \u001b[0m | \u001b[0m373.7    \u001b[0m | \u001b[0m130.6    \u001b[0m | \u001b[0m59.34    \u001b[0m | \u001b[0m142.9    \u001b[0m | \u001b[0m39.7     \u001b[0m | \u001b[0m235.7    \u001b[0m | \u001b[0m0.2662   \u001b[0m | \u001b[0m180.4    \u001b[0m | \u001b[0m2.247    \u001b[0m | \u001b[0m35.6     \u001b[0m |\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-2.689e+1\u001b[0m | \u001b[0m287.9    \u001b[0m | \u001b[0m0.09243  \u001b[0m | \u001b[0m487.8    \u001b[0m | \u001b[0m205.6    \u001b[0m | \u001b[0m242.4    \u001b[0m | \u001b[0m232.4    \u001b[0m | \u001b[0m165.9    \u001b[0m | \u001b[0m238.5    \u001b[0m | \u001b[0m0.09761  \u001b[0m | \u001b[0m75.9     \u001b[0m | \u001b[0m1.181    \u001b[0m | \u001b[0m29.76    \u001b[0m |\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-2.46e+13\u001b[0m | \u001b[0m212.7    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m327.6    \u001b[0m | \u001b[0m197.0    \u001b[0m | \u001b[0m62.11    \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m57.06    \u001b[0m | \u001b[0m164.5    \u001b[0m | \u001b[0m0.9056   \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m1.182    \u001b[0m | \u001b[0m50.0     \u001b[0m |\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-2.456e+1\u001b[0m | \u001b[0m203.9    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m494.3    \u001b[0m | \u001b[0m185.7    \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m50.0     \u001b[0m |\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-2.612e+1\u001b[0m | \u001b[0m439.1    \u001b[0m | \u001b[0m0.3421   \u001b[0m | \u001b[0m194.0    \u001b[0m | \u001b[0m49.28    \u001b[0m | \u001b[0m243.3    \u001b[0m | \u001b[0m170.7    \u001b[0m | \u001b[0m131.0    \u001b[0m | \u001b[0m83.59    \u001b[0m | \u001b[0m0.1348   \u001b[0m | \u001b[0m86.74    \u001b[0m | \u001b[0m4.043    \u001b[0m | \u001b[0m20.82    \u001b[0m |\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-2.656e+1\u001b[0m | \u001b[0m451.2    \u001b[0m | \u001b[0m0.05307  \u001b[0m | \u001b[0m186.9    \u001b[0m | \u001b[0m114.3    \u001b[0m | \u001b[0m94.19    \u001b[0m | \u001b[0m165.8    \u001b[0m | \u001b[0m54.16    \u001b[0m | \u001b[0m225.9    \u001b[0m | \u001b[0m0.5165   \u001b[0m | \u001b[0m36.21    \u001b[0m | \u001b[0m4.075    \u001b[0m | \u001b[0m36.53    \u001b[0m |\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-2.66e+13\u001b[0m | \u001b[0m126.5    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m400.1    \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m226.0    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m100.5    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m50.0     \u001b[0m |\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-2.499e+1\u001b[0m | \u001b[0m254.3    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m402.1    \u001b[0m | \u001b[0m101.0    \u001b[0m | \u001b[0m82.28    \u001b[0m | \u001b[0m45.62    \u001b[0m | \u001b[0m47.24    \u001b[0m | \u001b[0m233.3    \u001b[0m | \u001b[0m0.3413   \u001b[0m | \u001b[0m253.8    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m50.0     \u001b[0m |\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-2.838e+1\u001b[0m | \u001b[0m234.5    \u001b[0m | \u001b[0m0.2632   \u001b[0m | \u001b[0m344.6    \u001b[0m | \u001b[0m105.0    \u001b[0m | \u001b[0m249.8    \u001b[0m | \u001b[0m70.72    \u001b[0m | \u001b[0m197.2    \u001b[0m | \u001b[0m103.6    \u001b[0m | \u001b[0m0.148    \u001b[0m | \u001b[0m132.6    \u001b[0m | \u001b[0m4.014    \u001b[0m | \u001b[0m24.55    \u001b[0m |\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-2.487e+1\u001b[0m | \u001b[0m256.7    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m390.0    \u001b[0m | \u001b[0m226.4    \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m114.8    \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m250.3    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m252.7    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m50.0     \u001b[0m |\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-2.535e+1\u001b[0m | \u001b[0m241.8    \u001b[0m | \u001b[0m0.05533  \u001b[0m | \u001b[0m354.7    \u001b[0m | \u001b[0m168.2    \u001b[0m | \u001b[0m56.76    \u001b[0m | \u001b[0m92.27    \u001b[0m | \u001b[0m43.61    \u001b[0m | \u001b[0m214.0    \u001b[0m | \u001b[0m0.3788   \u001b[0m | \u001b[0m198.5    \u001b[0m | \u001b[0m1.006    \u001b[0m | \u001b[0m37.77    \u001b[0m |\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-2.516e+1\u001b[0m | \u001b[0m148.2    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m411.8    \u001b[0m | \u001b[0m172.2    \u001b[0m | \u001b[0m85.12    \u001b[0m | \u001b[0m63.76    \u001b[0m | \u001b[0m47.35    \u001b[0m | \u001b[0m229.3    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m255.7    \u001b[0m | \u001b[0m1.595    \u001b[0m | \u001b[0m50.0     \u001b[0m |\n",
      "=========================================================================================================================================================================\n",
      "Best Hyperparameters: {'batch_size': 207.28477562056565, 'dropout_rate': 0.4753571532049581, 'epochs': 392.797576724562, 'layer_neurons_1': 166.0995004601362, 'layer_neurons_2': 66.94817545910578, 'layer_neurons_3': 66.94277255530939, 'layer_neurons_4': 45.010729125676676, 'layer_neurons_5': 226.02345665358547, 'learning_rate': 0.6051038616257767, 'neurons': 190.6082574263142, 'num_layers': 1.0823379771832098, 'patience': 49.097295564859834}\n"
     ]
    }
   ],
   "source": [
    "def dnn_model_score(neurons, dropout_rate, learning_rate, epochs, batch_size, patience, num_layers, **layer_neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(neurons), activation='relu', input_shape = (X_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    for i in range(1, int(num_layers) + 1):\n",
    "        model.add(Dense(int(layer_neurons[f'layer_neurons_{i}']), activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "    optimizer = Adam(learning_rate = learning_rate)\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "\n",
    "    es = EarlyStopping(monitor = 'val_loss', patience = int(patience), restore_best_weights = True)\n",
    "\n",
    "    model.fit(X_train, y_train, validation_split = .2, epochs = int(epochs), batch_size = int(batch_size), callbacks = es, verbose = 0)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return -mse\n",
    "\n",
    "pbounds = {'neurons': (32, 256),\n",
    "           'dropout_rate': (0.0, 0.5),\n",
    "           'learning_rate': (0.01, 1),\n",
    "           'epochs' : (100, 500),\n",
    "           'batch_size' : (32, 500),\n",
    "           'patience' : (20, 50),\n",
    "           'num_layers': (1, 5)}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    pbounds[f'layer_neurons_{i}'] = (32, 256)\n",
    "\n",
    "optimizer = BayesianOptimization(f = dnn_model_score, pbounds = pbounds, random_state = 42)\n",
    "\n",
    "optimizer.maximize(init_points = 5, n_iter = 10)\n",
    "\n",
    "best_params = optimizer.max['params']\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(best_params['batch_size'])\n",
    "dropout_rate = best_params['dropout_rate']\n",
    "epochs = int(best_params['epochs'])\n",
    "neurons = []\n",
    "neurons.append(int(best_params['neurons']))\n",
    "neurons.append(int(best_params['layer_neurons_1']))\n",
    "neurons.append(int(best_params['layer_neurons_2']))\n",
    "neurons.append(int(best_params['layer_neurons_3']))\n",
    "neurons.append(int(best_params['layer_neurons_4']))\n",
    "neurons.append(int(best_params['layer_neurons_5']))\n",
    "learning_rate = best_params['learning_rate']\n",
    "num_layers = int(best_params['num_layers'])\n",
    "patience = int(best_params['patience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_67\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_67\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">190</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,940</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">190</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">31,706</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">166</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">167</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m190\u001b[0m)            │         \u001b[38;5;34m4,940\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout1 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m190\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense2 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m)            │        \u001b[38;5;34m31,706\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout2 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m166\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m167\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,813</span> (143.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,813\u001b[0m (143.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,813</span> (143.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,813\u001b[0m (143.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(name = 'Dense1', units = neurons[0], input_dim = X_train.shape[1], activation = 'relu'))\n",
    "model.add(Dropout(name = 'Dropout1', rate = dropout_rate))\n",
    "\n",
    "for i in range(1, num_layers + 1):\n",
    "    model.add(Dense(name = f'Dense{i + 1}', units = neurons[i], activation = 'relu'))\n",
    "    model.add(Dropout(name = f'Dropout{i + 1}', rate = dropout_rate))\n",
    "\n",
    "model.add(Dense(name = 'Output', units = 1, activation = 'linear'))\n",
    "\n",
    "optimizer = Adam(learning_rate = learning_rate)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = 'mean_squared_error')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/392\n",
      "32/32 - 3s - 90ms/step - loss: 38219475320832.0000 - val_loss: 31267485646848.0000\n",
      "Epoch 2/392\n",
      "32/32 - 0s - 10ms/step - loss: 29844391854080.0000 - val_loss: 29783419256832.0000\n",
      "Epoch 3/392\n",
      "32/32 - 0s - 9ms/step - loss: 29495379623936.0000 - val_loss: 30090299703296.0000\n",
      "Epoch 4/392\n",
      "32/32 - 0s - 9ms/step - loss: 29329681547264.0000 - val_loss: 30534086426624.0000\n",
      "Epoch 5/392\n",
      "32/32 - 0s - 9ms/step - loss: 29339747876864.0000 - val_loss: 29948347678720.0000\n",
      "Epoch 6/392\n",
      "32/32 - 0s - 9ms/step - loss: 29252380524544.0000 - val_loss: 29600449036288.0000\n",
      "Epoch 7/392\n",
      "32/32 - 0s - 9ms/step - loss: 29439373082624.0000 - val_loss: 29462785687552.0000\n",
      "Epoch 8/392\n",
      "32/32 - 0s - 9ms/step - loss: 28782207434752.0000 - val_loss: 29764802838528.0000\n",
      "Epoch 9/392\n",
      "32/32 - 0s - 8ms/step - loss: 28882956713984.0000 - val_loss: 30504032141312.0000\n",
      "Epoch 10/392\n",
      "32/32 - 0s - 8ms/step - loss: 29524328710144.0000 - val_loss: 30199668277248.0000\n",
      "Epoch 11/392\n",
      "32/32 - 0s - 9ms/step - loss: 29146879098880.0000 - val_loss: 29560506679296.0000\n",
      "Epoch 12/392\n",
      "32/32 - 0s - 9ms/step - loss: 28725276049408.0000 - val_loss: 29556620656640.0000\n",
      "Epoch 13/392\n",
      "32/32 - 0s - 9ms/step - loss: 28480513245184.0000 - val_loss: 29565499998208.0000\n",
      "Epoch 14/392\n",
      "32/32 - 0s - 8ms/step - loss: 29163605983232.0000 - val_loss: 29363443597312.0000\n",
      "Epoch 15/392\n",
      "32/32 - 0s - 9ms/step - loss: 29126954057728.0000 - val_loss: 30303303237632.0000\n",
      "Epoch 16/392\n",
      "32/32 - 0s - 13ms/step - loss: 28718714060800.0000 - val_loss: 29241720700928.0000\n",
      "Epoch 17/392\n",
      "32/32 - 0s - 9ms/step - loss: 28563254280192.0000 - val_loss: 29274836828160.0000\n",
      "Epoch 18/392\n",
      "32/32 - 0s - 9ms/step - loss: 28227747708928.0000 - val_loss: 30871411228672.0000\n",
      "Epoch 19/392\n",
      "32/32 - 0s - 9ms/step - loss: 29138008145920.0000 - val_loss: 29878432825344.0000\n",
      "Epoch 20/392\n",
      "32/32 - 0s - 9ms/step - loss: 28510619959296.0000 - val_loss: 29467061780480.0000\n",
      "Epoch 21/392\n",
      "32/32 - 0s - 9ms/step - loss: 28020727349248.0000 - val_loss: 30662356631552.0000\n",
      "Epoch 22/392\n",
      "32/32 - 0s - 8ms/step - loss: 28378725875712.0000 - val_loss: 29190120275968.0000\n",
      "Epoch 23/392\n",
      "32/32 - 0s - 9ms/step - loss: 28755537952768.0000 - val_loss: 29023264571392.0000\n",
      "Epoch 24/392\n",
      "32/32 - 0s - 9ms/step - loss: 28030556700672.0000 - val_loss: 29162901340160.0000\n",
      "Epoch 25/392\n",
      "32/32 - 0s - 9ms/step - loss: 27969766555648.0000 - val_loss: 29608040726528.0000\n",
      "Epoch 26/392\n",
      "32/32 - 0s - 9ms/step - loss: 28717044727808.0000 - val_loss: 29378127855616.0000\n",
      "Epoch 27/392\n",
      "32/32 - 0s - 9ms/step - loss: 27854045708288.0000 - val_loss: 29366180380672.0000\n",
      "Epoch 28/392\n",
      "32/32 - 0s - 9ms/step - loss: 28050297192448.0000 - val_loss: 29930410737664.0000\n",
      "Epoch 29/392\n",
      "32/32 - 0s - 9ms/step - loss: 28446558257152.0000 - val_loss: 30089393733632.0000\n",
      "Epoch 30/392\n",
      "32/32 - 0s - 8ms/step - loss: 27413956263936.0000 - val_loss: 28839570833408.0000\n",
      "Epoch 31/392\n",
      "32/32 - 0s - 9ms/step - loss: 28311260495872.0000 - val_loss: 29584911237120.0000\n",
      "Epoch 32/392\n",
      "32/32 - 0s - 9ms/step - loss: 27805674897408.0000 - val_loss: 29584756047872.0000\n",
      "Epoch 33/392\n",
      "32/32 - 0s - 9ms/step - loss: 27653260181504.0000 - val_loss: 29453503692800.0000\n",
      "Epoch 34/392\n",
      "32/32 - 0s - 9ms/step - loss: 27463428079616.0000 - val_loss: 28577135329280.0000\n",
      "Epoch 35/392\n",
      "32/32 - 0s - 8ms/step - loss: 27794002149376.0000 - val_loss: 30718832934912.0000\n",
      "Epoch 36/392\n",
      "32/32 - 0s - 8ms/step - loss: 28100788224000.0000 - val_loss: 29130890412032.0000\n",
      "Epoch 37/392\n",
      "32/32 - 0s - 9ms/step - loss: 27984341762048.0000 - val_loss: 28807115309056.0000\n",
      "Epoch 38/392\n",
      "32/32 - 0s - 9ms/step - loss: 27308396118016.0000 - val_loss: 28419830054912.0000\n",
      "Epoch 39/392\n",
      "32/32 - 0s - 9ms/step - loss: 27519594004480.0000 - val_loss: 28446432428032.0000\n",
      "Epoch 40/392\n",
      "32/32 - 0s - 9ms/step - loss: 27313060184064.0000 - val_loss: 28806184173568.0000\n",
      "Epoch 41/392\n",
      "32/32 - 0s - 8ms/step - loss: 27626173366272.0000 - val_loss: 29171078135808.0000\n",
      "Epoch 42/392\n",
      "32/32 - 0s - 9ms/step - loss: 27729487462400.0000 - val_loss: 28517005787136.0000\n",
      "Epoch 43/392\n",
      "32/32 - 0s - 9ms/step - loss: 27565576159232.0000 - val_loss: 28400022454272.0000\n",
      "Epoch 44/392\n",
      "32/32 - 0s - 8ms/step - loss: 27673401229312.0000 - val_loss: 29256142815232.0000\n",
      "Epoch 45/392\n",
      "32/32 - 0s - 9ms/step - loss: 27188382400512.0000 - val_loss: 29708567707648.0000\n",
      "Epoch 46/392\n",
      "32/32 - 0s - 8ms/step - loss: 27387504885760.0000 - val_loss: 28634419036160.0000\n",
      "Epoch 47/392\n",
      "32/32 - 0s - 9ms/step - loss: 27116080988160.0000 - val_loss: 28754340478976.0000\n",
      "Epoch 48/392\n",
      "32/32 - 0s - 9ms/step - loss: 27172481794048.0000 - val_loss: 29277437296640.0000\n",
      "Epoch 49/392\n",
      "32/32 - 0s - 8ms/step - loss: 26700115083264.0000 - val_loss: 30923141677056.0000\n",
      "Epoch 50/392\n",
      "32/32 - 0s - 9ms/step - loss: 27779978493952.0000 - val_loss: 29938761596928.0000\n",
      "Epoch 51/392\n",
      "32/32 - 0s - 8ms/step - loss: 27331976495104.0000 - val_loss: 28280405098496.0000\n",
      "Epoch 52/392\n",
      "32/32 - 0s - 9ms/step - loss: 26857678307328.0000 - val_loss: 29652171096064.0000\n",
      "Epoch 53/392\n",
      "32/32 - 0s - 9ms/step - loss: 27091900825600.0000 - val_loss: 28753751179264.0000\n",
      "Epoch 54/392\n",
      "32/32 - 0s - 9ms/step - loss: 26952897396736.0000 - val_loss: 28206157529088.0000\n",
      "Epoch 55/392\n",
      "32/32 - 0s - 9ms/step - loss: 27766542041088.0000 - val_loss: 29093519163392.0000\n",
      "Epoch 56/392\n",
      "32/32 - 0s - 9ms/step - loss: 27048034697216.0000 - val_loss: 28865231585280.0000\n",
      "Epoch 57/392\n",
      "32/32 - 0s - 12ms/step - loss: 26334277402624.0000 - val_loss: 29322312155136.0000\n",
      "Epoch 58/392\n",
      "32/32 - 0s - 9ms/step - loss: 26567073857536.0000 - val_loss: 27995205009408.0000\n",
      "Epoch 59/392\n",
      "32/32 - 0s - 10ms/step - loss: 25921140555776.0000 - val_loss: 28060015394816.0000\n",
      "Epoch 60/392\n",
      "32/32 - 0s - 10ms/step - loss: 26258219991040.0000 - val_loss: 28611184689152.0000\n",
      "Epoch 61/392\n",
      "32/32 - 0s - 11ms/step - loss: 26513518886912.0000 - val_loss: 29377213497344.0000\n",
      "Epoch 62/392\n",
      "32/32 - 0s - 11ms/step - loss: 26516494745600.0000 - val_loss: 28347553808384.0000\n",
      "Epoch 63/392\n",
      "32/32 - 0s - 11ms/step - loss: 26351423717376.0000 - val_loss: 28807627014144.0000\n",
      "Epoch 64/392\n",
      "32/32 - 0s - 12ms/step - loss: 26668563431424.0000 - val_loss: 27830945579008.0000\n",
      "Epoch 65/392\n",
      "32/32 - 0s - 13ms/step - loss: 26295610114048.0000 - val_loss: 28427553865728.0000\n",
      "Epoch 66/392\n",
      "32/32 - 0s - 11ms/step - loss: 25888527745024.0000 - val_loss: 27844746936320.0000\n",
      "Epoch 67/392\n",
      "32/32 - 0s - 9ms/step - loss: 26296421711872.0000 - val_loss: 28142441857024.0000\n",
      "Epoch 68/392\n",
      "32/32 - 0s - 8ms/step - loss: 26281013936128.0000 - val_loss: 28569617039360.0000\n",
      "Epoch 69/392\n",
      "32/32 - 0s - 9ms/step - loss: 26638662238208.0000 - val_loss: 28594615091200.0000\n",
      "Epoch 70/392\n",
      "32/32 - 0s - 9ms/step - loss: 26280581922816.0000 - val_loss: 27951074639872.0000\n",
      "Epoch 71/392\n",
      "32/32 - 0s - 9ms/step - loss: 26161165893632.0000 - val_loss: 27743613878272.0000\n",
      "Epoch 72/392\n",
      "32/32 - 0s - 9ms/step - loss: 25896060715008.0000 - val_loss: 28320120963072.0000\n",
      "Epoch 73/392\n",
      "32/32 - 0s - 9ms/step - loss: 25838133182464.0000 - val_loss: 28588919226368.0000\n",
      "Epoch 74/392\n",
      "32/32 - 0s - 9ms/step - loss: 26433636270080.0000 - val_loss: 28596510916608.0000\n",
      "Epoch 75/392\n",
      "32/32 - 0s - 9ms/step - loss: 25397959852032.0000 - val_loss: 28874620534784.0000\n",
      "Epoch 76/392\n",
      "32/32 - 0s - 9ms/step - loss: 26150497681408.0000 - val_loss: 28260240982016.0000\n",
      "Epoch 77/392\n",
      "32/32 - 0s - 9ms/step - loss: 25583717187584.0000 - val_loss: 27571836157952.0000\n",
      "Epoch 78/392\n",
      "32/32 - 0s - 8ms/step - loss: 25508706254848.0000 - val_loss: 28070387908608.0000\n",
      "Epoch 79/392\n",
      "32/32 - 0s - 9ms/step - loss: 25916661039104.0000 - val_loss: 27639551098880.0000\n",
      "Epoch 80/392\n",
      "32/32 - 0s - 8ms/step - loss: 26236304752640.0000 - val_loss: 29765811568640.0000\n",
      "Epoch 81/392\n",
      "32/32 - 0s - 9ms/step - loss: 25824365379584.0000 - val_loss: 28298495131648.0000\n",
      "Epoch 82/392\n",
      "32/32 - 0s - 9ms/step - loss: 25546293510144.0000 - val_loss: 27844556095488.0000\n",
      "Epoch 83/392\n",
      "32/32 - 0s - 9ms/step - loss: 25316948967424.0000 - val_loss: 28485248614400.0000\n",
      "Epoch 84/392\n",
      "32/32 - 0s - 9ms/step - loss: 25608264351744.0000 - val_loss: 28499700088832.0000\n",
      "Epoch 85/392\n",
      "32/32 - 0s - 9ms/step - loss: 25686592978944.0000 - val_loss: 27606588063744.0000\n",
      "Epoch 86/392\n",
      "32/32 - 0s - 9ms/step - loss: 24702504402944.0000 - val_loss: 27493117460480.0000\n",
      "Epoch 87/392\n",
      "32/32 - 0s - 9ms/step - loss: 25307822161920.0000 - val_loss: 28767567216640.0000\n",
      "Epoch 88/392\n",
      "32/32 - 0s - 9ms/step - loss: 25624733286400.0000 - val_loss: 27381863546880.0000\n",
      "Epoch 89/392\n",
      "32/32 - 0s - 9ms/step - loss: 25849982091264.0000 - val_loss: 28099513155584.0000\n",
      "Epoch 90/392\n",
      "32/32 - 0s - 9ms/step - loss: 24836627759104.0000 - val_loss: 28729510199296.0000\n",
      "Epoch 91/392\n",
      "32/32 - 0s - 9ms/step - loss: 25627121942528.0000 - val_loss: 27791040970752.0000\n",
      "Epoch 92/392\n",
      "32/32 - 0s - 9ms/step - loss: 25585185193984.0000 - val_loss: 28602609434624.0000\n",
      "Epoch 93/392\n",
      "32/32 - 0s - 9ms/step - loss: 24977996775424.0000 - val_loss: 27687848509440.0000\n",
      "Epoch 94/392\n",
      "32/32 - 0s - 9ms/step - loss: 25532643147776.0000 - val_loss: 27958563569664.0000\n",
      "Epoch 95/392\n",
      "32/32 - 0s - 13ms/step - loss: 24985133383680.0000 - val_loss: 28787452411904.0000\n",
      "Epoch 96/392\n",
      "32/32 - 0s - 9ms/step - loss: 24585783214080.0000 - val_loss: 28480980910080.0000\n",
      "Epoch 97/392\n",
      "32/32 - 0s - 9ms/step - loss: 24539255799808.0000 - val_loss: 28978301632512.0000\n",
      "Epoch 98/392\n",
      "32/32 - 0s - 9ms/step - loss: 24457024372736.0000 - val_loss: 28939456086016.0000\n",
      "Epoch 99/392\n",
      "32/32 - 0s - 8ms/step - loss: 24700868624384.0000 - val_loss: 28913447206912.0000\n",
      "Epoch 100/392\n",
      "32/32 - 0s - 9ms/step - loss: 24820444037120.0000 - val_loss: 27921223778304.0000\n",
      "Epoch 101/392\n",
      "32/32 - 0s - 9ms/step - loss: 24627029999616.0000 - val_loss: 28403765870592.0000\n",
      "Epoch 102/392\n",
      "32/32 - 0s - 9ms/step - loss: 24770735243264.0000 - val_loss: 27033348341760.0000\n",
      "Epoch 103/392\n",
      "32/32 - 0s - 8ms/step - loss: 24663440752640.0000 - val_loss: 27588017782784.0000\n",
      "Epoch 104/392\n",
      "32/32 - 0s - 9ms/step - loss: 24181961916416.0000 - val_loss: 28151075831808.0000\n",
      "Epoch 105/392\n",
      "32/32 - 0s - 8ms/step - loss: 24525070663680.0000 - val_loss: 27741432840192.0000\n",
      "Epoch 106/392\n",
      "32/32 - 0s - 9ms/step - loss: 25010030772224.0000 - val_loss: 27765610905600.0000\n",
      "Epoch 107/392\n",
      "32/32 - 0s - 9ms/step - loss: 24068698931200.0000 - val_loss: 27698474778624.0000\n",
      "Epoch 108/392\n",
      "32/32 - 0s - 9ms/step - loss: 24666756349952.0000 - val_loss: 28531054608384.0000\n",
      "Epoch 109/392\n",
      "32/32 - 0s - 8ms/step - loss: 24377852690432.0000 - val_loss: 28186165379072.0000\n",
      "Epoch 110/392\n",
      "32/32 - 0s - 9ms/step - loss: 24502989750272.0000 - val_loss: 27558112395264.0000\n",
      "Epoch 111/392\n",
      "32/32 - 0s - 9ms/step - loss: 24141222641664.0000 - val_loss: 28097908834304.0000\n",
      "Epoch 112/392\n",
      "32/32 - 0s - 8ms/step - loss: 24564188839936.0000 - val_loss: 28654927085568.0000\n",
      "Epoch 113/392\n",
      "32/32 - 0s - 9ms/step - loss: 23441956667392.0000 - val_loss: 28479714230272.0000\n",
      "Epoch 114/392\n",
      "32/32 - 0s - 9ms/step - loss: 24674140422144.0000 - val_loss: 28789274836992.0000\n",
      "Epoch 115/392\n",
      "32/32 - 0s - 9ms/step - loss: 23814924664832.0000 - val_loss: 31046248693760.0000\n",
      "Epoch 116/392\n",
      "32/32 - 0s - 9ms/step - loss: 24708980408320.0000 - val_loss: 28313150029824.0000\n",
      "Epoch 117/392\n",
      "32/32 - 0s - 8ms/step - loss: 24096500875264.0000 - val_loss: 29978798325760.0000\n",
      "Epoch 118/392\n",
      "32/32 - 0s - 8ms/step - loss: 24807760461824.0000 - val_loss: 28898314158080.0000\n",
      "Epoch 119/392\n",
      "32/32 - 0s - 9ms/step - loss: 23944920825856.0000 - val_loss: 28032827916288.0000\n",
      "Epoch 120/392\n",
      "32/32 - 0s - 9ms/step - loss: 23871191252992.0000 - val_loss: 28156738142208.0000\n",
      "Epoch 121/392\n",
      "32/32 - 0s - 9ms/step - loss: 23626927570944.0000 - val_loss: 28676664066048.0000\n",
      "Epoch 122/392\n",
      "32/32 - 0s - 9ms/step - loss: 23476102496256.0000 - val_loss: 27839443238912.0000\n",
      "Epoch 123/392\n",
      "32/32 - 0s - 10ms/step - loss: 23201006485504.0000 - val_loss: 27328904167424.0000\n",
      "Epoch 124/392\n",
      "32/32 - 0s - 9ms/step - loss: 23587138306048.0000 - val_loss: 27586944040960.0000\n",
      "Epoch 125/392\n",
      "32/32 - 0s - 9ms/step - loss: 23410189008896.0000 - val_loss: 29430091087872.0000\n",
      "Epoch 126/392\n",
      "32/32 - 0s - 10ms/step - loss: 23031103619072.0000 - val_loss: 27883112235008.0000\n",
      "Epoch 127/392\n",
      "32/32 - 0s - 10ms/step - loss: 23516818702336.0000 - val_loss: 30462890213376.0000\n",
      "Epoch 128/392\n",
      "32/32 - 0s - 9ms/step - loss: 23257679921152.0000 - val_loss: 30822121865216.0000\n",
      "Epoch 129/392\n",
      "32/32 - 0s - 8ms/step - loss: 22936761139200.0000 - val_loss: 29377928626176.0000\n",
      "Epoch 130/392\n",
      "32/32 - 0s - 10ms/step - loss: 23004675309568.0000 - val_loss: 29151750782976.0000\n",
      "Epoch 131/392\n",
      "32/32 - 0s - 9ms/step - loss: 22862687633408.0000 - val_loss: 27811226058752.0000\n",
      "Epoch 132/392\n",
      "32/32 - 0s - 9ms/step - loss: 22544402874368.0000 - val_loss: 27171384983552.0000\n",
      "Epoch 133/392\n",
      "32/32 - 0s - 9ms/step - loss: 23399401259008.0000 - val_loss: 27164934144000.0000\n",
      "Epoch 134/392\n",
      "32/32 - 0s - 13ms/step - loss: 22826608230400.0000 - val_loss: 28953672679424.0000\n",
      "Epoch 135/392\n",
      "32/32 - 0s - 9ms/step - loss: 22763377000448.0000 - val_loss: 27957680668672.0000\n",
      "Epoch 136/392\n",
      "32/32 - 0s - 10ms/step - loss: 23014099910656.0000 - val_loss: 28034348351488.0000\n",
      "Epoch 137/392\n",
      "32/32 - 0s - 8ms/step - loss: 23363349118976.0000 - val_loss: 29056380698624.0000\n",
      "Epoch 138/392\n",
      "32/32 - 0s - 9ms/step - loss: 22845337894912.0000 - val_loss: 27496422572032.0000\n",
      "Epoch 139/392\n",
      "32/32 - 0s - 8ms/step - loss: 22734966882304.0000 - val_loss: 28616284962816.0000\n",
      "Epoch 140/392\n",
      "32/32 - 0s - 9ms/step - loss: 22839428120576.0000 - val_loss: 31064124817408.0000\n",
      "Epoch 141/392\n",
      "32/32 - 0s - 9ms/step - loss: 23050292559872.0000 - val_loss: 27647553830912.0000\n",
      "Epoch 142/392\n",
      "32/32 - 0s - 9ms/step - loss: 22526222663680.0000 - val_loss: 28137542909952.0000\n",
      "Epoch 143/392\n",
      "32/32 - 0s - 9ms/step - loss: 22635895324672.0000 - val_loss: 27624795537408.0000\n",
      "Epoch 144/392\n",
      "32/32 - 0s - 10ms/step - loss: 23026305335296.0000 - val_loss: 26512524836864.0000\n",
      "Epoch 145/392\n",
      "32/32 - 0s - 9ms/step - loss: 22895617114112.0000 - val_loss: 28767118426112.0000\n",
      "Epoch 146/392\n",
      "32/32 - 0s - 9ms/step - loss: 22379778539520.0000 - val_loss: 26376126070784.0000\n",
      "Epoch 147/392\n",
      "32/32 - 0s - 9ms/step - loss: 22451327074304.0000 - val_loss: 28001202864128.0000\n",
      "Epoch 148/392\n",
      "32/32 - 0s - 8ms/step - loss: 21999564881920.0000 - val_loss: 29905544806400.0000\n",
      "Epoch 149/392\n",
      "32/32 - 0s - 9ms/step - loss: 22222800420864.0000 - val_loss: 27858661539840.0000\n",
      "Epoch 150/392\n",
      "32/32 - 0s - 9ms/step - loss: 21838226784256.0000 - val_loss: 28304165830656.0000\n",
      "Epoch 151/392\n",
      "32/32 - 0s - 8ms/step - loss: 22899494748160.0000 - val_loss: 26934060777472.0000\n",
      "Epoch 152/392\n",
      "32/32 - 0s - 9ms/step - loss: 22317017071616.0000 - val_loss: 29383488176128.0000\n",
      "Epoch 153/392\n",
      "32/32 - 0s - 9ms/step - loss: 22249509748736.0000 - val_loss: 28988802072576.0000\n",
      "Epoch 154/392\n",
      "32/32 - 0s - 8ms/step - loss: 22497997094912.0000 - val_loss: 27457182760960.0000\n",
      "Epoch 155/392\n",
      "32/32 - 0s - 9ms/step - loss: 22050016067584.0000 - val_loss: 27501040500736.0000\n",
      "Epoch 156/392\n",
      "32/32 - 0s - 9ms/step - loss: 22428507963392.0000 - val_loss: 29551369388032.0000\n",
      "Epoch 157/392\n",
      "32/32 - 0s - 9ms/step - loss: 21811752337408.0000 - val_loss: 29649904074752.0000\n",
      "Epoch 158/392\n",
      "32/32 - 0s - 9ms/step - loss: 21362257166336.0000 - val_loss: 27047866925056.0000\n",
      "Epoch 159/392\n",
      "32/32 - 0s - 8ms/step - loss: 21912128323584.0000 - val_loss: 27387624423424.0000\n",
      "Epoch 160/392\n",
      "32/32 - 0s - 10ms/step - loss: 21782845194240.0000 - val_loss: 28040610447360.0000\n",
      "Epoch 161/392\n",
      "32/32 - 0s - 8ms/step - loss: 22555853324288.0000 - val_loss: 28111783591936.0000\n",
      "Epoch 162/392\n",
      "32/32 - 0s - 9ms/step - loss: 21695509299200.0000 - val_loss: 27784869052416.0000\n",
      "Epoch 163/392\n",
      "32/32 - 0s - 9ms/step - loss: 21975548297216.0000 - val_loss: 29617582768128.0000\n",
      "Epoch 164/392\n",
      "32/32 - 0s - 8ms/step - loss: 20811320655872.0000 - val_loss: 29611188551680.0000\n",
      "Epoch 165/392\n",
      "32/32 - 0s - 9ms/step - loss: 21507661103104.0000 - val_loss: 27735495802880.0000\n",
      "Epoch 166/392\n",
      "32/32 - 0s - 10ms/step - loss: 21093695881216.0000 - val_loss: 28356898717696.0000\n",
      "Epoch 167/392\n",
      "32/32 - 0s - 9ms/step - loss: 21375781699584.0000 - val_loss: 27583351619584.0000\n",
      "Epoch 168/392\n",
      "32/32 - 0s - 9ms/step - loss: 20772376543232.0000 - val_loss: 28978085625856.0000\n",
      "Epoch 169/392\n",
      "32/32 - 0s - 9ms/step - loss: 21562396770304.0000 - val_loss: 27728602464256.0000\n",
      "Epoch 170/392\n",
      "32/32 - 0s - 9ms/step - loss: 21554746359808.0000 - val_loss: 28953821577216.0000\n",
      "Epoch 171/392\n",
      "32/32 - 0s - 12ms/step - loss: 22234343145472.0000 - val_loss: 28765470064640.0000\n",
      "Epoch 172/392\n",
      "32/32 - 0s - 9ms/step - loss: 20637003284480.0000 - val_loss: 27484139552768.0000\n",
      "Epoch 173/392\n",
      "32/32 - 0s - 9ms/step - loss: 21062293127168.0000 - val_loss: 27386991083520.0000\n",
      "Epoch 174/392\n",
      "32/32 - 0s - 8ms/step - loss: 22282894311424.0000 - val_loss: 29214157832192.0000\n",
      "Epoch 175/392\n",
      "32/32 - 0s - 9ms/step - loss: 21732213653504.0000 - val_loss: 26550925787136.0000\n",
      "Epoch 176/392\n",
      "32/32 - 0s - 8ms/step - loss: 21468144467968.0000 - val_loss: 28519784513536.0000\n",
      "Epoch 177/392\n",
      "32/32 - 0s - 9ms/step - loss: 20608171638784.0000 - val_loss: 28754663440384.0000\n",
      "Epoch 178/392\n",
      "32/32 - 0s - 8ms/step - loss: 20509496442880.0000 - val_loss: 28466699304960.0000\n",
      "Epoch 179/392\n",
      "32/32 - 0s - 9ms/step - loss: 21017405685760.0000 - val_loss: 28699122466816.0000\n",
      "Epoch 180/392\n",
      "32/32 - 0s - 9ms/step - loss: 21202684870656.0000 - val_loss: 28048246177792.0000\n",
      "Epoch 181/392\n",
      "32/32 - 0s - 9ms/step - loss: 21012162805760.0000 - val_loss: 27118721302528.0000\n",
      "Epoch 182/392\n",
      "32/32 - 0s - 9ms/step - loss: 20745572843520.0000 - val_loss: 27013727387648.0000\n",
      "Epoch 183/392\n",
      "32/32 - 0s - 8ms/step - loss: 20646853607424.0000 - val_loss: 31525785567232.0000\n",
      "Epoch 184/392\n",
      "32/32 - 0s - 9ms/step - loss: 21041395007488.0000 - val_loss: 27844340088832.0000\n",
      "Epoch 185/392\n",
      "32/32 - 0s - 8ms/step - loss: 20541809360896.0000 - val_loss: 28011850104832.0000\n",
      "Epoch 186/392\n",
      "32/32 - 0s - 9ms/step - loss: 20264035287040.0000 - val_loss: 29454353039360.0000\n",
      "Epoch 187/392\n",
      "32/32 - 0s - 9ms/step - loss: 20296591474688.0000 - val_loss: 29610100129792.0000\n",
      "Epoch 188/392\n",
      "32/32 - 0s - 9ms/step - loss: 20261174771712.0000 - val_loss: 27843356524544.0000\n",
      "Epoch 189/392\n",
      "32/32 - 0s - 9ms/step - loss: 19789034553344.0000 - val_loss: 31502784004096.0000\n",
      "Epoch 190/392\n",
      "32/32 - 0s - 9ms/step - loss: 20421883723776.0000 - val_loss: 27481786548224.0000\n",
      "Epoch 191/392\n",
      "32/32 - 0s - 9ms/step - loss: 20636095217664.0000 - val_loss: 30391150837760.0000\n",
      "Epoch 192/392\n",
      "32/32 - 0s - 9ms/step - loss: 19950418788352.0000 - val_loss: 29764960124928.0000\n",
      "Epoch 193/392\n",
      "32/32 - 0s - 9ms/step - loss: 20439730487296.0000 - val_loss: 29955608018944.0000\n",
      "Epoch 194/392\n",
      "32/32 - 0s - 9ms/step - loss: 20584010350592.0000 - val_loss: 28528575774720.0000\n",
      "Epoch 195/392\n",
      "32/32 - 0s - 9ms/step - loss: 19893504180224.0000 - val_loss: 28080435363840.0000\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', patience = int(patience), restore_best_weights = True)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split = .2, batch_size = batch_size, epochs = epochs, callbacks = es, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict(X_test)\n",
    "train_preds = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 5741801.991830943\n",
      "Test RMSE: 5672449.36633386\n"
     ]
    }
   ],
   "source": [
    "train_rmse = mean_squared_error(y_train, train_preds)\n",
    "test_rmse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "print(f'Train RMSE: {np.sqrt(train_rmse)}')\n",
    "print(f'Test RMSE: {np.sqrt(test_rmse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dnn/dnn_pca25_model.keras')\n",
    "joblib.dump('dnn/pca25.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Train RMSE: 5741801.991830943\n",
      "Test RMSE: 5672449.36633386\n"
     ]
    }
   ],
   "source": [
    "X_scaled = preprocessor.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components = 25, random_state = 621)\n",
    "X_pca = pca.fit_transform(X_comb)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_comb, test_size = .2, random_state = 621)\n",
    "\n",
    "loaded = tf.keras.models.load_model('dnn/dnn_pca25_model.keras')\n",
    "\n",
    "test_preds = loaded.predict(X_test)\n",
    "train_preds = loaded.predict(X_train)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train, train_preds)\n",
    "test_rmse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "print(f'Train RMSE: {np.sqrt(train_rmse)}')\n",
    "print(f'Test RMSE: {np.sqrt(test_rmse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('dnn/dnn_pca35_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from keras.models import model_from_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
