{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball = pd.read_csv('data/baseball.csv')\n",
    "baseball = baseball.drop(['Name', 'Age', 'Name-additional'], axis = 1)\n",
    "baseball['Salary'] = baseball['Salary'].str.replace('$', '').astype(float)\n",
    "\n",
    "baseball['C'] = baseball['Position'].apply(lambda x: 1 if 'C' in x else 0)\n",
    "baseball['1B'] = baseball['Position'].apply(lambda x: 1 if '1B' in x else 0)\n",
    "baseball['2B'] = baseball['Position'].apply(lambda x: 1 if '2B' in x else 0)\n",
    "baseball['3B'] = baseball['Position'].apply(lambda x: 1 if '3B' in x else 0)\n",
    "baseball['SS'] = baseball['Position'].apply(lambda x: 1 if 'SS' in x else 0)\n",
    "baseball['OF'] = baseball['Position'].apply(lambda x: 1 if 'OF' in x else 0)\n",
    "\n",
    "baseball['Num_Pos'] = baseball[['C', '1B', '2B', '3B', 'SS', 'OF']].sum(axis = 1)\n",
    "baseball = baseball.drop(['Position'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "# packages used in each section below\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "import shap\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = baseball.drop(['Salary'], axis = 1)\n",
    "y = baseball['Salary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['Tm', 'Lg', 'Acquired', 'Bat']\n",
    "num_columns = [col for col in X.columns if col not in cat_columns + ['C', '1B', '2B', '3B', 'SS', 'OF']]\n",
    "\n",
    "cat_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('scale', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, num_columns),\n",
    "        ('cat', cat_transformer, cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "X_transform = preprocessor.fit_transform(X)\n",
    "\n",
    "selected_features = np.concatenate([\n",
    "    np.array(num_columns),\n",
    "    np.array(preprocessor.transformers_[1][1]['onehot'].get_feature_names_out(cat_columns)),\n",
    "    np.array(['C', '1B', '2B', '3B', 'SS', 'OF'])\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_rf = RFE(estimator = RandomForestRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_rf.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[rfe_rf.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'RAA', 'WAA', 'RAR',\n",
    "               'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'CS', 'BB', 'SO', 'BA', 'OBP',\n",
    "               'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB', 'Num_Pos', 'Season']\n",
    "red_cat_columns = ['Tm', 'Acquired']\n",
    "X_rf = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf_red_train, X_rf_red_test, y_rf_red_train, y_rf_red_test = train_test_split(X_rf, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "rf_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', RandomForestRegressor(n_estimators = 150, min_samples_leaf = 10))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_red_pipe.fit(X_rf_red_train, y_rf_red_train)\n",
    "rf_red_train_mse = mean_squared_error(y_rf_red_train, rf_red_pipe.predict(X_rf_red_train))\n",
    "rf_red_test_mse = mean_squared_error(y_rf_red_test, rf_red_pipe.predict(X_rf_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(rf_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(rf_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestRegressor(n_estimators = 150, min_samples_leaf = 10))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe.fit(X_train, y_train)\n",
    "rf_train_mse = mean_squared_error(y_train, rf_pipe.predict(X_train))\n",
    "rf_test_mse = mean_squared_error(y_test, rf_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(rf_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(rf_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_xg = RFE(estimator = XGBRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_xg.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[rfe_xg.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Season', 'RBI', 'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS+', \n",
    "                   'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB', 'Num_Pos']\n",
    "red_cat_columns = ['Tm', 'Acquired', 'Bat', 'C', '1B', '2B', '3B', 'SS', 'OF']\n",
    "X_xg = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_xg_red_train, X_xg_red_test, y_xg_red_train, y_xg_red_test = train_test_split(X_xg, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "xg_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', XGBRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_red_pipe.fit(X_xg_red_train, y_xg_red_train)\n",
    "xg_red_train_mse = mean_squared_error(y_xg_red_train, xg_red_pipe.predict(X_xg_red_train))\n",
    "xg_red_test_mse = mean_squared_error(y_xg_red_test, xg_red_pipe.predict(X_xg_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(xg_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(xg_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', XGBRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_pipe.fit(X_train, y_train)\n",
    "xg_train_mse = mean_squared_error(y_train, xg_pipe.predict(X_train))\n",
    "xg_test_mse = mean_squared_error(y_test, xg_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(xg_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(xg_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_gb = RFE(estimator = GradientBoostingRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_gb.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[rfe_gb.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['Def-Inn', 'PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA',\n",
    "       'WAA', 'RAR', 'WAR', 'PA', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'CS',\n",
    "       'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'SH',\n",
    "       'SF', 'IBB', 'Num_Pos']\n",
    "red_cat_columns = ['Tm', 'Acquired', 'C', '1B', '2B', '3B', 'SS', 'OF']\n",
    "X_gb = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gb_red_train, X_gb_red_test, y_gb_red_train, y_gb_red_test = train_test_split(X_gb, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "gb_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', GradientBoostingRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_red_pipe.fit(X_gb_red_train, y_gb_red_train)\n",
    "gb_red_train_mse = mean_squared_error(y_gb_red_train, gb_red_pipe.predict(X_gb_red_train))\n",
    "gb_red_test_mse = mean_squared_error(y_gb_red_test, gb_red_pipe.predict(X_gb_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(gb_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(gb_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', GradientBoostingRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipe.fit(X_train, y_train)\n",
    "gb_train_mse = mean_squared_error(y_train, gb_pipe.predict(X_train))\n",
    "gb_test_mse = mean_squared_error(y_test, gb_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(gb_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(gb_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADA Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_ada = RFE(estimator = AdaBoostRegressor(random_state = 621), step = 1, n_features_to_select = None)\n",
    "rfe_ada.fit(X_transform, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features[rfe_ada.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_num_columns = ['PO', 'A', 'E', 'DP', 'Fld%', 'Rdrs', 'Season', 'RAA', 'WAA',\n",
    "       'RAR', 'WAR', 'AB', 'R', 'H', 'HR', 'RBI', 'SB', 'BB', 'SO', 'BA',\n",
    "       'OBP', 'SLG', 'OPS', 'OPS+', 'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB',\n",
    "       'Num_Pos']\n",
    "red_cat_columns = ['Tm', 'Acquired', 'Bat', 'C', '1B', '2B', '3B', 'SS', 'OF']\n",
    "X_ada = X[red_num_columns + red_cat_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ada_red_train, X_ada_red_test, y_ada_red_train, y_ada_red_test = train_test_split(X_ada, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, red_num_columns),\n",
    "        ('cat', cat_transformer, red_cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "ada_red_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', red_preprocessor),\n",
    "        ('model', AdaBoostRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_red_pipe.fit(X_ada_red_train, y_ada_red_train)\n",
    "ada_red_train_mse = mean_squared_error(y_ada_red_train, ada_red_pipe.predict(X_ada_red_train))\n",
    "ada_red_test_mse = mean_squared_error(y_ada_red_test, ada_red_pipe.predict(X_ada_red_test))\n",
    "print('Reduced Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(ada_red_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(ada_red_test_mse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', PCA(n_components = 30, random_state = 621)),\n",
    "        ('model', AdaBoostRegressor(random_state = 621))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_pipe.fit(X_train, y_train)\n",
    "ada_train_mse = mean_squared_error(y_train, ada_pipe.predict(X_train))\n",
    "ada_test_mse = mean_squared_error(y_test, ada_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(ada_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(ada_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', SVC())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipe.fit(X_train, y_train)\n",
    "svm_train_mse = mean_squared_error(y_train, svm_pipe.predict(X_train))\n",
    "svm_test_mse = mean_squared_error(y_test, svm_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(svm_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(svm_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', PCA(n_components = 63)),\n",
    "        ('model', KNeighborsRegressor())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe.fit(X_train, y_train)\n",
    "knn_train_mse = mean_squared_error(y_train, knn_pipe.predict(X_train))\n",
    "knn_test_mse = mean_squared_error(y_test, knn_pipe.predict(X_test))\n",
    "print('Random Forest Metrics:')\n",
    "print(f'Training RMSE: {np.sqrt(knn_train_mse)}')\n",
    "print(f'Test RMSE: {np.sqrt(knn_test_mse)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 12:27:42.928037: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from bayes_opt import BayesianOptimization\n",
    "from keras.optimizers import Adam\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES:\n",
    "- Should look at different dropout rates for the different layers we add (similar code to adding more layers)\n",
    "- Should look into different EPOCHS or optimizers in order to optimally fit and train the data\n",
    "- Should also look into different batch sizes or maybe different activations for the different layers and run more iterations to find the best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | dropou... | layer_... | layer_... | layer_... | layer_... | layer_... | learni... |  neurons  | num_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-2.76e+13\u001b[0m | \u001b[0m0.1873   \u001b[0m | \u001b[0m245.0    \u001b[0m | \u001b[0m196.0    \u001b[0m | \u001b[0m166.1    \u001b[0m | \u001b[0m66.95    \u001b[0m | \u001b[0m66.94    \u001b[0m | \u001b[0m0.0675   \u001b[0m | \u001b[0m226.0    \u001b[0m | \u001b[0m3.404    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m-3.893e+1\u001b[0m | \u001b[0m0.354    \u001b[0m | \u001b[0m36.61    \u001b[0m | \u001b[0m249.3    \u001b[0m | \u001b[0m218.5    \u001b[0m | \u001b[0m79.56    \u001b[0m | \u001b[0m72.73    \u001b[0m | \u001b[0m0.1916   \u001b[0m | \u001b[0m100.2    \u001b[0m | \u001b[0m3.099    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m-2.526e+1\u001b[0m | \u001b[95m0.216    \u001b[0m | \u001b[95m97.24    \u001b[0m | \u001b[95m169.1    \u001b[0m | \u001b[95m63.25    \u001b[0m | \u001b[95m97.44    \u001b[0m | \u001b[95m114.1    \u001b[0m | \u001b[95m0.4615   \u001b[0m | \u001b[95m207.9    \u001b[0m | \u001b[95m1.799    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-6.932e+1\u001b[0m | \u001b[0m0.2571   \u001b[0m | \u001b[0m164.7    \u001b[0m | \u001b[0m42.4     \u001b[0m | \u001b[0m168.1    \u001b[0m | \u001b[0m70.2     \u001b[0m | \u001b[0m46.57    \u001b[0m | \u001b[0m0.9494   \u001b[0m | \u001b[0m248.3    \u001b[0m | \u001b[0m4.234    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m-2.317e+1\u001b[0m | \u001b[95m0.1523   \u001b[0m | \u001b[95m53.88    \u001b[0m | \u001b[95m185.3    \u001b[0m | \u001b[95m130.6    \u001b[0m | \u001b[95m59.34    \u001b[0m | \u001b[95m142.9    \u001b[0m | \u001b[95m0.04404  \u001b[0m | \u001b[95m235.7    \u001b[0m | \u001b[95m2.035    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-2.642e+1\u001b[0m | \u001b[0m0.0001818\u001b[0m | \u001b[0m230.6    \u001b[0m | \u001b[0m201.1    \u001b[0m | \u001b[0m167.0    \u001b[0m | \u001b[0m70.7     \u001b[0m | \u001b[0m68.65    \u001b[0m | \u001b[0m0.188    \u001b[0m | \u001b[0m220.5    \u001b[0m | \u001b[0m2.969    \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-2.613e+1\u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m169.3    \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m96.7     \u001b[0m | \u001b[0m57.58    \u001b[0m | \u001b[0m193.8    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m234.2    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-2.652e+1\u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m59.2     \u001b[0m | \u001b[0m165.6    \u001b[0m | \u001b[0m195.7    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-2.673e+1\u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m183.0    \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m252.8    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m170.7    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-2.622e+1\u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m68.69    \u001b[0m | \u001b[0m176.2    \u001b[0m | \u001b[0m97.1     \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m147.5    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-2.598e+1\u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m232.6    \u001b[0m | \u001b[0m187.1    \u001b[0m | \u001b[0m179.3    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m224.6    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-2.634e+1\u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m180.8    \u001b[0m | \u001b[0m36.8     \u001b[0m | \u001b[0m172.7    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m87.5     \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-2.629e+1\u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m154.7    \u001b[0m | \u001b[0m209.2    \u001b[0m | \u001b[0m90.78    \u001b[0m | \u001b[0m212.5    \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m100.6    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-2.62e+13\u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m256.0    \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-2.738e+1\u001b[0m | \u001b[0m0.1046   \u001b[0m | \u001b[0m208.6    \u001b[0m | \u001b[0m202.0    \u001b[0m | \u001b[0m209.3    \u001b[0m | \u001b[0m226.5    \u001b[0m | \u001b[0m175.9    \u001b[0m | \u001b[0m0.3207   \u001b[0m | \u001b[0m201.5    \u001b[0m | \u001b[0m3.374    \u001b[0m |\n",
      "=====================================================================================================================================\n",
      "Best Hyperparameters: {'dropout_rate': 0.15230688458668534, 'layer_neurons_1': 53.87855353742999, 'layer_neurons_2': 185.26819793872315, 'layer_neurons_3': 130.59415859767068, 'layer_neurons_4': 59.33656460523046, 'layer_neurons_5': 142.9196278649245, 'learning_rate': 0.044044635904066216, 'neurons': 235.6877700656472, 'num_layers': 2.0351199264000677}\n"
     ]
    }
   ],
   "source": [
    "def dnn_cv_score(neurons, dropout_rate, learning_rate, num_layers, **layer_neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(neurons), activation='relu', input_shape = (X_train_scaled.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    for i in range(1, int(num_layers) + 1):\n",
    "        model.add(Dense(int(layer_neurons[f'layer_neurons_{i}']), activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "    optimizer = Adam(learning_rate = learning_rate)\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "\n",
    "    model.fit(X_train_scaled, y_train, epochs = 50, batch_size = 32, verbose = 0)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return -mse\n",
    "\n",
    "pbounds = {'neurons': (32, 256),\n",
    "           'dropout_rate': (0.0, 0.5),\n",
    "           'learning_rate': (0.01, 1),\n",
    "           'num_layers': (1, 5)}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    pbounds[f'layer_neurons_{i}'] = (32, 256)\n",
    "\n",
    "optimizer = BayesianOptimization(f = dnn_cv_score, pbounds = pbounds, random_state = 42)\n",
    "\n",
    "optimizer.maximize(init_points = 5, n_iter = 10)\n",
    "\n",
    "best_params = optimizer.max['params']\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(name = 'Dense1', units = 208, input_dim = X_train_scaled.shape[1], activation = 'relu'))\n",
    "model.add(Dropout(name = 'Dropout1', rate = 0.21597250932105788))\n",
    "model.add(Dense(name = 'Dense2', units = 97, activation = 'relu'))\n",
    "model.add(Dropout(name = 'Dropout2', rate = 0.21597250932105788))\n",
    "model.add(Dense(name = 'Dense3', units = 169, activation = 'relu'))\n",
    "model.add(Dropout(name = 'Dropout3', rate = 0.21597250932105788))\n",
    "\n",
    "model.add(Dense(name = 'Output', units = 1, activation = 'linear'))\n",
    "\n",
    "optimizer = Adam(learning_rate = 0.46150928437486555)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = 'mean_squared_error')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train, validation_split = .2, batch_size = 32, epochs = 50, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test_scaled)\n",
    "train_preds = model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse = mean_squared_error(y_train, train_preds)\n",
    "test_rmse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "print(f'Train RMSE: {np.sqrt(train_rmse)}')\n",
    "print(f'Test RMSE: {np.sqrt(test_rmse)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
