{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "import shap\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseball = pd.read_csv('data/baseball.csv')\n",
    "baseball = baseball.drop(['Name', 'Age', 'Name-additional'], axis = 1)\n",
    "baseball['Salary'] = baseball['Salary'].str.replace('$', '').astype(float)\n",
    "\n",
    "baseball['Pos_C'] = baseball['Position'].apply(lambda x: 1 if 'C' in x else 0)\n",
    "baseball['Pos_1B'] = baseball['Position'].apply(lambda x: 1 if '1B' in x else 0)\n",
    "baseball['Pos_2B'] = baseball['Position'].apply(lambda x: 1 if '2B' in x else 0)\n",
    "baseball['Pos_3B'] = baseball['Position'].apply(lambda x: 1 if '3B' in x else 0)\n",
    "baseball['Pos_SS'] = baseball['Position'].apply(lambda x: 1 if 'SS' in x else 0)\n",
    "baseball['Pos_OF'] = baseball['Position'].apply(lambda x: 1 if 'OF' in x else 0)\n",
    "\n",
    "baseball['Num_Pos'] = baseball[['Pos_C', 'Pos_1B', 'Pos_2B', 'Pos_3B', 'Pos_SS', 'Pos_OF']].sum(axis = 1)\n",
    "baseball['R/AB'] = baseball['R'] / baseball['AB']\n",
    "baseball['2B/AB'] = baseball['2B'] / baseball['AB']\n",
    "baseball['3B/AB'] = baseball['3B'] / baseball['AB']\n",
    "baseball['HR/AB'] = baseball['HR'] / baseball['AB']\n",
    "baseball['RBI/AB'] = baseball['RBI'] / baseball['AB']\n",
    "baseball['BB/PA'] = baseball['BB'] / baseball['PA']\n",
    "baseball['SB - CS'] = baseball['SB'] - baseball['CS']\n",
    "baseball['BB - SO'] = baseball['BB'] - baseball['SO'] # measures a batters eye\n",
    "baseball['E/Def-Inn'] = baseball['E'] / baseball['Def-Inn']\n",
    "baseball['DP/Def-Inn'] = baseball['DP'] / baseball['Def-Inn']\n",
    "\n",
    "baseball = baseball.drop(['Position', 'Def-Inn', 'PO', 'A', 'E', 'DP', 'PA', 'AB', 'R', 'H', \n",
    "                          '2B', '3B', 'HR', 'RBI', 'SB', 'CS', 'BB', 'SO', 'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = baseball.drop(['Salary'], axis = 1)\n",
    "y = baseball['Salary']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns = ['Tm', 'Lg', 'Acquired', 'Bat']\n",
    "num_columns = [col for col in X.columns if col not in cat_columns + ['Pos_C', 'Pos_1B', 'Pos_2B', 'Pos_3B', 'Pos_SS', 'Pos_OF']]\n",
    "\n",
    "cat_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('onehot', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "num_transformer = Pipeline(\n",
    "    steps = [\n",
    "        ('scale', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('cont', num_transformer, num_columns),\n",
    "        ('cat', cat_transformer, cat_columns)\n",
    "    ], remainder = 'passthrough'\n",
    ")\n",
    "\n",
    "X_transform = preprocessor.fit_transform(X)\n",
    "\n",
    "selected_features = np.concatenate([\n",
    "    np.array(num_columns),\n",
    "    np.array(preprocessor.transformers_[1][1]['onehot'].get_feature_names_out(cat_columns)),\n",
    "    np.array(['Pos_C', 'Pos_1B', 'Pos_2B', 'Pos_3B', 'Pos_SS', 'Pos_OF'])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from bayes_opt import BayesianOptimization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transform, y, test_size = .2, random_state = 621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | dropou... |  epochs   | layer_... | layer_... | layer_... | layer_... | layer_... | learni... |  neurons  | num_la... | patience  |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-2.342e+1\u001b[0m | \u001b[0m207.3    \u001b[0m | \u001b[0m0.4754   \u001b[0m | \u001b[0m392.8    \u001b[0m | \u001b[0m166.1    \u001b[0m | \u001b[0m66.95    \u001b[0m | \u001b[0m66.94    \u001b[0m | \u001b[0m45.01    \u001b[0m | \u001b[0m226.0    \u001b[0m | \u001b[0m0.6051   \u001b[0m | \u001b[0m190.6    \u001b[0m | \u001b[0m1.082    \u001b[0m | \u001b[0m49.1     \u001b[0m |\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m-2.362e+1\u001b[0m | \u001b[0m421.6    \u001b[0m | \u001b[0m0.1062   \u001b[0m | \u001b[0m172.7    \u001b[0m | \u001b[0m73.08    \u001b[0m | \u001b[0m100.2    \u001b[0m | \u001b[0m149.5    \u001b[0m | \u001b[0m128.8    \u001b[0m | \u001b[0m97.24    \u001b[0m | \u001b[0m0.6157   \u001b[0m | \u001b[0m63.25    \u001b[0m | \u001b[0m2.169    \u001b[0m | \u001b[0m30.99    \u001b[0m |\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-2.489e+1\u001b[0m | \u001b[0m245.4    \u001b[0m | \u001b[0m0.3926   \u001b[0m | \u001b[0m179.9    \u001b[0m | \u001b[0m147.2    \u001b[0m | \u001b[0m164.7    \u001b[0m | \u001b[0m42.4     \u001b[0m | \u001b[0m168.1    \u001b[0m | \u001b[0m70.2     \u001b[0m | \u001b[0m0.0744   \u001b[0m | \u001b[0m244.6    \u001b[0m | \u001b[0m4.863    \u001b[0m | \u001b[0m44.25    \u001b[0m |\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-2.44e+13\u001b[0m | \u001b[0m174.6    \u001b[0m | \u001b[0m0.04884  \u001b[0m | \u001b[0m373.7    \u001b[0m | \u001b[0m130.6    \u001b[0m | \u001b[0m59.34    \u001b[0m | \u001b[0m142.9    \u001b[0m | \u001b[0m39.7     \u001b[0m | \u001b[0m235.7    \u001b[0m | \u001b[0m0.2662   \u001b[0m | \u001b[0m180.4    \u001b[0m | \u001b[0m2.247    \u001b[0m | \u001b[0m35.6     \u001b[0m |\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-2.408e+1\u001b[0m | \u001b[0m287.9    \u001b[0m | \u001b[0m0.09243  \u001b[0m | \u001b[0m487.8    \u001b[0m | \u001b[0m205.6    \u001b[0m | \u001b[0m242.4    \u001b[0m | \u001b[0m232.4    \u001b[0m | \u001b[0m165.9    \u001b[0m | \u001b[0m238.5    \u001b[0m | \u001b[0m0.09761  \u001b[0m | \u001b[0m75.9     \u001b[0m | \u001b[0m1.181    \u001b[0m | \u001b[0m29.76    \u001b[0m |\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-2.371e+1\u001b[0m | \u001b[0m259.3    \u001b[0m | \u001b[0m0.354    \u001b[0m | \u001b[0m263.0    \u001b[0m | \u001b[0m154.4    \u001b[0m | \u001b[0m218.6    \u001b[0m | \u001b[0m143.3    \u001b[0m | \u001b[0m158.1    \u001b[0m | \u001b[0m126.6    \u001b[0m | \u001b[0m0.1988   \u001b[0m | \u001b[0m250.1    \u001b[0m | \u001b[0m1.082    \u001b[0m | \u001b[0m23.73    \u001b[0m |\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-2.515e+1\u001b[0m | \u001b[0m353.1    \u001b[0m | \u001b[0m0.3643   \u001b[0m | \u001b[0m410.4    \u001b[0m | \u001b[0m232.1    \u001b[0m | \u001b[0m166.2    \u001b[0m | \u001b[0m254.1    \u001b[0m | \u001b[0m59.43    \u001b[0m | \u001b[0m206.1    \u001b[0m | \u001b[0m0.06139  \u001b[0m | \u001b[0m62.54    \u001b[0m | \u001b[0m3.695    \u001b[0m | \u001b[0m35.34    \u001b[0m |\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-6.741e+1\u001b[0m | \u001b[0m439.1    \u001b[0m | \u001b[0m0.3421   \u001b[0m | \u001b[0m194.0    \u001b[0m | \u001b[0m49.28    \u001b[0m | \u001b[0m243.3    \u001b[0m | \u001b[0m170.7    \u001b[0m | \u001b[0m131.0    \u001b[0m | \u001b[0m83.59    \u001b[0m | \u001b[0m0.1348   \u001b[0m | \u001b[0m86.74    \u001b[0m | \u001b[0m4.043    \u001b[0m | \u001b[0m20.82    \u001b[0m |\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-6.741e+1\u001b[0m | \u001b[0m451.2    \u001b[0m | \u001b[0m0.05307  \u001b[0m | \u001b[0m186.9    \u001b[0m | \u001b[0m114.3    \u001b[0m | \u001b[0m94.19    \u001b[0m | \u001b[0m165.8    \u001b[0m | \u001b[0m54.16    \u001b[0m | \u001b[0m225.9    \u001b[0m | \u001b[0m0.5165   \u001b[0m | \u001b[0m36.21    \u001b[0m | \u001b[0m4.075    \u001b[0m | \u001b[0m36.53    \u001b[0m |\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "| \u001b[95m10       \u001b[0m | \u001b[95m-2.21e+13\u001b[0m | \u001b[95m240.9    \u001b[0m | \u001b[95m0.4286   \u001b[0m | \u001b[95m237.9    \u001b[0m | \u001b[95m153.5    \u001b[0m | \u001b[95m171.6    \u001b[0m | \u001b[95m86.9     \u001b[0m | \u001b[95m150.5    \u001b[0m | \u001b[95m111.7    \u001b[0m | \u001b[95m0.1999   \u001b[0m | \u001b[95m243.3    \u001b[0m | \u001b[95m2.906    \u001b[0m | \u001b[95m36.47    \u001b[0m |\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-2.32e+13\u001b[0m | \u001b[0m243.6    \u001b[0m | \u001b[0m0.3176   \u001b[0m | \u001b[0m379.7    \u001b[0m | \u001b[0m189.2    \u001b[0m | \u001b[0m159.8    \u001b[0m | \u001b[0m152.7    \u001b[0m | \u001b[0m115.3    \u001b[0m | \u001b[0m186.4    \u001b[0m | \u001b[0m0.2213   \u001b[0m | \u001b[0m168.3    \u001b[0m | \u001b[0m1.973    \u001b[0m | \u001b[0m36.9     \u001b[0m |\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-2.596e+1\u001b[0m | \u001b[0m234.5    \u001b[0m | \u001b[0m0.2632   \u001b[0m | \u001b[0m344.6    \u001b[0m | \u001b[0m105.0    \u001b[0m | \u001b[0m249.8    \u001b[0m | \u001b[0m70.72    \u001b[0m | \u001b[0m197.2    \u001b[0m | \u001b[0m103.6    \u001b[0m | \u001b[0m0.148    \u001b[0m | \u001b[0m132.6    \u001b[0m | \u001b[0m4.014    \u001b[0m | \u001b[0m24.55    \u001b[0m |\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-2.405e+1\u001b[0m | \u001b[0m161.9    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m353.3    \u001b[0m | \u001b[0m108.1    \u001b[0m | \u001b[0m155.0    \u001b[0m | \u001b[0m76.21    \u001b[0m | \u001b[0m127.0    \u001b[0m | \u001b[0m165.0    \u001b[0m | \u001b[0m0.4005   \u001b[0m | \u001b[0m245.2    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m23.22    \u001b[0m |\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-2.614e+1\u001b[0m | \u001b[0m422.8    \u001b[0m | \u001b[0m0.109    \u001b[0m | \u001b[0m173.5    \u001b[0m | \u001b[0m83.78    \u001b[0m | \u001b[0m104.0    \u001b[0m | \u001b[0m156.0    \u001b[0m | \u001b[0m129.1    \u001b[0m | \u001b[0m102.1    \u001b[0m | \u001b[0m0.02239  \u001b[0m | \u001b[0m74.81    \u001b[0m | \u001b[0m1.956    \u001b[0m | \u001b[0m31.67    \u001b[0m |\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-2.428e+1\u001b[0m | \u001b[0m354.3    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m154.5    \u001b[0m | \u001b[0m80.42    \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m108.4    \u001b[0m | \u001b[0m186.0    \u001b[0m | \u001b[0m32.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m76.64    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m38.71    \u001b[0m |\n",
      "=========================================================================================================================================================================\n",
      "Best Hyperparameters: {'batch_size': 240.89763598028236, 'dropout_rate': 0.42855588578354403, 'epochs': 237.94712200255134, 'layer_neurons_1': 153.52715797593584, 'layer_neurons_2': 171.6137220289574, 'layer_neurons_3': 86.90159050409001, 'layer_neurons_4': 150.4658065470828, 'layer_neurons_5': 111.66528321066846, 'learning_rate': 0.19989465787536304, 'neurons': 243.3083757611682, 'num_layers': 2.905535173493038, 'patience': 36.469707184570076}\n"
     ]
    }
   ],
   "source": [
    "def dnn_model_score(neurons, dropout_rate, learning_rate, epochs, batch_size, patience, num_layers, **layer_neurons):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(int(neurons), activation='relu', input_shape = (X_train.shape[1],)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    for i in range(1, int(num_layers) + 1):\n",
    "        model.add(Dense(int(layer_neurons[f'layer_neurons_{i}']), activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "    optimizer = Adam(learning_rate = learning_rate)\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "\n",
    "    es = EarlyStopping(monitor = 'val_loss', patience = int(patience), restore_best_weights = True)\n",
    "\n",
    "    model.fit(X_train, y_train, validation_split = .2, epochs = int(epochs), batch_size = int(batch_size), callbacks = es, verbose = 0)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    return -mse\n",
    "\n",
    "pbounds = {'neurons': (32, 256),\n",
    "           'dropout_rate': (0.0, 0.5),\n",
    "           'learning_rate': (0.01, 1),\n",
    "           'epochs' : (100, 500),\n",
    "           'batch_size' : (32, 500),\n",
    "           'patience' : (20, 50),\n",
    "           'num_layers': (1, 5)}\n",
    "\n",
    "for i in range(1, 6):\n",
    "    pbounds[f'layer_neurons_{i}'] = (32, 256)\n",
    "\n",
    "optimizer = BayesianOptimization(f = dnn_model_score, pbounds = pbounds, random_state = 42)\n",
    "\n",
    "optimizer.maximize(init_points = 5, n_iter = 10)\n",
    "\n",
    "best_params = optimizer.max['params']\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(best_params['batch_size'])\n",
    "dropout_rate = best_params['dropout_rate']\n",
    "epochs = int(best_params['epochs'])\n",
    "neurons = []\n",
    "neurons.append(int(best_params['neurons']))\n",
    "neurons.append(int(best_params['layer_neurons_1']))\n",
    "neurons.append(int(best_params['layer_neurons_2']))\n",
    "neurons.append(int(best_params['layer_neurons_3']))\n",
    "neurons.append(int(best_params['layer_neurons_4']))\n",
    "neurons.append(int(best_params['layer_neurons_5']))\n",
    "learning_rate = best_params['learning_rate']\n",
    "num_layers = int(best_params['num_layers'])\n",
    "patience = int(best_params['patience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_57\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_57\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">243</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,711</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">243</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">153</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,332</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">153</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">171</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,334</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">171</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">172</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Dense1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m243\u001b[0m)            │        \u001b[38;5;34m18,711\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout1 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m243\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense2 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m153\u001b[0m)            │        \u001b[38;5;34m37,332\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout2 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m153\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dense3 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m171\u001b[0m)            │        \u001b[38;5;34m26,334\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout3 (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m171\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m172\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,549</span> (322.46 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m82,549\u001b[0m (322.46 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,549</span> (322.46 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m82,549\u001b[0m (322.46 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(name = 'Dense1', units = neurons[0], input_dim = X_train.shape[1], activation = 'relu'))\n",
    "model.add(Dropout(name = 'Dropout1', rate = dropout_rate))\n",
    "\n",
    "for i in range(1, num_layers + 1):\n",
    "    model.add(Dense(name = f'Dense{i + 1}', units = neurons[i], activation = 'relu'))\n",
    "    model.add(Dropout(name = f'Dropout{i + 1}', rate = dropout_rate))\n",
    "\n",
    "model.add(Dense(name = 'Output', units = 1, activation = 'linear'))\n",
    "\n",
    "optimizer = Adam(learning_rate = learning_rate)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = 'mean_squared_error')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/237\n",
      "14/14 - 3s - 213ms/step - loss: 50376845819904.0000 - val_loss: 35216148135936.0000\n",
      "Epoch 2/237\n",
      "14/14 - 0s - 19ms/step - loss: 33823595167744.0000 - val_loss: 27806905925632.0000\n",
      "Epoch 3/237\n",
      "14/14 - 0s - 20ms/step - loss: 31751099383808.0000 - val_loss: 24726487433216.0000\n",
      "Epoch 4/237\n",
      "14/14 - 0s - 17ms/step - loss: 29393344790528.0000 - val_loss: 24126066524160.0000\n",
      "Epoch 5/237\n",
      "14/14 - 0s - 16ms/step - loss: 28801050345472.0000 - val_loss: 24942865285120.0000\n",
      "Epoch 6/237\n",
      "14/14 - 0s - 17ms/step - loss: 27835355889664.0000 - val_loss: 23157991800832.0000\n",
      "Epoch 7/237\n",
      "14/14 - 0s - 16ms/step - loss: 27041095221248.0000 - val_loss: 23205297258496.0000\n",
      "Epoch 8/237\n",
      "14/14 - 0s - 17ms/step - loss: 27106700427264.0000 - val_loss: 22662537543680.0000\n",
      "Epoch 9/237\n",
      "14/14 - 0s - 17ms/step - loss: 26786547105792.0000 - val_loss: 22838920609792.0000\n",
      "Epoch 10/237\n",
      "14/14 - 0s - 17ms/step - loss: 25471475515392.0000 - val_loss: 22688535937024.0000\n",
      "Epoch 11/237\n",
      "14/14 - 0s - 17ms/step - loss: 25503027167232.0000 - val_loss: 21703342161920.0000\n",
      "Epoch 12/237\n",
      "14/14 - 0s - 17ms/step - loss: 25715743391744.0000 - val_loss: 24186955235328.0000\n",
      "Epoch 13/237\n",
      "14/14 - 0s - 17ms/step - loss: 25245037625344.0000 - val_loss: 21329023598592.0000\n",
      "Epoch 14/237\n",
      "14/14 - 0s - 16ms/step - loss: 23881519726592.0000 - val_loss: 23496996421632.0000\n",
      "Epoch 15/237\n",
      "14/14 - 0s - 17ms/step - loss: 23969461698560.0000 - val_loss: 21291423760384.0000\n",
      "Epoch 16/237\n",
      "14/14 - 0s - 17ms/step - loss: 22937570639872.0000 - val_loss: 22245632114688.0000\n",
      "Epoch 17/237\n",
      "14/14 - 0s - 16ms/step - loss: 22453258551296.0000 - val_loss: 22164377960448.0000\n",
      "Epoch 18/237\n",
      "14/14 - 0s - 16ms/step - loss: 21817980878848.0000 - val_loss: 21513478602752.0000\n",
      "Epoch 19/237\n",
      "14/14 - 0s - 16ms/step - loss: 21707857330176.0000 - val_loss: 20259276849152.0000\n",
      "Epoch 20/237\n",
      "14/14 - 0s - 16ms/step - loss: 20622226751488.0000 - val_loss: 21015555997696.0000\n",
      "Epoch 21/237\n",
      "14/14 - 0s - 16ms/step - loss: 20351035637760.0000 - val_loss: 21563782987776.0000\n",
      "Epoch 22/237\n",
      "14/14 - 0s - 16ms/step - loss: 19570282725376.0000 - val_loss: 20407977508864.0000\n",
      "Epoch 23/237\n",
      "14/14 - 0s - 16ms/step - loss: 19678271373312.0000 - val_loss: 22298377584640.0000\n",
      "Epoch 24/237\n",
      "14/14 - 0s - 16ms/step - loss: 18560583729152.0000 - val_loss: 21911115399168.0000\n",
      "Epoch 25/237\n",
      "14/14 - 0s - 16ms/step - loss: 19571140460544.0000 - val_loss: 20144789127168.0000\n",
      "Epoch 26/237\n",
      "14/14 - 0s - 16ms/step - loss: 17425468751872.0000 - val_loss: 20387152789504.0000\n",
      "Epoch 27/237\n",
      "14/14 - 0s - 16ms/step - loss: 16761884770304.0000 - val_loss: 21108059275264.0000\n",
      "Epoch 28/237\n",
      "14/14 - 0s - 16ms/step - loss: 16219079966720.0000 - val_loss: 20569107988480.0000\n",
      "Epoch 29/237\n",
      "14/14 - 0s - 20ms/step - loss: 16360396554240.0000 - val_loss: 20868554031104.0000\n",
      "Epoch 30/237\n",
      "14/14 - 0s - 17ms/step - loss: 16138814619648.0000 - val_loss: 21393550868480.0000\n",
      "Epoch 31/237\n",
      "14/14 - 0s - 16ms/step - loss: 16634416726016.0000 - val_loss: 19879346307072.0000\n",
      "Epoch 32/237\n",
      "14/14 - 0s - 16ms/step - loss: 16413939990528.0000 - val_loss: 23589648596992.0000\n",
      "Epoch 33/237\n",
      "14/14 - 0s - 16ms/step - loss: 16079745187840.0000 - val_loss: 20612781178880.0000\n",
      "Epoch 34/237\n",
      "14/14 - 0s - 16ms/step - loss: 15546391199744.0000 - val_loss: 21060195975168.0000\n",
      "Epoch 35/237\n",
      "14/14 - 0s - 16ms/step - loss: 15595482382336.0000 - val_loss: 20073844572160.0000\n",
      "Epoch 36/237\n",
      "14/14 - 0s - 16ms/step - loss: 14588107030528.0000 - val_loss: 19833328500736.0000\n",
      "Epoch 37/237\n",
      "14/14 - 0s - 16ms/step - loss: 13640625291264.0000 - val_loss: 20558399930368.0000\n",
      "Epoch 38/237\n",
      "14/14 - 0s - 16ms/step - loss: 14376596668416.0000 - val_loss: 20174944075776.0000\n",
      "Epoch 39/237\n",
      "14/14 - 0s - 16ms/step - loss: 14138815283200.0000 - val_loss: 20816001499136.0000\n",
      "Epoch 40/237\n",
      "14/14 - 0s - 15ms/step - loss: 14414742814720.0000 - val_loss: 21151707299840.0000\n",
      "Epoch 41/237\n",
      "14/14 - 0s - 16ms/step - loss: 13656143167488.0000 - val_loss: 20229329518592.0000\n",
      "Epoch 42/237\n",
      "14/14 - 0s - 16ms/step - loss: 13129968779264.0000 - val_loss: 21289395814400.0000\n",
      "Epoch 43/237\n",
      "14/14 - 0s - 16ms/step - loss: 13320071413760.0000 - val_loss: 20588248694784.0000\n",
      "Epoch 44/237\n",
      "14/14 - 0s - 16ms/step - loss: 13133025378304.0000 - val_loss: 21411741564928.0000\n",
      "Epoch 45/237\n",
      "14/14 - 0s - 16ms/step - loss: 13609319006208.0000 - val_loss: 20707408871424.0000\n",
      "Epoch 46/237\n",
      "14/14 - 0s - 15ms/step - loss: 13595237679104.0000 - val_loss: 21077851897856.0000\n",
      "Epoch 47/237\n",
      "14/14 - 0s - 16ms/step - loss: 12736937328640.0000 - val_loss: 20628358823936.0000\n",
      "Epoch 48/237\n",
      "14/14 - 0s - 26ms/step - loss: 12757769388032.0000 - val_loss: 20309025488896.0000\n",
      "Epoch 49/237\n",
      "14/14 - 0s - 16ms/step - loss: 12986657800192.0000 - val_loss: 19535973318656.0000\n",
      "Epoch 50/237\n",
      "14/14 - 0s - 16ms/step - loss: 12957941497856.0000 - val_loss: 20692315668480.0000\n",
      "Epoch 51/237\n",
      "14/14 - 0s - 16ms/step - loss: 11764674592768.0000 - val_loss: 20836784275456.0000\n",
      "Epoch 52/237\n",
      "14/14 - 0s - 23ms/step - loss: 12090863517696.0000 - val_loss: 19343706423296.0000\n",
      "Epoch 53/237\n",
      "14/14 - 0s - 30ms/step - loss: 11836028092416.0000 - val_loss: 20955707473920.0000\n",
      "Epoch 54/237\n",
      "14/14 - 0s - 27ms/step - loss: 12089591595008.0000 - val_loss: 20397407862784.0000\n",
      "Epoch 55/237\n",
      "14/14 - 0s - 23ms/step - loss: 12181462581248.0000 - val_loss: 19929233358848.0000\n",
      "Epoch 56/237\n",
      "14/14 - 0s - 20ms/step - loss: 12327125516288.0000 - val_loss: 19833638879232.0000\n",
      "Epoch 57/237\n",
      "14/14 - 0s - 17ms/step - loss: 10567483916288.0000 - val_loss: 20449087979520.0000\n",
      "Epoch 58/237\n",
      "14/14 - 0s - 17ms/step - loss: 10931929088000.0000 - val_loss: 20803779297280.0000\n",
      "Epoch 59/237\n",
      "14/14 - 0s - 17ms/step - loss: 12766585815040.0000 - val_loss: 20996576772096.0000\n",
      "Epoch 60/237\n",
      "14/14 - 0s - 16ms/step - loss: 12376660246528.0000 - val_loss: 20449696153600.0000\n",
      "Epoch 61/237\n",
      "14/14 - 0s - 16ms/step - loss: 12276978417664.0000 - val_loss: 21576598683648.0000\n",
      "Epoch 62/237\n",
      "14/14 - 0s - 16ms/step - loss: 13263794339840.0000 - val_loss: 20790403661824.0000\n",
      "Epoch 63/237\n",
      "14/14 - 0s - 16ms/step - loss: 12453207343104.0000 - val_loss: 21111467147264.0000\n",
      "Epoch 64/237\n",
      "14/14 - 0s - 16ms/step - loss: 11729652154368.0000 - val_loss: 20281762512896.0000\n",
      "Epoch 65/237\n",
      "14/14 - 0s - 19ms/step - loss: 10802785419264.0000 - val_loss: 20362821632000.0000\n",
      "Epoch 66/237\n",
      "14/14 - 0s - 16ms/step - loss: 11646385782784.0000 - val_loss: 20740470472704.0000\n",
      "Epoch 67/237\n",
      "14/14 - 0s - 16ms/step - loss: 11103695273984.0000 - val_loss: 21013995716608.0000\n",
      "Epoch 68/237\n",
      "14/14 - 0s - 15ms/step - loss: 11048541224960.0000 - val_loss: 21424095887360.0000\n",
      "Epoch 69/237\n",
      "14/14 - 0s - 16ms/step - loss: 12062856052736.0000 - val_loss: 21612137021440.0000\n",
      "Epoch 70/237\n",
      "14/14 - 0s - 16ms/step - loss: 10925576814592.0000 - val_loss: 19563490050048.0000\n",
      "Epoch 71/237\n",
      "14/14 - 0s - 16ms/step - loss: 10700821889024.0000 - val_loss: 20694725296128.0000\n",
      "Epoch 72/237\n",
      "14/14 - 0s - 16ms/step - loss: 10791669465088.0000 - val_loss: 21350613778432.0000\n",
      "Epoch 73/237\n",
      "14/14 - 0s - 16ms/step - loss: 11183122808832.0000 - val_loss: 20363637424128.0000\n",
      "Epoch 74/237\n",
      "14/14 - 0s - 16ms/step - loss: 10483539116032.0000 - val_loss: 20941098713088.0000\n",
      "Epoch 75/237\n",
      "14/14 - 0s - 15ms/step - loss: 10058236690432.0000 - val_loss: 20609757085696.0000\n",
      "Epoch 76/237\n",
      "14/14 - 0s - 16ms/step - loss: 9997605928960.0000 - val_loss: 19943993114624.0000\n",
      "Epoch 77/237\n",
      "14/14 - 0s - 16ms/step - loss: 10276415995904.0000 - val_loss: 21050882523136.0000\n",
      "Epoch 78/237\n",
      "14/14 - 0s - 17ms/step - loss: 9993804840960.0000 - val_loss: 20991484887040.0000\n",
      "Epoch 79/237\n",
      "14/14 - 0s - 17ms/step - loss: 10328400199680.0000 - val_loss: 22302307647488.0000\n",
      "Epoch 80/237\n",
      "14/14 - 0s - 18ms/step - loss: 10646159622144.0000 - val_loss: 20717598932992.0000\n",
      "Epoch 81/237\n",
      "14/14 - 0s - 17ms/step - loss: 11878886539264.0000 - val_loss: 21075121405952.0000\n",
      "Epoch 82/237\n",
      "14/14 - 0s - 19ms/step - loss: 10673770725376.0000 - val_loss: 21183468666880.0000\n",
      "Epoch 83/237\n",
      "14/14 - 0s - 18ms/step - loss: 9564152922112.0000 - val_loss: 20393167421440.0000\n",
      "Epoch 84/237\n",
      "14/14 - 0s - 21ms/step - loss: 9004281495552.0000 - val_loss: 20734896242688.0000\n",
      "Epoch 85/237\n",
      "14/14 - 0s - 16ms/step - loss: 10097140957184.0000 - val_loss: 20746959060992.0000\n",
      "Epoch 86/237\n",
      "14/14 - 0s - 16ms/step - loss: 8714891296768.0000 - val_loss: 20565907734528.0000\n",
      "Epoch 87/237\n",
      "14/14 - 0s - 27ms/step - loss: 9481849143296.0000 - val_loss: 20955344666624.0000\n",
      "Epoch 88/237\n",
      "14/14 - 0s - 16ms/step - loss: 9449094774784.0000 - val_loss: 20433300619264.0000\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor = 'val_loss', patience = int(patience), restore_best_weights = True)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_split = .2, batch_size = batch_size, epochs = epochs, callbacks = es, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "test_preds = model.predict(X_test)\n",
    "train_preds = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Network Metrics:\n",
      "Train RMSE: 3031693.1268392135\n",
      "Test RMSE: 4818131.924759854\n"
     ]
    }
   ],
   "source": [
    "train_rmse = mean_squared_error(y_train, train_preds)\n",
    "test_rmse = mean_squared_error(y_test, test_preds)\n",
    "\n",
    "print('Deep Neural Network Metrics:')\n",
    "print(f'Train RMSE: {np.sqrt(train_rmse)}')\n",
    "print(f'Test RMSE: {np.sqrt(test_rmse)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dnn_new/best_preprocssor.joblib']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model, pca, and preprocessor so that new data can be fit using the same criteria\n",
    "#model.save('dnn_new/best_model.keras')\n",
    "#joblib.dump(pca, 'dnn/pca45.joblib')\n",
    "#joblib.dump(preprocessor, 'dnn_new/best_preprocssor.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
